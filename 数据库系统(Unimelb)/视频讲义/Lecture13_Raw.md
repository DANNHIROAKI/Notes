$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140021621.png" alt="image-20240420140021621" style="zoom:50%;" /> 

This is one of several possible architectures; each system has its own slight variations.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140104341.png" alt="image-20240420140104341" style="zoom:50%;" /> 

```
å¤§å®¶å¥½ï¼Œæ¬¢è¿å›åˆ°æ•°æ®åº“ç³»ç»Ÿç³»åˆ—ç¬¬ 13 è®²ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨æŸ¥è¯¢ä¼˜åŒ–ã€‚ä½œä¸ºå¼€åœºç™½ï¼Œè¯·è®°ä½ä¼˜åŒ–å™¨æ˜¯æŸ¥è¯¢å¤„ç†æ¨¡å—çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬ä¸Šå‘¨å¼€å§‹æ¢è®¨çš„ä¸»é¢˜ã€‚åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºäº†æ‰§è¡Œå™¨ï¼Œè¯¦ç»†ä»‹ç»äº†æ‰§è¡Œè®¡åˆ’çš„æ„å»ºæ¨¡å—ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†å„ç§æ“ä½œï¼ˆæ— è®ºæ˜¯è¿æ¥è¿˜æ˜¯è®¿é—®è·¯å¾„ï¼‰æ˜¯å¦‚ä½•æ‰§è¡Œçš„ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æŠŠè¿™äº›å…ƒç´ æ‹¼å‡‘åœ¨ä¸€èµ·ï¼Œäº†è§£å®ƒä»¬å¦‚ä½•æ„æˆä¸€ä¸ªå…¨é¢çš„æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ã€‚
Hello, everyone, and welcome back to lecture 13 of our database systems series. Today, we'll delve into query optimization. To set the stage, remember that the optimizer is a crucial component of the query processing module, a topic we began exploring last week. Up to this point, we've discussed the executor, detailing the building blocks of execution plans. We've examined how various operations, whether joins or access paths, are executed. Today, we will piece these elements together to understand how they form a comprehensive query execution plan.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140122998.png" alt="image-20240420140122998" style="zoom:50%;" /> 

**â€¢ Overview**
â€¢ Query optimization
â€¢ Cost estimation

```
For this lecture. We will use material from chapters 12 and 15 of the database management systems book. 
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140203113.png" alt="image-20240420140203113" style="zoom:50%;" /> 

```sql
Select *
From Blah B
Where B.blah = â€œfooâ€
```

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140227459.png" alt="image-20240420140227459" style="zoom:50%;" /> 

```
å›é¡¾ä¸€ä¸‹æˆ‘ä»¬å·²ç»è®¨è®ºè¿‡çš„å·¥ä½œæµç¨‹ã€‚ç”¨æˆ·è¾“å…¥æŸ¥è¯¢åï¼ŒæŸ¥è¯¢é¦–å…ˆä¼šåˆ°è¾¾æŸ¥è¯¢è§£æå™¨ï¼Œç”±å…¶æ£€æŸ¥è¯­æ³•å¹¶è¿›è¡Œä¸€äº›é‡å†™ã€‚ç„¶åï¼ŒæŸ¥è¯¢ä¼šè¿›å…¥æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼Œå¦‚å‰æ‰€è¿°ï¼ŒæŸ¥è¯¢ä¼˜åŒ–å™¨æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„å¤§è„‘ï¼Œè´Ÿè´£å¤„ç†æœ€å¤æ‚çš„ä»»åŠ¡ã€‚ä¼˜åŒ–å™¨çš„ä¸»è¦ä½œç”¨æ˜¯æ¢ç´¢æ‰§è¡ŒæŸ¥è¯¢çš„æ‰€æœ‰å¯èƒ½æ–¹å¼ï¼Œè¿™ä¸€é˜¶æ®µç§°ä¸ºè®¡åˆ’ç”Ÿæˆã€‚ç„¶åï¼Œæ¯ä¸ªå¯èƒ½çš„è®¡åˆ’éƒ½è¦ä½¿ç”¨ä¼°ç®—å™¨è¿›è¡Œæˆæœ¬è¯„ä¼°ï¼Œä¼°ç®—å™¨ä¾èµ–äºç›®å½•ä¸­çš„åŸºæœ¬ä¿¡æ¯ï¼Œæˆ‘ä»¬ä»Šå¤©å°†è®¨è®ºè¿™äº›ä¿¡æ¯ã€‚é€‰å‡ºæœ€å…·æˆæœ¬æ•ˆç›Šçš„è®¡åˆ’ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æŸ¥è¯¢è®¡åˆ’è¯„ä¼°å™¨æˆ–æ‰§è¡Œå™¨ã€‚ç„¶åï¼Œæ‰§è¡Œå™¨ä¼šæ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’--ä¸€è¿ä¸²æ—¨åœ¨æ£€ç´¢æ‰€éœ€ç»“æœçš„æ­¥éª¤ã€‚åœ¨è¿™ä¸ªæ‰§è¡Œé˜¶æ®µï¼Œæ‰€æœ‰å†…å®¹éƒ½ä¼šæ•´åˆåœ¨ä¸€èµ·äº§ç”Ÿç»“æœã€‚
Just to recap, let's revisit the workflow we've already discussed. Once a query is entered by a user, it first reaches the query parser, which checks the syntax and may perform some rewriting. Then, the query progresses to the query optimizer, which, as I've mentioned, acts as the brain of database systems, handling the most complex tasks. The primary role of the optimizer is to explore all possible ways a query can be executed, a phase known as plan generation. Each potential plan is then evaluated for its cost using an estimator that relies on basic information from the catalog, which we will discuss today. The most cost-effective plan is selected and passed to the query plan evaluator or executor. This executor then implements the query planâ€”a sequence of steps designed to retrieve the desired results. This execution phase is where everything comes together to produce the outcome.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140309242.png" alt="image-20240420140309242" style="zoom:50%;" /> 

**1ï¸âƒ£**Typically there are many ways of executing a given query, all giving the same answer

**2ï¸âƒ£**Cost of alternative methods often **varies enormously**

**3ï¸âƒ£**Query optimization aims to find the execution strategy with the lowest cost

**4ï¸âƒ£**We will cover:

1. Relational algebra equivalences
2. Cost estimation: Result size estimation and reduction factors
3. Enumeration of alternative plans

```
æŸ¥è¯¢ä¼˜åŒ–å¯ä»¥è¯´æ˜¯æ•°æ®åº“ç®¡ç†ä¸­æœ€å…³é”®çš„ä¸€ç¯ã€‚æ‰§è¡Œå•ä¸ªæŸ¥è¯¢çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œè™½ç„¶æ‰€æœ‰æ›¿ä»£æ–¹æ³•éƒ½å¯èƒ½äº§ç”Ÿç›¸åŒçš„ç»“æœï¼Œä½†ä¸è¿™äº›æ–¹æ³•ç›¸å…³çš„æˆæœ¬å´å¯èƒ½ç›¸å·®å¾ˆå¤§ã€‚ä¸€ä¸ªæœªç»ä¼˜åŒ–çš„æŸ¥è¯¢å¯èƒ½éœ€è¦å‡ å¤©ç”šè‡³å‡ ä¸ªæœˆçš„æ—¶é—´æ‰èƒ½æ‰§è¡Œï¼Œè€Œä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„æŸ¥è¯¢å¯ä»¥æ›´å¿«åœ°äº§ç”Ÿç»“æœã€‚æŸ¥è¯¢ä¼˜åŒ–çš„ä¸»è¦ç›®æ ‡æ˜¯æ‰¾åˆ°æ£€ç´¢æ‰€éœ€ä¿¡æ¯çš„æœ€æœ‰æ•ˆæ­¥éª¤åºåˆ—ã€‚è¿™ç§æ•ˆç‡ä¸ä»…å¯¹æ•°æ®åº“æ€§èƒ½è‡³å…³é‡è¦ï¼Œè€Œä¸”å¯¹ä½¿ç”¨è¿™äº›æ•°æ®åº“çš„äºº--æ— è®ºæ˜¯å­¦ç”Ÿã€ä¸“ä¸šäººå£«è¿˜æ˜¯ä¼ä¸š--çš„å·¥ä½œæ•ˆç‡å’Œæ»¡æ„åº¦ä¹Ÿè‡³å…³é‡è¦ã€‚
Query optimization is arguably the most crucial aspect of database management. There are numerous ways to execute a single query, and while all alternatives may yield the same result, the costs associated with these methods can vary significantly. An unoptimized query might take days or even months to execute, whereas an optimized query can produce results much faster. The primary goal of query optimization is to find the most efficient sequence of steps to retrieve the desired information. This efficiency is vital not only for database performance but also for the productivity and satisfaction of those who use these databasesâ€”whether students, professionals, or businesses.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140309242.png" alt="image-20240420140309242" style="zoom:50%;" /> 

**1ï¸âƒ£**Typically there are many ways of executing a given query, all giving the same answer

**2ï¸âƒ£**Cost of alternative methods often **varies enormously**

**3ï¸âƒ£**Query optimization aims to find the execution strategy with the lowest cost

**4ï¸âƒ£**We will cover:

1. Relational algebra equivalences
2. Cost estimation: Result size estimation and reduction factors
3. Enumeration of alternative plans

```
å°½ç®¡æŸ¥è¯¢ä¼˜åŒ–éå¸¸é‡è¦ï¼Œä½†ä»å­¦ç”Ÿåˆ°ä¸“ä¸šäººå£«ï¼Œå¾ˆå¤šäººéƒ½è§‰å¾—æŸ¥è¯¢ä¼˜åŒ–ä»¤äººç”Ÿç•ï¼Œå®æ„¿é¿å…å¤„ç†å®ƒã€‚ç„¶è€Œï¼ŒæŸ¥è¯¢ä¼˜åŒ–çš„åŸºæœ¬åŸç†éå¸¸ç®€å•ã€‚ä¼˜åŒ–å™¨åˆ©ç”¨å…³ç³»ä»£æ•°ç­‰ä»·å…³ç³»æ¥æ¢ç´¢æ›¿ä»£æ‰§è¡Œè®¡åˆ’ï¼Œç¡®ä¿æ‰€æœ‰å¯èƒ½çš„æ–¹æ³•éƒ½èƒ½äº§ç”Ÿå‡†ç¡®çš„ç»“æœã€‚é€šè¿‡ç†è§£å’Œåº”ç”¨ç®€å•çš„ç®—æ³•ï¼Œä»»ä½•äººéƒ½èƒ½æ˜¾è‘—æé«˜æŸ¥è¯¢æ€§èƒ½ã€‚è¿™äº›çŸ¥è¯†åœ¨å·¥ä½œä¸­éå¸¸å®è´µï¼Œå› ä¸ºä¼˜åŒ–æŸ¥è¯¢å¯ä»¥å¤§å¤§åŠ å¿«æ•°æ®åˆ†æçš„é€Ÿåº¦ï¼Œå—ç›Šçš„ä¸ä»…æ˜¯è‡ªå·±ï¼Œè¿˜æœ‰åŒäº‹ã€å®¢æˆ·å’Œä¸Šçº§ã€‚
Despite its importance, many individuals, from students to professionals, find query optimization daunting and prefer to avoid dealing with it. However, the underlying principles of query optimization are quite straightforward. The optimizer leverages relational algebra equivalences to explore alternative execution plans, ensuring that all possible approaches yield accurate results. By understanding and applying simple algorithms, anyone can significantly enhance the performance of their queries. This knowledge is invaluable in the workforce, where optimizing a query can drastically speed up data analysis, benefiting not just oneself but also colleagues, clients, and superiors.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140309242.png" alt="image-20240420140309242" style="zoom:50%;" /> 

**1ï¸âƒ£**Typically there are many ways of executing a given query, all giving the same answer

**2ï¸âƒ£**Cost of alternative methods often **varies enormously**

**3ï¸âƒ£**Query optimization aims to find the execution strategy with the lowest cost

**4ï¸âƒ£**We will cover:

1. Relational algebra equivalences
2. Cost estimation: Result size estimation and reduction factors
3. Enumeration of alternative plans

```
å®é™…ä¸Šï¼ŒæŸ¥è¯¢ä¼˜åŒ–åŒ…æ‹¬ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ï¼šä¼°è®¡ç»“æœå¤§å°å’Œè®¡ç®—æ‰§è¡Œæˆæœ¬ã€‚ç»“æœå¤§å°æˆ–äº§ç”Ÿçš„å…ƒç»„æ•°é‡è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä¼šå½±å“æŸ¥è¯¢è®¡åˆ’ä¸­çš„åç»­æ“ä½œã€‚äº†è§£è¾“å…¥å¤§å°æœ‰åŠ©äºå‡†ç¡®è®¡ç®—æ¯ä¸ªæ“ä½œçš„æˆæœ¬ï¼Œæ— è®ºæ˜¯è¿æ¥ã€é€‰æ‹©è¿˜æ˜¯æŠ•å½±ã€‚æ˜å¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•å°†è¿™äº›å…ƒç´ é›†æˆåˆ°å…¨é¢çš„æŸ¥è¯¢è®¡åˆ’ä¸­ï¼Œå¹¶å°†æˆ‘ä»¬è®¨è®ºè¿‡çš„æ‰€æœ‰æ¦‚å¿µè¿æ¥åˆ°ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢çš„ç»Ÿä¸€ç­–ç•¥ä¸­ã€‚
In practical terms, query optimization involves two key components: estimating the result size and calculating the cost of execution. The result size, or the number of tuples produced, is critical because it affects subsequent operations within the query plan. Knowing the input size helps in accurately costing each operation, whether it's a join, selection, or projection. Tomorrow, we will delve deeper into how these elements are integrated into comprehensive query plans, connecting all the concepts weâ€™ve discussed into a cohesive strategy for optimizing database queries.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140513012.png" alt="image-20240420140513012" style="zoom:50%;" /> 

**1ï¸âƒ£**A tree, with relational algebra operators as nodes and accesspaths as leaves

**2ï¸âƒ£**Each operator labeled with a choice of algorithm

```sql
SELECT snamefrom Sailors NATURAL JOIN Reserves
WHERE bid = 100 and rating > 5
```

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140558041.png" alt="image-20240420140558041" style="zoom:50%;" /> 

```
æŸ¥è¯¢è®¡åˆ’æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªè“å›¾ï¼Œæ¦‚è¿°äº†æ•°æ®åº“æŸ¥è¯¢åº”è¯¥å¦‚ä½•æ‰§è¡Œã€‚è™½ç„¶æˆ‘ä¹‹å‰å¯¹å®ƒçš„æè¿°æœ‰äº›æ¨¡ç³Šï¼Œä½†é‡è¦çš„æ˜¯è¦äº†è§£æŸ¥è¯¢è®¡åˆ’çš„ç»“æ„æ˜¯ä¸€æ£µå…³ç³»ä»£æ•°æ ‘ã€‚æ ‘ä¸­çš„èŠ‚ç‚¹æ˜¯å…³ç³»ä»£æ•°è¿ç®—ç¬¦ï¼Œæ ‘å¶ä»£è¡¨è®¿é—®è·¯å¾„ï¼Œè¡¨ç¤ºåº”å¦‚ä½•è®¿é—®æ•°æ®ã€‚æ¯ä¸ªèŠ‚ç‚¹è¿˜ä¸ç‰¹å®šç®—æ³•ç›¸å…³è”ï¼Œåæ˜ äº†æˆ‘ä»¬è®¨è®ºè¿‡çš„è¿æ¥ã€é€‰æ‹©å’ŒæŠ•å½±ç­‰æ“ä½œçš„å„ç§å®ç°ç­–ç•¥ã€‚
A query plan is essentially a blueprint that outlines how a database query should be executed. While I've previously described it somewhat vaguely, itâ€™s important to understand that a query plan is structured as a relational algebra tree. The nodes in this tree are relational algebra operators, and the leaves represent access paths indicating how data should be accessed. Each node is also associated with a specific algorithm, reflecting the various implementation strategies we've discussed for operations such as joins, selections, and projections.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140513012.png" alt="image-20240420140513012" style="zoom:50%;" /> 

**1ï¸âƒ£**A tree, with relational algebra operators as nodes and accesspaths as leaves

**2ï¸âƒ£**Each operator labeled with a choice of algorithm

```sql
SELECT snamefrom Sailors NATURAL JOIN Reserves
WHERE bid = 100 and rating > 5
```

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140558041.png" alt="image-20240420140558041" style="zoom:50%;" /> 

```
è®©æˆ‘ä»¬ä¸¾ä¾‹è¯´æ˜å¦‚ä½•æ„å»ºæŸ¥è¯¢è®¡åˆ’ã€‚åœ¨ä¸€ä¸ªç®€å•çš„æŸ¥è¯¢ä¸­ï¼Œæˆ‘ä»¬ä»ä¸åå¤‡äººå‘˜è‡ªç„¶è¿æ¥çš„æ°´æ‰‹ä¸­é€‰æ‹©å§“åï¼Œå…¶ä¸­IDç­‰äº10ï¼Œç­‰çº§å¤§äº5ã€‚åœ¨æˆ‘ä»¬è®¡åˆ’çš„æœ€åº•å±‚ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè‡ªç„¶è¿æ¥æ“ä½œï¼Œå…¶ä¸­æ°´æ‰‹çš„ ID ä¸åå¤‡å½¹æ°´æ‰‹çš„ ID ç›¸åŒ¹é…ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ ¹æ®ä¸¤ä¸ªè°“è¯è¿›è¡Œé€‰æ‹©ï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶ã€‚å¦‚æœè¿™äº›æ¡ä»¶éƒ½æ»¡è¶³ï¼Œæˆ‘ä»¬å°±è¿›å…¥é¢„æµ‹é˜¶æ®µã€‚è¿™ç§åˆ†å±‚è®¾ç½®ç¡®ä¿äº†æ¯ä¸ªæ“ä½œåœ¨é€»è¾‘ä¸Šéƒ½æ˜¯æœ‰åºçš„ã€‚
Letâ€™s consider an example to illustrate how we construct a query plan. Take a simple query where we select the name from sailors naturally joined with reserves, where both the ID equals 10 and the rating is greater than five. At the base of our plan, we have a natural join operation where a sailor's ID matches a reserve's sailor ID. Above this, we perform selections based on two predicates to check if the conditions are met. If these are satisfied, we proceed to the projection stage. This hierarchical setup ensures that each operation is logically and sequentially organized.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140513012.png" alt="image-20240420140513012" style="zoom:50%;" /> 

**1ï¸âƒ£**A tree, with relational algebra operators as nodes and accesspaths as leaves

**2ï¸âƒ£**Each operator labeled with a choice of algorithm

```sql
SELECT snamefrom Sailors NATURAL JOIN Reserves
WHERE bid = 100 and rating > 5
```

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140558041.png" alt="image-20240420140558041" style="zoom:50%;" /> 

```
è¦ç†è§£æŸ¥è¯¢è®¡åˆ’ä¸­çš„æ“ä½œæµç¨‹ï¼Œå¯ä»¥æŠŠå®ƒæƒ³è±¡æˆæµç»æ²³æµçš„æ°´ï¼Œå›¾å…ƒä»åº•éƒ¨å‘ä¸Šç§»åŠ¨ã€‚ä¸€å¼€å§‹ï¼Œ"æ°´æ‰‹ "è¡¨ä¸­çš„å›¾å…ƒè¢«æ‹‰ä¸Šæ¥ï¼Œæ¥ç€æ˜¯ "å‚¨å¤‡ "è¡¨ä¸­çš„å›¾å…ƒã€‚ç„¶åé€šè¿‡è¿æ¥æ“ä½œæ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ IDã€‚å¦‚æœä¸€ä¸ªå…ƒç»„ä¸ç¬¦åˆ ID å¤§äº 10 å’Œè¯„çº§è¶…è¿‡ 5 çš„åç»­æ¡ä»¶ï¼Œå®ƒå°±ä¼šè¢«ä¸¢å¼ƒã€‚å¦åˆ™ï¼Œå®ƒå°†åœ¨æˆ‘ä»¬æ‰€è¯´çš„æµæ°´çº¿--æ•°æ®å¤„ç†çš„è¿ç»­æµä¸­ç»§ç»­å‘ä¸Šè¿è¡Œã€‚
To understand the flow of operations in a query plan, think of it as water flowing through a river, where tuples move from the bottom upwards. Initially, tuples from the "sailors" table are pulled up, followed by tuples from the "reserves". These are then passed through a join operation to check for matching IDs. If a tuple fails to meet the subsequent conditions of having an ID greater than 10 and a rating over five, it is disğŸš—ded. Otherwise, it continues upwards in what we call a pipelineâ€”a continuous flow of data processing.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140513012.png" alt="image-20240420140513012" style="zoom:50%;" /> 

**1ï¸âƒ£**A tree, with relational algebra operators as nodes and accesspaths as leaves

**2ï¸âƒ£**Each operator labeled with a choice of algorithm

```sql
SELECT snamefrom Sailors NATURAL JOIN Reserves
WHERE bid = 100 and rating > 5
```

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140558041.png" alt="image-20240420140558041" style="zoom:50%;" /> 

```
æœ€åï¼Œè®¡ç®—è¿™äº›è®¡åˆ’çš„æˆæœ¬è‡³å…³é‡è¦ã€‚æˆæœ¬ä¸€èˆ¬ç”¨ I/O æ“ä½œæ•°æ¥è¡¨ç¤ºï¼Œä¸»è¦æ˜¯è®¿é—®äº†å¤šå°‘é¡µï¼Œå› ä¸ºè¿™æ˜¯æ‰§è¡ŒæŸ¥è¯¢æ—¶æœ€è€—è´¹èµ„æºçš„éƒ¨åˆ†ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œæˆæœ¬å¯ä»¥ç”¨ 500 + 500 * 1000 è¿™æ ·çš„å…¬å¼è®¡ç®—ï¼Œåˆ†åˆ«ä»£è¡¨æ°´æ‰‹è¡¨å’Œå‚¨å¤‡è¡¨çš„å¤§å°ã€‚è¿™ç§è®¡ç®—ä½¿ç”¨é¢å‘é¡µé¢çš„åµŒå¥—å¾ªç¯æ–¹æ³•ã€‚å½“å›¾å…ƒæ»¡è¶³æ¡ä»¶å¹¶åœ¨è®¡åˆ’ä¸­ç§»åŠ¨æ—¶ï¼Œæ“ä½œå°† "åœ¨è¿è¡Œä¸­ "æ‰§è¡Œï¼Œè¿™æ„å‘³ç€å®ƒä»¬å°†è¢«å®æ—¶å¤„ç†ï¼Œè€Œä¸ä¼šå­˜å‚¨å›ç£ç›˜ï¼Œä»è€Œé™ä½äº†æˆæœ¬å¹¶æé«˜äº†æ•ˆç‡ã€‚
Finally, costing these plans is crucial. Costs are generally expressed in terms of the number of I/O operations, primarily how many pages are accessed, as this is the most resource-intensive part of executing a query. Using the example, the cost might be calculated using a formula like 500 + 500 * 1000, representing the sizes of the sailors and reserves tables, respectively. This calculation uses the page-oriented nested loops approach. As tuples meet conditions and move through the plan, operations are performed "on the fly", meaning they're processed in real-time without being stored back to diskâ€”minimizing cost and enhancing efficiency.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140622885.png" alt="image-20240420140622885" style="zoom:50%;" /> 

â€¢ Overview
**â€¢ Query optimization**
â€¢ Cost estimation

```
So now let's focus on query optimization.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140704730.png" alt="image-20240420140704730" style="zoom:50%;" /> 

Sailors (**sid: integer**, sname: string, rating: integer, age: real)
Reserves (**sid: integer, bid: integer, day: dates**, rname: string)
Boats (**bid: integer,** bname: string, color: string)

```
åœ¨æ•´ä¸ªè®¨è®ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘å°†ç»§ç»­ä½¿ç”¨æ¶‰åŠæ°´æ‰‹ã€é¢„å¤‡é˜Ÿå’Œèˆ¹åªçš„æ¨¡å¼ã€‚å¦‚æœåœ¨æˆ‘æä¾›çš„ç¤ºä¾‹ä¸­å‡ºç°ä»»ä½•å›°æƒ‘ï¼Œæˆ‘é¼“åŠ±ä½ ä»¬é‡æ–°å®¡è§†è¿™ä¸€ç¤ºæ„å›¾ï¼Œä»¥æ¾„æ¸…ä»»ä½•ä¸ç¡®å®šä¹‹å¤„ã€‚è¿™ç§æ–¹æ³•åº”æœ‰åŠ©äºç¡®ä¿æˆ‘ä»¬æ¢è®¨çš„æ¦‚å¿µæ¸…æ™°æ˜“æ‡‚ã€‚
I will continue using the schema involving sailors, reserves, and boats throughout our discussions. If any confusion arises from the examples I provide, I encourage you to revisit this schema to clarify any uncertainties. This approach should help ensure that the concepts we explore are clear and understandable.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420140830855.png" alt="image-20240420140830855" style="zoom:50%;" /> 

**1ï¸âƒ£**Example:

```sql
SELECT S.sname FROM Reserves R, Sailors S
WHERE R.sid=S.sid AND R.bid=100 AND S.rating>5
```

**2ï¸âƒ£**Query optimization steps:

1. Query first broken into â€œblocksâ€
2. Each block converted to relational algebra
3. Then, for each block, several alternative **query plans** are considered
4. Plan with the lowest **estimated cost** is selected

```
æŸ¥è¯¢ä¼˜åŒ–å™¨åˆ†å››ä¸ªä¸åŒæ­¥éª¤æ‰§è¡Œä»»åŠ¡ï¼Œè¿™å¯¹ç†è§£å…¶æ•´ä½“åŠŸèƒ½è‡³å…³é‡è¦ã€‚é¦–å…ˆï¼Œæ¯ä¸ªæŸ¥è¯¢éƒ½è¢«åˆ†å‰²æˆå—ï¼Œæ¯ä¸ªå—ä»£è¡¨ä¸€ä¸ªä»¥ select å­å¥å¼€å¤´çš„ä¸åŒè¯­å¥ã€‚è¿™ç§åˆ†å‰²åœ¨å¤„ç†åµŒå¥—è¯­å¥æ—¶å°¤ä¸ºé‡è¦--ä»¥ select å¼€å¤´çš„æ¯ä¸ªä¸åŒéƒ¨åˆ†éƒ½è¢«è§†ä¸ºä¸€ä¸ªå—ã€‚å¯¹äºæ¯ä¸ªå—ï¼Œæˆ‘ä»¬å°†å…¶è½¬åŒ–ä¸ºå…³ç³»ä»£æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨å…³ç³»ä»£æ•°çš„ç­‰ä»·æ€§ï¼Œæ¢ç´¢è¯¥è¯­å¥å—çš„æ‰€æœ‰å¯èƒ½æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬å¯¹æ¯ä¸ªå¤‡é€‰æ–¹æ¡ˆçš„æˆæœ¬è¿›è¡Œè¯„ä¼°ï¼Œç„¶åä¸ºæ¯ä¸ªåŒºå—é€‰æ‹©ä¼°è®¡æˆæœ¬æœ€ä½çš„è®¡åˆ’ã€‚è¿™ä¸€è¿‡ç¨‹ä»¥å…³ç³»ä»£æ•°è§„åˆ™ä¸ºæŒ‡å¯¼åŸåˆ™ï¼ŒæŒ‰é¡ºåºä¸€ä¸ªåŒºå—ä¸€ä¸ªåŒºå—åœ°è¿›è¡Œã€‚è¯·è®°ä½ï¼Œæ‰§è¡Œé¡ºåºæ˜¯ä»æœ€å†…å±‚çš„ç¨‹åºå—å¼€å§‹ï¼Œç„¶åå‘å¤–æ¨è¿›ï¼Œæ¯æ¬¡å¤„ç†å…³ç³»ä»£æ•°å±‚æ¬¡ç»“æ„ä¸­çš„ä¸€ä¸ªé€‰æ‹©è¯­å¥ã€‚
The query optimizer performs its tasks in four distinct steps, which are crucial for understanding its overall function. Initially, each query is segmented into blocks, where each block represents a distinct statement beginning with a select clause. This segmentation is particularly important when dealing with nested statementsâ€”each distinct part that begins with select is recognized as a block. For each block, we translate it into relational algebra. Utilizing relational algebra equivalences, we then explore all possible alternatives for that block. Each alternative is assessed for its cost, and we select the plan with the lowest estimated cost for each block. This process is done sequentially, one block at a time, using relational algebra rules as guiding principles. Remember, the execution order starts with the innermost block and progresses outward, handling one select statement at a time in terms of relational algebra hierarchy.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141015293.png" alt="image-20240420141015293" style="zoom:50%;" /> 

**1ï¸âƒ£**Query block is any statement starting with select

**2ï¸âƒ£**Query block = unit of optimization

**3ï¸âƒ£**Typically inner most block is optimized first, then moving towards outers

```sql
SELECT S.sname   -- Outer block
FROM Sailors S
WHERE S.ageIN
```

```sql
(SELECT MAX (S2.age)   -- Nested block
 FROM Sailors S2
 GROUP BY S2.rating)
```

```
å°†æŸ¥è¯¢åˆ†è§£æˆä»£ç å—éå¸¸ç®€å•ã€‚åŸºæœ¬ä¸Šï¼Œæ¯å½“è¯­å¥ä»¥ select å¼€å§‹ï¼Œå°±å®šä¹‰äº†ä¸€ä¸ªæ–°çš„æŸ¥è¯¢å—ã€‚ç„¶åï¼Œè¿™ä¸ªæŸ¥è¯¢å—å°±æˆä¸ºä¸€ä¸ªä¼˜åŒ–å•å…ƒã€‚åœ¨åˆ†æè®¡åˆ’æ—¶ï¼Œè¿™äº›æŸ¥è¯¢é€šå¸¸ä¼šå˜å¾—ç›¸å½“å¤æ‚ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ‰§è¡Œè¿‡ç¨‹ä»æœ€å†…å±‚çš„ä»£ç å—å¼€å§‹ï¼Œç„¶åä¸€å±‚ä¸€å±‚å‘å¤–æ¨è¿›ã€‚è¿™ç§æœ‰æ¡ä¸ç´Šçš„æ–¹æ³•å¯ç¡®ä¿æŸ¥è¯¢çš„æ¯ä¸ªéƒ¨åˆ†éƒ½å¾—åˆ°æœ‰æ•ˆä¼˜åŒ–ï¼Œç„¶åå†è¿›å…¥ä¸‹ä¸€ä¸ªéƒ¨åˆ†ã€‚
Breaking down a query into blocks is straightforward. Essentially, each time a statement starts with a select, it defines a new block. This query block then becomes a unit of optimization. When analyzing plans, these queries can often become quite complex. Typically, the execution process begins with the innermost block and then progresses outward, one layer at a time. This methodical approach ensures that each part of the query is optimized effectively before moving on to the next.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141203095.png" alt="image-20240420141203095" style="zoom:50%;" /> 

**1ï¸âƒ£**Query:

```sql
SELECT S.sid
FROM Sailors S, Reserves R, Boats B
WHERE S.sid= R.sidAND R.bid= B.bidAND B.color= â€œredâ€
```

**2ï¸âƒ£**Relational algebra:
$$
\Pi_{S.sid} (\sigma_{B.color = ''red''} (Sailors \bowtie Reserves \bowtie Boats))
$$

```
å¯¹äºæ¯ä¸ªæ•°æ®å—ï¼Œæˆ‘ä»¬éƒ½è¦å°†å…¶è½¬æ¢ä¸ºå…³ç³»ä»£æ•°è¡¨è¾¾å¼ï¼Œè€Œè¿™æ­£æ˜¯æ‰å®ç†è§£å…³ç³»ä»£æ•°çš„å…³é”®æ‰€åœ¨ã€‚ä¸‹é¢çš„ç¤ºä¾‹å¯ä»¥è¯´æ˜è¿™ä¸€è¿‡ç¨‹ï¼šè€ƒè™‘ä¸€ä¸ªæ¶‰åŠä¸‰ä¸ªè¡¨å’Œä¸€ä¸ªæ¡ä»¶çš„é€‰æ‹©å­å¥--æ°´æ‰‹ï¼Œå…¶ä¸­æ°´æ‰‹ ID ç­‰äºåå¤‡æ°´æ‰‹ IDï¼›èˆ¹åªï¼Œå…¶ä¸­èˆ¹åª ID ç­‰äºåå¤‡èˆ¹åª IDï¼Œä¸”èˆ¹åªé¢œè‰²ä¸ºçº¢è‰²ã€‚åœ¨å…³ç³»ä»£æ•°ä¸­ï¼Œè¿™ç§è®¾ç½®è½¬åŒ–ä¸ºè¡¨ Sailorsã€Reserves å’Œ Boats ä¹‹é—´çš„è‡ªç„¶è¿æ¥ã€‚ç‰¹å®šæ¡ä»¶ "çº¢è‰² "åœ¨å…³ç³»ä»£æ•°ä¸­è¡¨ç¤ºä¸ºé€‰æ‹©æ“ä½œã€‚æœ€åï¼Œæ“ä½œä»¥æŠ•å½±ç»“æŸï¼Œåœ¨æŠ•å½±ä¸­åªé€‰æ‹©å¹¶æ˜¾ç¤ºæ°´æ‰‹ IDã€‚è¿™ä¸€ç»†åˆ†å›Šæ‹¬äº†è¿™ä¸€ç‰¹å®šæŸ¥è¯¢å—åœ¨å…³ç³»ä»£æ•°ä¸­çš„è½¬æ¢æ­¥éª¤ã€‚
For each block, we transform it into a relational algebra expression, which is where a solid understanding of relational algebra becomes crucial. Here's an example to illustrate this process: consider a select clause involving three tables and a conditionâ€”Sailor, where Sailor ID equals Reserve Sailor ID, Boat where Boat ID equals Reserves Boat ID, and the boats are colored red. In relational algebra, this setup translates into a natural join between the tables Sailors, Reserves, and Boats. The specific condition, 'color red', is represented as a selection operation in relational algebra. Finally, the operation concludes with a projection, where only the Sailor ID is selected and displayed. This breakdown encapsulates the transformation steps in relational algebra for this particular query block.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

**1ï¸âƒ£**Selections:

$\sigma_{c_1 \wedge \cdots \wedge c_n}(R) \equiv \sigma_{c_1}\left(\ldots\left(\sigma_{c_n}(R)\right)\right)$ (Cascade)

$\sigma_{c_1}\left(\sigma_{c_2}(R)\right) \equiv \sigma_{c_2}\left(\sigma_{c_1}(R)\right)$ (Commute)

**2ï¸âƒ£**Projections: 

$\pi_{a_1}(R) \equiv \pi_{a_1}\left(\ldots\left(\pi_{a_n}(R)\right)\right)$ (Cascade) 

$a_i$ is a set of attributes of $\mathrm{R}$ and $a_i \subseteq a_{i+1}$ for $i=1 \ldots n-1$â€‹

**3ï¸âƒ£**These equivalences allow us to 'push' selections and projections ahead of joins.

```
åœ¨ä¼˜åŒ–æŸ¥è¯¢çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šæ¢ç´¢å…³ç³»ä»£æ•°ç­‰ä»·å…³ç³»ï¼Œä»¥ç¡®å®šä¸åŒçš„å¯æ‰§è¡Œè®¡åˆ’ã€‚å…³ç³»ç†è®ºç¡®ä¿æ— è®ºæˆ‘ä»¬é€‰æ‹©å“ªç§æ–¹æ¡ˆï¼Œç»“æœéƒ½èƒ½ä¿æŒä¸€è‡´ã€‚è¿™ç§å¯é æ€§æºäºå…³ç³»ä»£æ•°çš„ä¸€äº›åŸºæœ¬è§„åˆ™ï¼Œå®ƒä»¬ä¸ºæˆ‘ä»¬æä¾›äº†æ“ä½œå’Œè¯•éªŒå„ç§å¤‡é€‰æ–¹æ¡ˆçš„çµæ´»æ€§ã€‚æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨è¿™äº›è§„åˆ™ï¼Œå°¤å…¶æ˜¯å®ƒä»¬å¦‚ä½•åº”ç”¨äºæŸ¥è¯¢è®¡åˆ’ä¸­çš„é€‰æ‹©ã€‚
In the process of optimizing queries, we explore relational algebra equivalences to identify different executable plans. Relational theory ensures that no matter which option we choose, the result remains consistent. This reliability stems from a few fundamental rules of relational algebra that provide us with the flexibility to manipulate and experiment with various alternatives. We are about to dive into these rules, particularly focusing on how they apply to selections in query plans.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

**1ï¸âƒ£**Selections:

$\sigma_{c_1 \wedge \cdots \wedge c_n}(R) \equiv \sigma_{c_1}\left(\ldots\left(\sigma_{c_n}(R)\right)\right)$ (Cascade)

$\sigma_{c_1}\left(\sigma_{c_2}(R)\right) \equiv \sigma_{c_2}\left(\sigma_{c_1}(R)\right)$ (Commute)

**2ï¸âƒ£**Projections: 

$\pi_{a_1}(R) \equiv \pi_{a_1}\left(\ldots\left(\pi_{a_n}(R)\right)\right)$ (Cascade) 

$a_i$ is a set of attributes of $\mathrm{R}$ and $a_i \subseteq a_{i+1}$ for $i=1 \ldots n-1$â€‹

**3ï¸âƒ£**These equivalences allow us to 'push' selections and projections ahead of joins.

```
ç¬¬ä¸€å¥—è§„åˆ™æ¶‰åŠé€‰æ‹©çš„åº”ç”¨ã€‚è¿™é‡Œæœ‰ä¸¤æ¡ä¸»è¦è§„åˆ™ï¼šé€‰æ‹©é¡¹å¯ä»¥çº§è”æ–¹å¼æˆ–äº¤æ¢æ–¹å¼åº”ç”¨ã€‚å¯¹äºçº§è”é€‰æ‹©ï¼Œå¯ä»¥æƒ³è±¡ä¸€ç³»åˆ—æ¡ä»¶ï¼Œä¾‹å¦‚å¹´é¾„å¤§äº 5 å²å’Œè¯„åˆ†å¤§äº 7 åˆ†ã€‚æ— è®ºè¿™äº›æ¡ä»¶æ˜¯åœ¨è¡¨ä¸­ä¸€æ¬¡æ€§åº”ç”¨ï¼Œè¿˜æ˜¯ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°é¡ºåºåº”ç”¨ï¼Œç»“æœéƒ½æ˜¯ä¸€æ ·çš„ã€‚ç¬¦åˆè¿™äº›æ¡ä»¶çš„è®°å½•å°†æ˜¯ç›¸åŒçš„ï¼Œè¿™è¡¨æ˜äº†é€‰æ‹©çš„çº§è”æ€§è´¨ã€‚å¦ä¸€æ–¹é¢ï¼Œé€‰æ‹©çš„äº¤æ¢è§„åˆ™è¡¨æ˜ï¼Œæ¡ä»¶çš„é¡ºåºä¸ä¼šå½±å“ç»“æœã€‚ä¾‹å¦‚ï¼Œæ— è®ºæ˜¯å…ˆåº”ç”¨ "æ¡ä»¶ä¸€"ï¼Œå†åº”ç”¨ "æ¡ä»¶äºŒ"ï¼Œè¿˜æ˜¯å…ˆåº”ç”¨ "æ¡ä»¶äºŒ"ï¼Œå†åº”ç”¨ "æ¡ä»¶ä¸€"ï¼Œåˆæ ¼è®°å½•çš„é›†åˆéƒ½ä¸ä¼šæ”¹å˜ã€‚è¿™ä¸€è§„åˆ™å‡¸æ˜¾äº†å…³ç³»ä»£æ•°åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­æŠ½è±¡è€Œå¼ºå¤§çš„ç‰¹æ€§ã€‚
The first set of rules involves the application of selections. There are two main rules here: selections can be applied in a cascade or in a commutative manner. For cascading selections, imagine a series of conditionsâ€”such as age greater than five and rating greater than seven. Whether these conditions are applied all at once over a table or sequentially, one after another, the outcome is the same. The records that meet these criteria will be the same, demonstrating the cascading nature of selections. On the other hand, the commutative rule of selections shows that the order of conditions does not affect the result. For example, whether we apply 'condition one' followed by 'condition two', or 'condition two' followed by 'condition one', the set of qualifying records remains unchanged. This rule highlights the abstract yet powerful nature of relational algebra in query optimization.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420214207261.png" alt="image-20240420214207261" style="zoom: 67%;" /> 

```
ä¸¾ä¸ªä¾‹å­æ¥è¯´æ˜ï¼Œè®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹ "æ°´æ‰‹ "è¡¨ï¼Œå¹¶åº”ç”¨ä¸€äº›æ¡ä»¶ï¼šé€‰æ‹©å¹´é¾„å¤§äº 50 ä¸”ç­‰çº§ç­‰äº 10 çš„æ°´æ‰‹ã€‚åœ¨å…³ç³»ä»£æ•°ä¸­ï¼Œå¯ä»¥è¿™æ ·å¤„ç†ï¼šé¦–å…ˆæ ¹æ®å¹´é¾„ç­›é€‰æ°´æ‰‹ï¼Œç„¶åå°†è¿™äº›ç»“æœå‘å‰æ¨ï¼Œéšåæ£€æŸ¥ä»–ä»¬çš„è¯„çº§ã€‚ç”±äºè¿™äº›è¿ç®—çš„äº¤æ¢å±æ€§ï¼Œè¿™ä¸ªé¡ºåºå®é™…ä¸Šç­‰åŒäºå…ˆæ£€æŸ¥ç­‰çº§ï¼Œå†æ£€æŸ¥å¹´é¾„ï¼›æ¡ä»¶çš„é¡ºåºä¸ä¼šå½±å“æœ€ç»ˆç»“æœã€‚æ— è®ºé‡‡ç”¨å“ªç§æ–¹å¼ï¼Œè¾“å‡ºç»“æœéƒ½ä¿æŒä¸€è‡´ï¼Œè¿™è¡¨æ˜è¿™ä¸¤ç§æ–¹æ³•æ˜¯ç­‰ä»·çš„ï¼Œå¹¶éªŒè¯äº†å¤„ç†æŸ¥è¯¢æ¡ä»¶çš„çµæ´»æ€§ã€‚
To illustrate with an example, let's consider our table 'sailors' and apply some conditions: select sailors where age is greater than 50 and rating equals 10. In relational algebra, this could be approached by first filtering sailors based on age, then pushing those results forward, and subsequently checking their rating. This sequence is effectively equivalent to checking the rating first and then age due to the commutative property of these operations; the order of the conditions doesnâ€™t impact the final result. Either way, the output remains consistent, demonstrating that both approaches are equivalent and validate the flexibility in processing query conditions.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

**1ï¸âƒ£**Selections:

$\sigma_{c_1 \wedge \cdots \wedge c_n}(R) \equiv \sigma_{c_1}\left(\ldots\left(\sigma_{c_n}(R)\right)\right)$ (Cascade)

$\sigma_{c_1}\left(\sigma_{c_2}(R)\right) \equiv \sigma_{c_2}\left(\sigma_{c_1}(R)\right)$ (Commute)

**2ï¸âƒ£**Projections: 

$\pi_{a_1}(R) \equiv \pi_{a_1}\left(\ldots\left(\pi_{a_n}(R)\right)\right)$ (Cascade) 

$a_i$ is a set of attributes of $\mathrm{R}$ and $a_i \subseteq a_{i+1}$ for $i=1 \ldots n-1$â€‹

**3ï¸âƒ£**These equivalences allow us to 'push' selections and projections ahead of joins.

```
åœ¨æŠ•å½±æ–¹é¢ï¼Œæœ‰ä¸€ç§æ¶‰åŠçº§è”æŠ•å½±çš„å¾®å¦™æŠ€æœ¯ã€‚å…¶åŸç†éå¸¸ç®€å•ï¼šå¦‚æœæœ‰ä¸€è¿ä¸²çš„æŠ•å½±ï¼Œé‚£ä¹ˆæ¯ä¸€ä¸ªåç»­æŠ•å½±éƒ½å¿…é¡»æ¶‰åŠå‰ä¸€ä¸ªæŠ•å½±ä¸­åŒ…å«çš„åˆ—çš„å­é›†ã€‚è¿™ç§æ–¹æ³•ä¹çœ‹ä¹‹ä¸‹å¯èƒ½åƒå¤æ‚çš„æ•°å­¦ï¼Œä½†å¦‚æœè€ƒè™‘åˆ°æ•°æ®åº“è¡¨çš„ç»“æ„å’ŒåŠŸèƒ½ï¼Œå®ƒå®é™…ä¸Šæ˜¯éå¸¸åˆä¹é€»è¾‘çš„ã€‚é€šè¿‡ç¡®ä¿æ¯ä¸ªæŠ•å½±æ¯”ä¸Šä¸€ä¸ªæŠ•å½±æ›´èƒ½ç¼©å°ç„¦ç‚¹ï¼Œæˆ‘ä»¬å°±èƒ½æœ‰æ•ˆåœ°é€æ­¥å®Œå–„æ•°æ®è¾“å‡ºã€‚
Moving on to projection, there's a nuanced technique involving cascading projections. The principle here is quite straightforward: if you have a sequence of projections, each subsequent projection must involve a subset of the columns included in the previous one. This approach, which might seem like complex math at first glance, is actually quite logical when you consider the structure and function of database tables. By ensuring each projection narrows the focus more than the last, we efficiently refine the data output step-by-step.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420214723572.png" alt="image-20240420214723572" style="zoom: 33%;" /> 

```
è®©æˆ‘ä»¬ä¸¾ä¾‹è¯´æ˜çº§è”é¢„æµ‹çš„æ¦‚å¿µã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º "æ°´æ‰‹ "çš„è¡¨ï¼Œå…¶ä¸­åŒ…å« IDã€å¹´é¾„ã€å§“åã€æ’åç­‰å¤šåˆ—ã€‚åœ¨ç¬¬ä¸€æ¬¡æŠ•å½±ä¸­ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å†³å®šåªä¿ç•™å‰ä¸‰åˆ—--IDã€Age å’Œ Nameã€‚è¿™æ ·ä¸€æ¥ï¼Œæˆ‘ä»¬å®é™…ä¸Šå°±èˆå¼ƒäº†åŒ…æ‹¬æ’ååœ¨å†…çš„å…¶ä»–åˆ—ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ä»ç¬¬ä¸€åˆ—çº§è”åº”ç”¨ç¬¬äºŒåˆ—æŠ•å½±ï¼Œæˆ‘ä»¬å°±åªèƒ½ä½¿ç”¨åˆå§‹æŠ•å½±ä¸­ä¿ç•™çš„åˆ—ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¸èƒ½å°† "æ’å "åŒ…å«åœ¨åç»­çš„é¢„æµ‹ä¸­ï¼Œå› ä¸ºå®ƒæ²¡æœ‰åŒ…å«åœ¨ç¬¬ä¸€æ¬¡é¢„æµ‹ä¸­ã€‚ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©åªé¢„æµ‹ "å§“å"ï¼Œå› ä¸ºå®ƒä»ç„¶å¯ä»¥ä»ä¸Šä¸€ä¸ªé¢„æµ‹çš„è¾“å‡ºä¸­è·å¾—ã€‚è¿™ç§æŠ€æœ¯ç¡®ä¿äº†æ¯ä¸ªåç»­æŠ•å½±åªèƒ½ä½¿ç”¨å‰ä¸€ä¸ªæŠ•å½±ä¸­å¯ç”¨åˆ—çš„å­é›†ï¼Œè¿™æ˜¯ç†è§£çº§è”æŠ•å½±çš„å…³é”®æ‰€åœ¨ã€‚
Let's explore an example to illustrate the concept of cascading projections. Imagine we have a table called 'sailors' with multiple columns such as ID, Age, Name, Ranking, and others. In our first projection, we decide to keep only the first three columnsâ€”ID, Age, and Nameâ€”for simplicity. By doing this, we have effectively disğŸš—ded the other columns, including Ranking. Now, if we wish to apply a second projection cascading from the first, we are limited to using only the columns retained from the initial projection. For instance, we cannot include Ranking in our subsequent projection since it was not included in the first projection. However, we could choose to project only the Name if desired, as it remains available from the previous projection's output. This technique ensures that each subsequent projection can only work with a subset of the columns available from the prior one, which is the key to understanding cascading projections.
```
$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141428733.png" alt="image-20240420141428733" style="zoom:50%;" /> 

**1ï¸âƒ£**Selections:

$\sigma_{c_1 \wedge \cdots \wedge c_n}(R) \equiv \sigma_{c_1}\left(\ldots\left(\sigma_{c_n}(R)\right)\right)$ (Cascade)

$\sigma_{c_1}\left(\sigma_{c_2}(R)\right) \equiv \sigma_{c_2}\left(\sigma_{c_1}(R)\right)$ (Commute)

**2ï¸âƒ£**Projections: 

$\pi_{a_1}(R) \equiv \pi_{a_1}\left(\ldots\left(\pi_{a_n}(R)\right)\right)$ (Cascade) 

$a_i$ is a set of attributes of $\mathrm{R}$ and $a_i \subseteq a_{i+1}$ for $i=1 \ldots n-1$â€‹

**3ï¸âƒ£**These equivalences allow us to 'push' selections and projections ahead of joins.

```
ç°åœ¨ï¼Œè¿™äº›ç­‰ä»·å…³ç³»æœ¬è´¨ä¸Šå…è®¸æˆ‘ä»¬å°†é€‰æ‹©æˆ–é¢„æµ‹æ¨åˆ°ç¼æ–¯çš„å‰é¢ï¼Œæœ¬è´¨ä¸Šæ˜¯åœ¨ç©å¦ç±»æ¸¸æˆã€‚
Now these equivalences essentially allow us to push selection or projection ahead of Jones essentially to play with the alternatives. 
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141906601.png" alt="image-20240420141906601" style="zoom:50%;" /> 

**1ï¸âƒ£**Selection: 
$
\begin{aligned}
& \sigma_{\text {age }<18 \wedge \text { rating }>5} \text { (Sailors) } \\
& \leftrightarrow \sigma_{\text {age }<18}\left(\sigma_{\text {rating }>5}\right. \text { (Sailors)) } \\
& \leftrightarrow \sigma_{\text {rating }>5}\left(\sigma_{\text {age }<18}(\text { Sailors })\right) \\
&
\end{aligned}
$

```
åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æœ€åˆå°†æŠ•å½±å‘ä¸‹æ¨ï¼Œä½†æ— æ„ä¸­ä¸¢å¤±äº† "è¯„çº§"ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬åœ¨åç»­è¿æ¥ä¸­è¯„ä¼°æ¡ä»¶æ—¶æ— æ³•ä½¿ç”¨è¿™ä¸ªå­—æ®µã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨å…³ç³»ä»£æ•°ä¸­ï¼Œè¿æ¥æ—¢æ˜¯å…³è”çš„ï¼Œä¹Ÿæ˜¯äº¤æ¢çš„ã€‚è¿™ç§çµæ´»æ€§å…è®¸æˆ‘ä»¬åœ¨ä¸æ”¹å˜ç»“æœçš„æƒ…å†µä¸‹é‡æ–°å®‰æ’è¿æ¥ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆåœ¨è¡¨ S å’Œè¡¨ T ä¹‹é—´æ‰§è¡Œè¿æ¥ï¼Œç„¶åå°†ç»“æœä¸è¡¨ R è¿æ¥ï¼Œæˆ–è€…ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å…ˆè¿æ¥ R å’Œ Sï¼Œç„¶åå†æ•´åˆ Tã€‚æ— è®ºå“ªç§æƒ…å†µï¼Œæœ€ç»ˆç»“æœéƒ½æ˜¯ä¸€è‡´çš„ï¼Œè¿™å±•ç¤ºäº†è¿™äº›å…³ç³»ä»£æ•°ç‰¹æ€§åœ¨ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œæ–¹é¢çš„å¼ºå¤§åŠŸèƒ½ã€‚
In this example, we initially push the projection down but inadvertently lose the 'rating', which means we can't use this field when evaluating conditions in subsequent joins. It's important to note that in relational algebra, joins are both associative and commutative. This flexibility allows us to rearrange the joins without altering the outcome. For instance, we can first perform a join between tables S and T, and then join the result with table R, or alternatively, we could start by joining R and S and then integrate T. In either scenario, the final result remains consistent, showcasing the power of these relational algebra properties in optimizing query execution.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141906601.png" alt="image-20240420141906601" style="zoom:50%;" /> 

**1ï¸âƒ£**Selection: 
$
\begin{aligned}
& \sigma_{\text {age }<18 \wedge \text { rating }>5} \text { (Sailors) } \\
& \leftrightarrow \sigma_{\text {age }<18}\left(\sigma_{\text {rating }>5}\right. \text { (Sailors)) } \\
& \leftrightarrow \sigma_{\text {rating }>5}\left(\sigma_{\text {age }<18}(\text { Sailors })\right) \\
&
\end{aligned}
$
**2ï¸âƒ£**Projection:

1. No: $
   \pi_{\text {age,rating }}(\text { Sailors }) \leftrightarrow \pi_{\text {age}}\left(\pi_{\text {rating}}(\text { Sailors })\right)
   $

2. Yes: $
   \pi_{\text {age,rating }}(\text { Sailors }) \leftrightarrow \pi_{\text {age,rating }}\left(\pi_{\text {age,rating,sid }}(\text { Sailors })\right)
   $

```
è€ƒè™‘å…³ç³»ä»£æ•°ä¸­çš„ä¸€ç§æƒ…å†µï¼šæˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªè°“è¯çš„é€‰æ‹©æ“ä½œï¼šå¹´é¾„å°äº 18 å²å’Œè¯„åˆ†å¤§äº 5 åˆ†ã€‚è¿™å¯ä»¥é€šè¿‡åˆ†åˆ«æ£€æŸ¥æ¯ä¸ªæ¡ä»¶æ¥æ‰§è¡Œï¼Œä»è€Œå±•ç¤ºçº§è”è§„åˆ™çš„åº”ç”¨ã€‚å¦å¤–ï¼Œç”±äºå…³ç³»ä»£æ•°çš„äº¤æ¢å±æ€§ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æŒ‰ç…§ä»»æ„é¡ºåºåº”ç”¨è¿™äº›æ¡ä»¶ï¼Œä»è€Œè¯´æ˜åº”ç”¨æ¡ä»¶çš„é¡ºåºä¸ä¼šå½±å“ç»“æœã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½èƒ½ç¡®ä¿ç»“æœä¿æŒä¸€è‡´ï¼Œçªå‡ºäº†å…³ç³»ä»£æ•°ç­‰ä»·çš„çµæ´»æ€§å’Œå¼ºå¤§åŠŸèƒ½ã€‚
Consider a scenario in relational algebra where we have a selection operation with two predicates: age less than 18 and rating greater than five. This can be executed by checking each condition separately, demonstrating the application of cascading rules. Alternatively, we can apply these conditions in any order due to the commutative property of relational algebra, illustrating that the sequence in which conditions are applied does not impact the outcome. Both methods ensure that the result remains consistent, highlighting the flexibility and power of relational algebra equivalences.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420141906601.png" alt="image-20240420141906601" style="zoom:50%;" /> 

**1ï¸âƒ£**Selection: 
$
\begin{aligned}
& \sigma_{\text {age }<18 \wedge \text { rating }>5} \text { (Sailors) } \\
& \leftrightarrow \sigma_{\text {age }<18}\left(\sigma_{\text {rating }>5}\right. \text { (Sailors)) } \\
& \leftrightarrow \sigma_{\text {rating }>5}\left(\sigma_{\text {age }<18}(\text { Sailors })\right) \\
&
\end{aligned}
$
**2ï¸âƒ£**Projection:

1. No: $
   \pi_{\text {age,rating }}(\text { Sailors }) \leftrightarrow \pi_{\text {age}}\left(\pi_{\text {rating}}(\text { Sailors })\right)
   $

2. Yes: $
   \pi_{\text {age,rating }}(\text { Sailors }) \leftrightarrow \pi_{\text {age,rating }}\left(\pi_{\text {age,rating,sid }}(\text { Sailors })\right)
   $

```
æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªæ¶‰åŠæŠ•å½±çš„æ›´å¤æ‚çš„ä¾‹å­ã€‚å‡è®¾æˆ‘ä»¬å¯¹æ•°æ®é›†ä¸­çš„ "å¹´é¾„ "å’Œ "è¯„åˆ† "è¿›è¡Œäº†æŠ•å½±ï¼Œä½†å´åªå¯¹ "è¯„åˆ† "è¿›è¡Œäº†ä¸€è¿ä¸²çš„æŠ•å½±ã€‚è¿™ä¼šå¯¼è‡´ "å¹´é¾„ "æ•°æ®ä¸¢å¤±ï¼Œä»è€Œæ— æ³•åœ¨åç»­æ“ä½œä¸­å¼•ç”¨ "å¹´é¾„ "æ•°æ®ã€‚è¿™ç§æƒ…å†µæ¸…æ¥šåœ°è¡¨æ˜ï¼Œå½“å±æ€§åœ¨åºåˆ—æ—©æœŸè¢«æ¶ˆé™¤æ—¶ï¼ŒæŠ•å½±å¹¶ä¸æ€»æ˜¯ç­‰ä»·çš„ã€‚ä¸ºäº†åœ¨æ•´ä¸ªæŸ¥è¯¢è¿‡ç¨‹ä¸­æœ‰æ•ˆç®¡ç†æ•°æ®å±æ€§ï¼Œå¯ä»¥å…ˆé¢„æµ‹ "å¹´é¾„"ã€"è¯„çº§ "å’Œ "ID"ï¼Œç„¶åå†åº”ç”¨ä¸€ä¸ªä¿ç•™ "å¹´é¾„ "å’Œ "è¯„çº§ "çš„æ¡ä»¶ã€‚è¿™ç§æ–¹æ³•å¯ç¡®ä¿æœ€ç»ˆè¾“å‡ºä¿æŒä¸å˜ï¼Œä»è€Œå¼ºè°ƒäº†ä»”ç»†è€ƒè™‘æŸ¥è¯¢è®¡åˆ’ä¸­æ¯ä¸ªæ“ä½œçš„è¾“å‡ºçš„å¿…è¦æ€§ã€‚
Next, letâ€™s examine a more complex example involving projection. Suppose we project 'age' and 'rating' from a dataset but then attempt to apply a cascade of projections, focusing only on 'rating'. This results in a loss of the 'age' data, making it impossible to reference 'age' in subsequent operations. This scenario clearly shows that projections are not always equivalent when attributes are eliminated early in the sequence. To effectively manage data attributes throughout the query process, one could initially project 'age', 'rating', and 'ID', then apply a further condition that retains 'age' and 'rating'. This approach ensures that the final output remains unchanged, emphasizing the need to ğŸš—efully consider the output of each operation in a query plan.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143028677.png" alt="image-20240420143028677" style="zoom:50%;" /> 

**1ï¸âƒ£**A projection commutes with a selection that only uses attributes retained by the projection

1. Yes

$
\begin{aligned}
& \pi_{\text {age, rating, sid }}\left(\sigma_{\text {age }<18 \wedge \text { rating }>5}(\text { Sailors })\right) \\
& \leftrightarrow \sigma_{\text {age }<18 \wedge \text { rating }>5}\left(\pi_{\text {age, rating, sid }}(\text { Sailors })\right)
\end{aligned}
$

```
æŠ•å½±çš„ç¡®å¯ä»¥ä¸é€‰æ‹©æ¢ç®—ï¼Œä½†è¿™åªæœ‰åœ¨é€‰æ‹©æ¶‰åŠåˆ°æŠ•å½±æ‰€ä¿ç•™çš„å±æ€§æ—¶æ‰å¯è¡Œã€‚åœ¨æˆ‘ä»¬è®¨è®ºçš„ä¾‹å­ä¸­ï¼Œç­–ç•¥æ˜¯åœ¨æ‰§è¡Œé€‰æ‹©ä¹‹å‰ç¿»è½¬é¡ºåºå¹¶åº”ç”¨æŠ•å½±ã€‚è¿™é‡Œçš„å…³é”®æ˜¯æ£€æŸ¥å¿…è¦çš„å±æ€§ï¼ˆå¦‚å¹´é¾„å’Œè¯„çº§ï¼‰æ˜¯å¦ä¿ç•™åœ¨æŠ•å½±åˆ—è¡¨ä¸­ã€‚å¹¸è¿çš„æ˜¯ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œè¯„åˆ†åœ¨æŠ•å½±ä¸­å¾—åˆ°äº†ä¿ç•™ï¼Œå› æ­¤é‡æ–°æ’åˆ—æ˜¯æœ‰æ•ˆçš„ã€‚è¿™ç§æ–¹æ³•è¡¨æ˜ï¼Œä»”ç»†è§„åˆ’æŠ•å½±ä¸­åŒ…å«çš„å±æ€§å¯ä»¥å®ç°çµæ´»é«˜æ•ˆçš„æŸ¥è¯¢ä¼˜åŒ–ã€‚
Projection can indeed commute with a selection, but this is only feasible if the selection involves attributes that are preserved by the projection. In the example we are discussing, the strategy was to flip the order and apply projection before performing the selection. The crucial check here is whether the necessary attributes, like age and rating, are retained in the projection list. Fortunately, in this case, rating has been preserved in the projection, making this rearrangement valid. This approach shows how ğŸš—eful planning of attribute inclusion in projections can enable flexible and efficient query optimization.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143028677.png" alt="image-20240420143028677" style="zoom:50%;" /> 

**1ï¸âƒ£**A projection commutes with a selection that only uses attributes retained by the projection

1. Yes

$
\begin{aligned}
& \pi_{\text {age, rating, sid }}\left(\sigma_{\text {age }<18 \wedge \text { rating }>5}(\text { Sailors })\right) \\
& \leftrightarrow \sigma_{\text {age }<18 \wedge \text { rating }>5}\left(\pi_{\text {age, rating, sid }}(\text { Sailors })\right)
\end{aligned}
$

2. No

$
\begin{aligned}
& \pi_{\text {age, rating, sid }}\left(\sigma_{\text {age }<18 \wedge \text { rating }>5}(\text { Sailors })\right) \\
& \leftrightarrow \sigma_{\text {age }<18 \wedge \text { rating }>5}\left(\pi_{\text {age, sid }}(\text { Sailors })\right)
\end{aligned}
$

```
ä¸‹é¢æ˜¯å¦ä¸€ä¸ªå¸¸è§çš„ç»Šå€’å­¦ç”Ÿçš„ä¾‹å­--é€šè¿‡ç¿»è½¬å¹¶å°†æŠ•å½±æ¨åˆ°åºåˆ—çš„å‰é¢ï¼Œè¯•å›¾åˆ©ç”¨ç­‰ä»·åŸç†ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•ä¼šå¯¼è‡´ "è¯„çº§ "å±æ€§ä¸¢å¤±ã€‚å› æ­¤ï¼Œç”±äº "ç­‰çº§ "ä¸å†å¯ç”¨ï¼Œæˆ‘ä»¬åœ¨è¿›è¡Œè¿æ¥æ—¶å°±æ— æ³•åœ¨æ¡ä»¶ä¸­åº”ç”¨å®ƒã€‚è¿™è¯´æ˜äº†ä¸€ä¸ªå…³é”®ç‚¹ï¼šåœ¨é‡æ–°æ’åºæ“ä½œæ—¶ï¼Œéœ€è¦ç¡®ä¿ä¿ç•™æ‰€æœ‰å¿…è¦çš„å±æ€§ï¼Œä»¥é¿å…å¯¼è‡´æŸäº›æ¡ä»¶æ— æ³•æ£€æŸ¥ï¼Œä»è€Œå½±å“æŸ¥è¯¢çš„æ­£ç¡®æ€§ã€‚
Here's another example that commonly trips up studentsâ€”it involves an attempt to utilize the equivalence principle by flipping and pushing the projection ahead in the sequence. However, this maneuver results in the loss of the 'rating' attribute. Consequently, because 'rating' is no longer available, we are unable to apply it in conditions when performing joins. This illustrates a crucial point: the need to ensure that all necessary attributes are retained when reordering operations to avoid rendering certain conditions uncheckable and potentially compromising the query's correctness.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143310274.png" alt="image-20240420143310274" style="zoom:50%;" /> 

$
\begin{array}{ll}
R \bowtie(S \bowtie T) \equiv(R \bowtie S) \bowtie T & \text { (Associative) } \\
(R \bowtie S) \equiv(S \bowtie R) & \text { (Commutative) }
\end{array}
$â€‹
These equivalences allow us to choose **different join orders**

```
å…³ç³»ä»£æ•°ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›æœ‰ç”¨çš„å±æ€§ï¼Œå¦‚è¿æ¥çš„å…³è”æ€§å’Œäº¤æ¢æ€§ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥çµæ´»å®‰æ’è¡¨è¾¾å¼ä¸­çš„è¿æ¥æ“ä½œã€‚è¯•æƒ³ä¸€ä¸‹åµŒå¥—è¿æ¥--æœ€å†…å±‚çš„æ‹¬å·å…ˆè¢«è®¡ç®—ã€‚ä½†æ˜¯ï¼Œåˆ©ç”¨å…³è”æ€§ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å…ˆæ‰§è¡Œ S å’Œ T ä¹‹é—´çš„è¿æ¥ï¼Œç„¶åå°†ç»“æœä¸ R è¿æ¥ï¼Œæˆ–è€…åä¹‹äº¦ç„¶--é¡ºåºä¸ä¼šå½±å“æœ€ç»ˆç»“æœã€‚åŒæ ·ï¼Œäº¤æ¢æ€§å…è®¸æˆ‘ä»¬äº¤æ¢è¿æ¥çš„é¡ºåºï¼ˆS è¿æ¥ R ä¸ R è¿æ¥ S æ˜¯ä¸€æ ·çš„ï¼‰ã€‚è¿™ç§çµæ´»æ€§å¯¹äºä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’è‡³å…³é‡è¦ã€‚ä¸åŒçš„è¿æ¥é¡ºåºä¼šå¯¼è‡´æ‰§è¡Œæˆæœ¬çš„æ˜¾è‘—å˜åŒ–ã€‚æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨è¿æ¥é¡ºåºå’Œæ‰§è¡Œé€‰æ‹©å¦‚ä½•å½±å“æŸ¥è¯¢è®¡åˆ’åŠå…¶ç›¸å…³æˆæœ¬ã€‚
Relational algebra offers us some helpful properties like associativity and commutativity for joins. This means we have flexibility in how we arrange join operations within an expression.  Imagine nested joins â€“ the innermost set of brackets gets evaluated first. But with associativity, we can choose to perform the join between S and T first, then join the result with R, or vice versa â€“ the order doesn't affect the final outcome. Similarly, commutativity allows us to swap the order of joins (S join R is the same as R join S). This flexibility is crucial for optimizing query plans. Different join orders can lead to significant cost variations in execution. We'll delve deeper into how join order and implementation choices impact query plans and their associated costs.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143458457.png" alt="image-20240420143458457" style="zoom:50%;" /> 

**1ï¸âƒ£**Converting selection + cross-product to join

$
\begin{aligned}
\sigma_{\text {S.sid }=\text { R.sid }} & (\text { Sailors } \times \text { Reserves }) \\
& \leftrightarrow \text { Sailors } \bowtie_{\text {S.sid }=\text { R.sid }} \text { Reserves }
\end{aligned}
$â€‹

```
å› æ­¤ï¼Œä»æœ¬è´¨ä¸Šè®²ï¼Œä¼˜åŒ–å™¨è¦åšçš„å°±æ˜¯ç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½éµå®ˆç­‰ä»·è§„åˆ™ï¼Œä»è€Œä¿ç•™ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†ä¸åŒçš„æ“ä½œç»“åˆèµ·æ¥ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯åœ¨åº”ç”¨è¿™äº›ç­‰ä»·è§„åˆ™ï¼Œä»¥ç¡®ä¿ä¸ä¼šä¸¢å¤±ä»»ä½•ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå¸¦åç»­æ¡ä»¶çš„äº¤ä¹˜ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯è½¬åŒ–ä¸ºè‡ªç„¶è¿æ¥ã€‚è¿™ä¸€ç‚¹è‡³å…³é‡è¦ï¼Œå› ä¸ºåœ¨ SQL ç¬¦å·ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæŒ‡å®šè¡¨åå’Œè¿æ¥æ¡ä»¶ï¼Œè¿™ç±»ä¼¼äºå¸¦æ¡ä»¶çš„äº¤å‰ä¹˜ç§¯ã€‚ä¸è¿‡ï¼Œæˆ‘ç›¸ä¿¡ä¼˜åŒ–å™¨æœ‰èƒ½åŠ›ä¸æ‰§è¡Œä»£ä»·é«˜æ˜‚çš„äº¤å‰ä¹˜ç§¯ã€‚ä¸ºä»€ä¹ˆå‘¢ï¼Ÿå› ä¸ºæˆ‘äº†è§£å…³ç³»ä»£æ•°çš„ç­‰ä»·å…³ç³»ï¼Œè€Œä¸”æˆ‘çŸ¥é“ä¼˜åŒ–å™¨ä¼šå°†æ­¤ç±»æ“ä½œæ”¹å†™æˆæ›´æœ‰æ•ˆçš„å½¢å¼ï¼Œæ¯”å¦‚è‡ªç„¶è¿æ¥ã€‚å› æ­¤ï¼Œæœ‰äº†è¿™ç§ç†è§£ï¼Œæˆ‘ç›¸ä¿¡ä¼˜åŒ–å™¨ä¼šå°½å¯èƒ½ç”Ÿæˆæœ€å¥½çš„è®¡åˆ’ã€‚
So, in essence, what the optimizer does is ensure that all operations adhere to the rules of equivalence, thereby preserving information. For instance, consider the case of combining different operations. Here, we're essentially applying these equivalence rules to ensure that no information is lost. Take, for example, the cross product with a subsequent condition, which is essentially transformed into a natural join. This is crucial because, in SQL notation, we often specify table names and join conditions, resembling a cross product with conditions. However, I'm confident in the optimizer's ability not to execute costly cross products. Why? Because I understand relational algebra equivalences, and I know the optimizer will rewrite such operations into more efficient forms, like a natural join. So, with this understanding, I trust that the optimizer will generate the best plan possible.
```
$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143458457.png" alt="image-20240420143458457" style="zoom:50%;" /> 

**1ï¸âƒ£**Converting selection + cross-product to join

$
\begin{aligned}
\sigma_{\text {S.sid }=\text { R.sid }} & (\text { Sailors } \times \text { Reserves }) \\
& \leftrightarrow \text { Sailors } \bowtie_{\text {S.sid }=\text { R.sid }} \text { Reserves }
\end{aligned}
$â€‹
**2ï¸âƒ£**Selection on just attributes of S commutes with $\text{R}\bowtie\text{S}$â€‹

$
\begin{aligned}
\sigma_{S.age<18} & (\text{Sailors} \bowtie_{S.sid = R.sid} \text{Reserves})\\
& \leftrightarrow
(\sigma_{S.age<18} (\text{Sailors})) \bowtie_{S.sid = R.sid} \text{Reserves}
\end{aligned}
$

```
æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é‡‡ç”¨ä¸‹æ¨é€‰æ‹©çš„ç­–ç•¥ï¼Œç¡®ä¿å§‹ç»ˆä¿ç•™æˆ‘ä»¬éœ€è¦çš„å±æ€§ã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯å…ˆæ‰§è¡Œè¿æ¥ï¼Œç„¶åå†åº”ç”¨é€‰æ‹©ï¼Œè€Œæ˜¯å°†é€‰æ‹©ä¸‹æ¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å…ˆæ£€æŸ¥æ¡ä»¶ï¼Œç„¶åå†æ‰§è¡Œè¿æ¥ã€‚ä¸ºä»€ä¹ˆè¦è¿™æ ·åšå‘¢ï¼Ÿå› ä¸ºå½’æ ¹ç»“åº•ï¼Œåœ¨è¿æ¥ä¹‹å‰è¿‡æ»¤æ•°æ®ä¼šä½¿æ“ä½œæ›´åŠ é«˜æ•ˆã€‚å®ƒå‡å°‘äº†è¿æ¥çš„å¤§å°ï¼Œä»è€Œé™ä½äº†æˆæœ¬ã€‚
Additionally, we can also employ the strategy of pushing down selection, ensuring that we always retain the attributes we need. This is an example where instead of initially performing a join and then applying selection, we push the selection down. This means we first check conditions and then perform the join. Why do we do this? Because ultimately, filtering the data before the join makes the operation more efficient. It reduces the size of the join, making it less costly.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420143458457.png" alt="image-20240420143458457" style="zoom:50%;" /> 

**1ï¸âƒ£**Converting selection + cross-product to join

$
\begin{aligned}
\sigma_{\text {S.sid }=\text { R.sid }} & (\text { Sailors } \times \text { Reserves }) \\
& \leftrightarrow \text { Sailors } \bowtie_{\text {S.sid }=\text { R.sid }} \text { Reserves }
\end{aligned}
$â€‹
**2ï¸âƒ£**Selection on just attributes of S commutes with $\text{R}\bowtie\text{S}$â€‹

$
\begin{aligned}
\sigma_{S.age<18} & (\text{Sailors} \bowtie_{S.sid = R.sid} \text{Reserves})\\
& \leftrightarrow
(\sigma_{S.age<18} (\text{Sailors})) \bowtie_{S.sid = R.sid} \text{Reserves}
\end{aligned}
$
**3ï¸âƒ£**We can also â€œpush downâ€projection (but be ğŸš—efulâ€¦)

$
\begin{aligned}
\Pi_{S.sname} & (\text{Sailors} \bowtie_{S.sid = R.sid} \text{Reserves})\\
& \leftrightarrow
 (\Pi_{S.sname} (\Pi_{sname, sid} (\text{Sailors})) \bowtie_{S.sid = R.sid} \Pi_{sid} (\text{Reserves}))
 \end{aligned}
$â€‹

```
æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†ç›¸åŒçš„é€»è¾‘åº”ç”¨äºä¸‹æ¨æŠ•å½±ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬ä»ä¸€å¼€å§‹å°±åªä¿ç•™æˆ‘ä»¬éœ€è¦çš„åˆ—ã€‚è¿™æ ·å¯ä»¥èŠ‚çœå†…å­˜ï¼Œå¤§å¤§é™ä½æˆæœ¬ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬å¿…é¡»æœ‰é€‰æ‹©åœ°ä¿ç•™å“ªäº›å±æ€§ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸‹å­¦ç”Ÿä»¬ç»å¸¸çŠ¯é”™çš„æƒ…å†µï¼šå¦‚æœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åªä¿ç•™æ°´æ‰‹çš„å§“åï¼Œç„¶åå°†è¿™ä¸ªå­é›†ä¸åå¤‡é›†è¿æ¥èµ·æ¥ã€‚å¦‚æœæˆ‘ä»¬å‹ä½æŠ•å½±ï¼Œåªä¿ç•™å§“åï¼Œå°±ä¼šä¸¢å¤±è‡ªç„¶è¿æ¥æ‰€éœ€çš„ ID å±æ€§ã€‚å› æ­¤ï¼Œåœ¨æŠ•å½±åˆ—è¡¨ä¸­ä¹Ÿå¿…é¡»åŒ…å« IDã€‚å®Œæˆè¿æ¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥åªæŠ•å½±åç§°äº†ã€‚è¿™æœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿå› ä¸ºé€šè¿‡æŠ•å½±ç¼©å°äº†è§„æ¨¡ï¼Œä½¿ç”¨å‚¨å¤‡åˆå¹¶å°±ä¼šå˜å¾—æ›´æœ‰æ•ˆç‡ã€‚è¿™ç§æ–¹æ³•ä¼šäº§ç”Ÿä¸€ä¸ªæ›´å¥½çš„è®¡åˆ’ï¼Œä¼˜åŒ–å™¨ä¼šè¯†åˆ«è¿™ä¸ªè®¡åˆ’ã€‚
Furthermore, we can apply the same logic to push down projection. By doing so, we retain only the columns we need right from the start. This allows us to conserve memory and reduce costs significantly. However, it's crucial to be selective about which attributes we retain. For instance, consider the scenario where students often make mistakes: if we aim to keep only the names of sailors and then join this subset with reserves. If we push down projection and keep only the names, we lose the ID attribute necessary for a natural join. Therefore, it's essential to include the ID in the projection list as well. After completing the join, we can then project only the names. Why does this matter? Well, with a reduced size due to projection, merging with reserves becomes much more efficient. This approach yields a better plan, one that the optimizer will identify.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420144447913.png" alt="image-20240420144447913" style="zoom:50%;" /> 

â€¢Overview
â€¢ Query optimization
**â€¢ Cost estimation**

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420144502935.png" alt="image-20240420144502935" style="zoom:50%;" /> 

**1ï¸âƒ£**Query first broken into â€œblocksâ€

**2ï¸âƒ£**Each block converted to relational algebra

**3ï¸âƒ£**Then, for each block, several alternative **query plans** are considered

**4ï¸âƒ£**Plan with lowest **estimated cost** is selected

```sql
SELECT S.sname FROM Reserves R, Sailors S
WHERE R.sid=S.sidAND R.bid=100 AND S.rating>5
```
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420144653043.png" alt="image-20240420144653043" style="zoom:50%;" />    

$\pi_{\text {(sname) }} \sigma_{(\text {bid }=100 \wedge \text { rating }>5)}(\text { Reserves } \bowtie \text { Sailors })$â€‹

```
ç°åœ¨ï¼Œè®©æˆ‘ä»¬æŠŠæ³¨æ„åŠ›è½¬ç§»åˆ°æˆæœ¬ä¼˜åŒ–ä¸Šã€‚æˆ‘ä»¬ä¹‹å‰å·²ç»ä»‹ç»äº†è½¬æ¢æ•°æ®å—çš„è¿‡ç¨‹ï¼Œäº†è§£äº†å®ƒä»¬çš„åŸºæœ¬åŸç†ä»¥åŠå¦‚ä½•å°†å®ƒä»¬è½¬æ¢æˆå…³ç³»ä»£æ•°ã€‚æˆ‘ä»¬åˆ©ç”¨ç­‰ä»·è®¿é—®æ¥æœ‰æ•ˆæ¢ç´¢æ›¿ä»£æ–¹æ¡ˆã€‚
Now, let's shift our attention to cost optimization. We've previously covered the process of transforming blocks, understanding their fundamentals and how they're converted into relational algebra. We utilize equivalent access to explore alternatives effectively.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420144830500.png" alt="image-20240420144830500" style="zoom:50%;" /> 

Step 3&4

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420144946195.png" alt="image-20240420144946195" style="zoom:50%;" /> 

**3ï¸âƒ£**What plans are considered?

**4ï¸âƒ£**What is the cost of a plan?

```
And then uh we will now focus on uh these uh costing parts. OK.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420145007982.png" alt="image-20240420145007982" style="zoom: 50%;" /> 

For each plan considered, must estimate cost:

**1ï¸âƒ£**Must **estimate size of result** for each operation in tree

- Use information about input relations (from the system catalogs), and apply rules **(discussed next)**

**2ï¸âƒ£**Must **estimate cost** of each operation in plan tree

1. Depends on input ğŸš—dinalities
2. Weâ€™ve already discussed how to estimate the cost of operations (sequential scan, index scan, joins)
3. **Next time we will calculate the cost of entire plansâ€¦**

```
åœ¨ä¼°ç®—æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬æ—¶ï¼Œè®¡ç®—æ ‘ä¸­æ¯ä¸ªæ“ä½œçš„ç»“æœå¤§å°è‡³å…³é‡è¦ã€‚è¿™æ˜¯å› ä¸ºæ ‘ä»£è¡¨äº†ä¸€ç³»åˆ—æ“ä½œï¼Œå…¶ä¸­ä¸€ä¸ªæ“ä½œçš„è¾“å‡ºå°†æˆä¸ºåç»­æ“ä½œçš„è¾“å…¥ã€‚äº†è§£æµå…¥æ¯ä¸ªæ“ä½œçš„å›¾å…ƒæ•°é‡å¯¹äºå®Œæˆè¿™é¡¹ä»»åŠ¡è‡³å…³é‡è¦ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶å¦‚ä½•ç¡®å®šæ¯ä¸ªæ“ä½œçš„ç»“æœå¤§å°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸Šå‘¨ä»‹ç»çš„å…¬å¼ä¼°ç®—è®¡åˆ’ä¸­æ¯ä¸ªæ“ä½œçš„æˆæœ¬ã€‚æˆ‘ä»¬è®¨è®ºäº†è¿æ¥ã€åµŒå¥—å¾ªç¯è¿æ¥ã€æ•£åˆ—è¿æ¥ç­‰å„ç§æ“ä½œï¼Œä»¥åŠå †æ‰«æå’Œç´¢å¼•æ‰«æç­‰è®¿é—®è·¯å¾„ã€‚åœ¨ä¸‹ä¸€è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£æ‰€æœ‰è¿™äº›æ“ä½œå¦‚ä½•åœ¨æ„å»ºè®¡åˆ’æ—¶ç»“åˆåœ¨ä¸€èµ·ã€‚
When it comes to estimating the cost of each plan, it's crucial to calculate the result size for every operation within the tree. This is because the tree represents a sequence of operations, where the output of one operation becomes the input for the subsequent one. Understanding how many tuples are flowing into each operator is essential for this task. Today, we'll delve into determining the result size of each operation. Following this, we'll move on to estimating the cost of each operation in the plan using the formulas we covered last week. We discussed various operations such as joinsâ€”nested loop joins, hash joins, and othersâ€”along with access paths like heap scans and index scans. In our next session, we'll see how all of this comes together in constructing a plan.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420145221198.png" alt="image-20240420145221198" style="zoom:50%;" /> 

**1ï¸âƒ£**To decide on the cost, the optimizer needs information about the relations and indexes involved. This information is stored in the system **catalogs**.

**2ï¸âƒ£****Catalogs** typically contain at least:

â€“  # tuples **(NTuples)** and # pages **(NPages)** per relation

â€“  # distinct key values **(NKeys)** for eachindex (orrelation attribute)

â€“  low/high key values **(Low/High)** for each index (orrelation attribute)

â€“  Index height **(Height(I))** for each tree index

â€“  # index pages **(NPages(I))** for each index

**3ï¸âƒ£**Statistics in catalogs are updated periodically 

```
åœ¨æ•°æ®åº“ç®¡ç†é¢†åŸŸï¼Œç³»ç»Ÿç›®å½•åœ¨ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½æ–¹é¢å‘æŒ¥ç€ä¸¾è¶³è½»é‡çš„ä½œç”¨ã€‚è¿™äº›ç›®å½•æœ¬è´¨ä¸Šæ˜¯å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„å…ƒæ•°æ®é›†åˆï¼Œè¯¦ç»†è¯´æ˜äº†æ•°æ®åº“ç»“æ„çš„å„ä¸ªæ–¹é¢ã€‚å…ƒæ•°æ®åŒ…æ‹¬æ•°æ®å…ƒç´ çš„æè¿°ï¼Œå¦‚å›¾å…ƒï¼ˆ'T'ï¼‰çš„æ•°é‡å’Œæ¯ä¸ªå…³ç³»ä¸­çš„é¡µæ•°ã€‚è¿™äº›ç»†èŠ‚è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä»¬èƒ½è®©ä¼˜åŒ–å™¨äº†è§£æ•°æ®çš„ç‰©ç†å¸ƒå±€å’Œå¤§å°ï¼Œè€Œè¿™å¯¹äºè®¡ç®—é€‰æ‹©ã€æŠ•å½±å’Œè¿æ¥çš„è¿è¡Œæˆæœ¬æ˜¯ä¸å¯æˆ–ç¼ºçš„ã€‚é€šè¿‡å‚è€ƒè¯¥ç›®å½•ï¼Œä¼˜åŒ–å™¨å¯ä»¥åˆ©ç”¨æœ‰å…³æ•°æ®å­˜å‚¨å’Œç»“æ„çš„ç²¾ç¡®ä¿¡æ¯åšå‡ºæ˜æ™ºçš„å†³ç­–ã€‚
In the realm of database management, system catalogs play a pivotal role in optimizing query performance. These catalogs are essentially collections of metadata stored within the database, detailing various aspects of its structure. Metadata, to clarify, includes descriptions of data elements such as the number of tuples ('T') and the number of pages within each relation. These details are crucial as they inform the optimizer about the physical layout and size of the data, which are integral to calculating operational costs for selections, projections, and joins. By referencing this catalog, the optimizer can make informed decisions using precise information about data storage and structure.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420145221198.png" alt="image-20240420145221198" style="zoom:50%;" /> 

**1ï¸âƒ£**To decide on the cost, the optimizer needs information about the relations and indexes involved. This information is stored in the system **catalogs**.

**2ï¸âƒ£****Catalogs** typically contain at least:

â€“  # tuples **(NTuples)** and # pages **(NPages)** per relation

â€“  # distinct key values **(NKeys)** for eachindex (orrelation attribute)

â€“  low/high key values **(Low/High)** for each index (orrelation attribute)

â€“  Index height **(Height(I))** for each tree index

â€“  # index pages **(NPages(I))** for each index

**3ï¸âƒ£**Statistics in catalogs are updated periodically 

```
ç³»ç»Ÿç›®å½•ä¼šä¸ºæ¯ä¸ªå…³ç³»åŠå…¶å±æ€§ç»´æŠ¤ç‰¹å®šçš„å…ƒæ•°æ®ï¼Œä¾‹å¦‚ä¸åŒé”®å€¼çš„æ•°é‡ï¼Œç”¨é”®çš„æ•°é‡æ¥è¡¨ç¤ºï¼Œå®ƒä»£è¡¨ä¸€ä¸ªåŸŸå†…ä¸åŒçš„å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨ "æ°´æ‰‹ "è¡¨ä¸­ï¼Œ"æ’å "å±æ€§çš„å€¼èŒƒå›´ä¸º 1 åˆ° 10ï¼Œå› æ­¤ï¼Œä¸åŒé”®å€¼çš„åŸŸä¸º 10ã€‚æ— è®ºè®°å½•çš„å®é™…æ•°é‡æ˜¯å¤šå°‘ï¼Œè¿™ä¸€æŒ‡æ ‡éƒ½æœ‰åŠ©äºäº†è§£æ•°æ®çš„åˆ†å¸ƒæƒ…å†µã€‚æ­¤å¤–ï¼Œå…ƒæ•°æ®è¿˜åŒ…æ‹¬å±æ€§çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œå¯¹äºç´¢å¼•ï¼Œè¿˜ä¿ç•™äº†ç´¢å¼•é«˜åº¦å’Œç´¢å¼•é¡µæ•°ç­‰è¯¦ç»†ä¿¡æ¯ã€‚åœ¨è®¡ç®—å„ç§ç´¢å¼•æ‰«æï¼ˆæ— è®ºæ˜¯èšç±»è¿˜æ˜¯éèšç±»ï¼‰çš„æˆæœ¬æ—¶ï¼Œè¿™äº›æ•°å­—è‡³å…³é‡è¦ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶è¿™äº›æ•°æ®ä¼šå®šæœŸæ›´æ–°ï¼Œè€Œä¸”å¹¶ä¸æ€»æ˜¯å®Œå…¨å‡†ç¡®ï¼Œä½†å®ƒæä¾›äº†ä¸€ä¸ªé‡è¦çš„ä¼°ç®—å€¼ï¼Œæœ‰åŠ©äºè¯„ä¼°ä¸åŒçš„æ‰§è¡Œç­–ç•¥ï¼Œä»¥ç¡®å®šæœ€å…·æˆæœ¬æ•ˆç›Šçš„æ–¹æ¡ˆã€‚
The system catalog maintains specific metadata for each relation and its attributes, such as the number of distinct key values, denoted as the number of keys, which represent the distinct values within a domain. For example, consider the 'sailors' table where the 'ranking' attribute's values range from one to ten; thus, the domain of distinct keys is ten. This metric helps in understanding the distribution of data, irrespective of the actual number of records. Additionally, metadata includes the minimum and maximum values for attributes, and for indexes, details like index height and the number of index pages are kept. These figures are essential when calculating costs for various index scans, whether clustered or unclustered. Itâ€™s important to note that while this data is periodically updated and not always perfectly accurate, it provides a crucial estimate that aids in evaluating different execution strategies to identify the most cost-effective option.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420145615783.png" alt="image-20240420145615783" style="zoom:50%;" /> 

**1ï¸âƒ£**Consider a query block:

```sql
SELECT attribute list
FROM relation list
WHERE predicate1 AND ... AND predicate_k
```

**2ï¸âƒ£**Maximum number of tuples in the result is the **product** of the ğŸš—dinalities of relations in the FROM clause

**3ï¸âƒ£****Reduction factor (RF)** associated with each predicate reflects the impact of the predicate in reducing the result size. RF is also called **selectivity.**

```
ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¢ä¸ªæ€è·¯ï¼Œé‡ç‚¹è®¡ç®—å…³ç³»ä»£æ•°è¡¨è¾¾å¼ä¸­æ¯ä¸ªæ“ä½œçš„ç»“æœçš„ä¼°è®¡å¤§å°ã€‚æˆ‘ä»¬å°†é€å—è€ƒè™‘æ¯ä¸ªæ“ä½œã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåŒ…å«ä¸€ç³»åˆ—è°“è¯çš„ SELECT å­å¥ä½œä¸ºç¤ºä¾‹ã€‚å…³é”®é—®é¢˜æ˜¯ï¼šè¾“å‡ºä¸­æœ€å¤šå¯ä»¥åŒ…å«å¤šå°‘ä¸ªè¡¨ç¬¦ï¼Ÿå¯¹äº FROM å­å¥ä¸­çš„è¡¨åºåˆ—ï¼Œè¿™ç›¸å½“äºå®ƒä»¬çš„å¿ƒæ•°ï¼ˆè¡Œæ•°ï¼‰çš„ä¹˜ç§¯ã€‚ä»æœ¬è´¨ä¸Šè®²ï¼Œè¿™æ˜¯å‡è®¾æ‰€æœ‰è¡¨äº¤å‰ä¹˜ç§¯çš„ç²—ç•¥ä¼°è®¡ã€‚ä¸è¿‡ï¼ŒWHERE å­å¥ä¸­çš„æ¯ä¸ªè°“è¯éƒ½èµ·ç€è¿‡æ»¤å™¨çš„ä½œç”¨ï¼Œå¯èƒ½ä¼šåˆ é™¤éƒ¨åˆ†æ•°æ®ã€‚è¿™ç§è¿‡æ»¤æ•ˆæœç”±é€‰æ‹©æ€§å› å­æ•æ‰ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬åœ¨åº”ç”¨ç‰¹å®šæ¡ä»¶åå°†ä¿ç•™å¤šå°‘ç™¾åˆ†æ¯”çš„è¡Œã€‚é€‰æ‹©æ€§åœ¨å®Œå–„æˆ‘ä»¬å¯¹ç»“æœå¤§å°çš„åˆå§‹ä¼°è®¡ï¼ˆå¯èƒ½ä¼šå¤¸å¤§ï¼‰æ–¹é¢èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚
Now, let's shift gears and focus on calculating the estimated size of the results for each operation in a relational algebra expression. We'll consider each operation on a block-by-block basis. Here, we'll use an example with a SELECT clause containing a sequence of predicates. The key question: what's the maximum number of tuples we can expect in the output?  For a sequence of tables in the FROM clause, this translates to the product of their ğŸš—dinalities (number of rows). In essence, this is a rough estimate assuming a cross product of all tables. However, each predicate in the WHERE clause acts as a filter, potentially removing a portion of the data. This filtering effect is captured by the selectivity factor, which tells us what percentage of rows will be kept after applying a specific condition. Selectivity plays a crucial role in refining our initial, potentially inflated, estimate of the result size.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420145740638.png" alt="image-20240420145740638" style="zoom:50%;" /> 

**1ï¸âƒ£**Single table selection:

$
\text { ResultSize }=\mathrm{NTuples}(R) \prod_{i=1 . . n} R F_i
$â€‹
**2ï¸âƒ£**Joins (over k tables):

$
\text { ResultSize }=\prod_{j=1 . . k}  \text { NTuples }\left(R_j\right) \prod_{i=1 . . n} R F_i
$â€‹â€‹
**3ï¸âƒ£**If there are no selections (no predicates), reduction factors are simply ignored, i.e. they are ==1

```
äº‹å®ä¸Šï¼Œå…³ç³»ä»£æ•°ä¸ºæˆ‘ä»¬æä¾›äº†å¼ºå¤§çš„ç­‰ä»·å…³ç³»ï¼Œå°¤å…¶æ˜¯åœ¨è¿æ¥æ–¹é¢ã€‚æ­£å¦‚ä½ æåˆ°çš„ï¼Œè¿æ¥æ—¢æ˜¯å…³è”çš„ï¼Œä¹Ÿæ˜¯äº¤æ¢çš„ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é‡æ–°å®‰æ’å®ƒä»¬çš„é¡ºåºï¼Œè€Œä¸ä¼šæ”¹å˜æœ€ç»ˆç»“æœã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆæ‰§è¡Œè¡¨ S å’Œè¡¨ T ä¹‹é—´çš„è¿æ¥ï¼Œç„¶åå°†ç»“æœä¸è¡¨ R è¿æ¥ï¼Œæˆ–è€…åè¿‡æ¥å…ˆè¿æ¥ R å’Œ Sï¼Œç„¶åå†æ•´åˆ Tï¼š è¿™äº›ç‰¹æ€§è®©æˆ‘ä»¬å¯ä»¥çµæ´»åœ°å°è¯•ä¸åŒçš„è®¡åˆ’ï¼Œè€Œä¸”å¯¹æŸ¥è¯¢æ€§èƒ½çš„å½±å“å¯èƒ½å¾ˆå¤§ã€‚è¿æ¥é¡ºåºå’Œå®ç°æ–¹å¼çš„é€‰æ‹©ä¼šå¯¼è‡´è®¡åˆ’æˆæœ¬çš„å·¨å¤§å·®å¼‚ï¼Œè¿™çªå‡ºäº†ä¼˜åŒ–è¿™äº›å†³ç­–ä»¥å®ç°æœ€ä½³æŸ¥è¯¢æ‰§è¡Œçš„é‡è¦æ€§ã€‚
Indeed, relational algebra provides us with powerful equivalences, particularly concerning joins. As you mentioned, joins are both associative and commutative, meaning we can rearrange their order without altering the final result. For example, we can perform the join between tables S and T first and then join the result with table R, or vice versaâ€”joining R and S first and then integrating T. Additionally, the order of the tables in a join operation doesn't matter: R join S is equivalent to S join R. These properties give us the flexibility to experiment with different plans, and the impact on query performance can be significant. The choice of join order and implementation can lead to substantial differences in plan cost, underscoring the importance of optimizing these decisions to achieve optimal query execution.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150042968.png" alt="image-20240420150042968" style="zoom:50%;" /> 

Depend on the type of the predicate:

| Condition                              | Reduction Factor (RF) Calculation                   |
| -------------------------------------- | --------------------------------------------------- |
| `Col = value`                          | `RF = 1/NKeys(Col)`                                 |
| `Col > value`                          | `RF = (High(Col) - value) / (High(Col) - Low(Col))` |
| `Col < value`                          | `RF = (val - Low(Col)) / (High(Col) - Low(Col))`    |
| `Col_A = Col_B (for joins)`            | `RF = 1/(Max(NKeys(Col_A), NKeys(Col_B)))`          |
| No information about Nkeys or interval | `RF = 1/10` (use a â€œmagic numberâ€)                  |

```
è¦ä¼˜åŒ–æŸ¥è¯¢ï¼Œå¿…é¡»è®¡ç®—ç¼©å‡å› å­ï¼Œè€Œç¼©å‡å› å­å› åº”ç”¨äºæ•°æ®åº“åˆ—çš„æ¡ä»¶ç±»å‹è€Œå¼‚ã€‚æˆ‘ä»¬å°†è¿™äº›æ¡ä»¶åˆ†ä¸ºå‡ ç§ç±»å‹ï¼Œæ¯ç§ç±»å‹éƒ½ä¼šå¯¹ç»“æœå¤§å°äº§ç”Ÿä¸åŒçš„å½±å“ã€‚ç¬¬ä¸€ç§æ˜¯ç›¸ç­‰æ¡ä»¶ï¼Œå³åˆ—ç­‰äºä¸€ä¸ªç‰¹å®šå€¼ï¼Œå¦‚ "è¯„åˆ†ç­‰äº 8"ã€‚å¦ä¸€ç§æ˜¯æ¯”è¾ƒæ¡ä»¶ï¼Œå¦‚ "å¹´é¾„å¤§äº 50 "æˆ– "å¹´é¾„å°äº 50"ã€‚è¿æ¥æ“ä½œç»å¸¸ä½¿ç”¨ "æ°´æ‰‹ ID ç­‰äºå‚¨å¤‡ ID "è¿™æ ·çš„æ¡ä»¶ã€‚æœ€åï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ•°æ®åº“ç¼ºä¹è°“è¯çš„ç‰¹å®šå…ƒæ•°æ®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„ä¼°è®¡å€¼ï¼Œå³ "1 å¤§äº n"ï¼Œåœ¨æ²¡æœ‰ç²¾ç¡®æ•°æ®çš„æƒ…å†µä¸‹æä¾›ä¸€ä¸ªç²—ç•¥ä½†å¿…è¦çš„è¿‘ä¼¼å€¼ã€‚
To optimize queries, it's essential to calculate the reduction factor, which varies depending on the type of condition applied to the database columns. We categorize these conditions into several types, each affecting the result size differently. The first type is the equality condition, where a column equals a specific value, such as 'rating equals 8'. Another type involves comparisons, such as 'age greater than 50' or 'age less than 50'. Join operations often use conditions like 'sailor ID equals reserve ID'. Lastly, there are situations where the database lacks specific metadata for a predicate. In such cases, a generic estimate, termed 'one over n', is used, providing a rough but necessary approximation when precise data is unavailable. 
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150042968.png" alt="image-20240420150042968" style="zoom:50%;" /> 

Depend on the type of the predicate:

| Condition                              | Reduction Factor (RF) Calculation                   |
| -------------------------------------- | --------------------------------------------------- |
| `Col = value`                          | `RF = 1/NKeys(Col)`                                 |
| `Col > value`                          | `RF = (High(Col) - value) / (High(Col) - Low(Col))` |
| `Col < value`                          | `RF = (val - Low(Col)) / (High(Col) - Low(Col))`    |
| `Col_A = Col_B (for joins)`            | `RF = 1/(Max(NKeys(Col_A), NKeys(Col_B)))`          |
| No information about Nkeys or interval | `RF = 1/10` (use a â€œmagic numberâ€)                  |

```
è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸€ä¸‹æ¯ç§ç±»å‹çš„æ¡ä»¶æ˜¯å¦‚ä½•è®¡ç®—ç¼©å‡å› å­çš„ã€‚å¯¹äºç›¸ç­‰æ¡ä»¶ï¼ˆ"åˆ—ç­‰äºå€¼"ï¼‰ï¼Œç¼©å‡å› å­çš„è®¡ç®—å…¬å¼æ˜¯ 1 é™¤ä»¥ä¸åŒé”®çš„ä¸ªæ•°ï¼Œåè€…ä»£è¡¨åˆ—ä¸­çš„å”¯ä¸€å€¼ã€‚å¯¹äºèŒƒå›´æ¡ä»¶ï¼ˆå¦‚ "åˆ—å¤§äºå€¼"ï¼‰ï¼Œç¼©å‡å› å­æ˜¯æ ¹æ®æ»¡è¶³æ¡ä»¶çš„å€¼èŒƒå›´çš„æ¯”ä¾‹å¾—å‡ºçš„ã€‚å½“æ¶‰åŠåˆ°è¿æ¥ï¼ˆ"åˆ— A ç­‰äºåˆ— B"ï¼‰æ—¶ï¼Œç³»æ•°æ˜¯è¿æ¥ä¸­ä»»ä¸€åˆ—ä¸­ä¸åŒé”®æœ€å¤§å€¼çš„ 1 å€ã€‚è¿™äº›è®¡ç®—æœ‰åŠ©äºç²¾ç¡®ä¼°ç®—æ¯ä¸ªæ¡ä»¶å¯¹æŸ¥è¯¢ç»“æœå¤§å°çš„å½±å“ã€‚ä¸ºè¿›ä¸€æ­¥æä¾›å¸®åŠ©ï¼Œæˆ‘å°†æä¾›ä¸€ä»½åŒ…å«æ‰€æœ‰å¿…è¦å…¬å¼çš„å°æŠ„ï¼Œæ— è®ºæ‚¨æ˜¯å¦è®°ä½å…¬å¼ï¼Œéƒ½èƒ½è½»æ¾è®¡ç®—è¿™äº›å› å­ã€‚
 Letâ€™s delve deeper into how these reduction factors are calculated for each type of condition. For an equality condition ('column equals value'), the reduction factor is calculated as one divided by the number of distinct keys, which represents the unique values within a column. For range conditions, such as 'column greater than value', the reduction factor is derived from the proportion of the value range that meets the condition. When it comes to joins ('column A equals column B'), the factor is one over the maximum of the distinct keys in either column involved in the join. These calculations help in precisely estimating the impact of each condition on the result size of a query. To assist further, I will provide a cheat sheet with all the necessary formulas, enabling you to compute these factors easily, whether you memorize the formulas or not.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150042968.png" alt="image-20240420150042968" style="zoom:50%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420221311039.png" alt="image-20240420221311039" style="zoom:50%;" /> 

```
è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹æ’åå±æ€§çš„è´¨é‡ï¼Œå…¶ä¸­å¯èƒ½çš„å€¼åŸŸèŒƒå›´ä»ä¸€åˆ°åã€‚å¦‚æœæˆ‘ä»¬è¦å¯»æ‰¾ä¸€ä¸ªå®Œå…¨åŒ¹é…çš„å€¼ï¼Œæ¯”å¦‚æ’åç­‰äºæŸä¸ªç‰¹å®šå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬åŸºæœ¬ä¸Šå°±ä¼šæŠŠæœç´¢èŒƒå›´ç¼©å°åˆ°åŸŸä¸­ 10 ä¸ªå¯èƒ½å€¼ä¸­çš„ä¸€ä¸ªå€¼ã€‚å› æ­¤ï¼Œè¿™é‡Œçš„ç¼©å‡ç³»æ•°æ˜¯æ’åä¸­ä¸åŒå…³é”®å­—æ•°é‡çš„ 1 å€ï¼Œå³ 1/10ã€‚è¿™ä¸ªç¼©å‡ç³»æ•°åæ˜ äº†ä¸€ä¸ªåŸºæœ¬æ¯”ä¾‹ï¼Œå³åœ¨åä¸ªå¯èƒ½å€¼ä¸­ï¼Œæˆ‘ä»¬åªå¯¹ä¸€ä¸ªç‰¹å®šå€¼æ„Ÿå…´è¶£ã€‚
Let's consider the quality of the ranking attribute, where the domain of possible values ranges from one to ten. If we're looking for an exact match, such as ranking equal to a specific value, we're essentially narrowing down our search to just one value out of the ten possible values in the domain. Therefore, the reduction factor here is one over the number of distinct keys in the ranking, which is 1/10. This reduction factor reflects the basic proportion that out of the ten possible values, we're interested in only one specific value.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150042968.png" alt="image-20240420150042968" style="zoom:50%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420221649974.png" alt="image-20240420221649974" style="zoom:50%;" /> 

```
ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬çš„æ¡ä»¶æ¶‰åŠä¸€ä¸ªæ•°å€¼èŒƒå›´ã€‚ä¸¾ä¾‹è¯´æ˜ï¼Œå‡è®¾æˆ‘ä»¬æƒ³é€‰æ‹©ä¸€åˆ—å¤§äºæŸä¸ªå€¼çš„è¡Œã€‚åœ¨ç›®å½•ä¸­ï¼Œæˆ‘ä»¬å­˜å‚¨äº†å¯èƒ½å€¼åŸŸçš„æœ€ä½å€¼å’Œæœ€é«˜å€¼ã€‚å½“æˆ‘ä»¬é‡åˆ°è¿™ç§æƒ…å†µæ—¶ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„åŸºæœ¬ä¸Šæ˜¯æ•´ä¸ªèŒƒå›´çš„æŸä¸ªæ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦æŸ¥æ‰¾å¤§äºæŸä¸ªç‰¹å®šå€¼çš„å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„æ¯”ä¾‹å°±æ˜¯ï¼ˆé«˜å€¼-ç‰¹å®šå€¼ï¼‰é™¤ä»¥ï¼ˆé«˜å€¼-ä½å€¼ï¼‰ã€‚è¿™ä¸ªæ¯”ä¾‹ä»£è¡¨æˆ‘ä»¬æ„Ÿå…´è¶£çš„èŒƒå›´çš„ä¸€éƒ¨åˆ†ã€‚åŒæ ·ï¼Œå¦‚æœæ¡ä»¶æ˜¯æ•°å€¼ä½äºæŸä¸ªç‰¹å®šå€¼ï¼Œé‚£ä¹ˆæ¯”ä¾‹å°±æ˜¯ï¼ˆç‰¹å®šå€¼ - ä½å€¼ï¼‰é™¤ä»¥ï¼ˆé«˜å€¼ - ä½å€¼ï¼‰ã€‚
Let's consider an example where our condition involves a range of values. To illustrate, let's assume we're interested in selecting rows where a column is greater than a certain value. In our catalog, we store the lowest and highest values for the domain of possible values. When we encounter this condition, we're essentially interested in a proportion of the entire range. For example, if we're looking for values greater than a specific value, our proportion would be (high value - specific value) divided by (high value - low value). This ratio represents the portion of the range that we're interested in. Similarly, if the condition is for values lower than a certain value, the proportion would be (specific value - low value) divided by (high value - low value).
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150042968.png" alt="image-20240420150042968" style="zoom:50%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420221649974.png" alt="image-20240420221649974" style="zoom:50%;" /> 

```
æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†è¿™ä¸€æ¦‚å¿µæ‰©å±•åˆ°ä»»ä½•èŒƒå›´æ¡ä»¶ï¼Œä¾‹å¦‚åœ¨ä¸¤ä¸ªç»™å®šå€¼ä¹‹é—´çš„ç‰¹å®šèŒƒå›´å†…é€‰æ‹©å€¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç›¸å…³æ¯”ä¾‹å°±æ˜¯ï¼ˆå€¼ 1 - å€¼ 2ï¼‰é™¤ä»¥ï¼ˆé«˜å€¼ - ä½å€¼ï¼‰ã€‚é€šè¿‡è¿™äº›ç®€å•æ˜äº†çš„æ•°å­¦è®¡ç®—ï¼Œæˆ‘ä»¬å¯ä»¥æ¨å¯¼å‡ºç²¾ç¡®åæ˜ å„ç§èŒƒå›´æ¡ä»¶ä¸‹ç›¸å…³æ¯”ä¾‹çš„å…¬å¼ï¼Œä»è€Œå¸®åŠ©ä¼˜åŒ–æŸ¥è¯¢ã€‚
Moreover, we can extend this concept to encompass any range condition, such as selecting values within a specific range between two given values. In this case, the proportion of interest would be (value1 - value2) divided by (high value - low value). These straightforward mathematical calculations allow us to derive formulas that accurately reflect the proportion of interest for various range conditions, aiding in query optimization.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150324213.png" alt="image-20240420150324213" style="zoom:50%;" /> 

**1ï¸âƒ£**Sailors (S): 

NTuples(S) =1000, Nkeys(rating) = 10 interval [1-10],

age interval [0-100], Nkeys(sid)=1000

```sql
SELECT * FROM Sailors WHERE rating = 3 AND age > 50;
```

**2ï¸âƒ£**Calculate result size:

```
è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥å®è·µä¸€ä¸‹æ–°å‘ç°çš„çŸ¥è¯†ã€‚å‡è®¾æˆ‘ä»¬æ­£åœ¨æŸ¥è¯¢ "æ°´æ‰‹ "è¡¨ä¸­çš„æ•°æ®ï¼Œå…¶ä¸­æœ‰ä¸¤ä¸ªè°“è¯ï¼šç­‰çº§ç­‰äº 3 å’Œå¹´é¾„å¤§äº 50ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬ä»ç³»ç»Ÿç›®å½•ä¸­è·å¾—çš„ä¿¡æ¯ï¼š"æ°´æ‰‹ "è¡¨ä¸­çš„å›¾å…ƒæ•°ä¸º 1000ï¼Œ"ç­‰çº§ "çš„ä¸åŒé”®æ•°åœ¨ 1 åˆ° 10 çš„åŒºé—´å†…ä¸º 10ï¼Œ"æ°´æ‰‹ ID "çš„é”®æ•°ä¸º 1000ã€‚ç°åœ¨çš„é—®é¢˜æ˜¯ï¼šå¦‚ä½•è®¡ç®—ç»“æœå¤§å°ï¼Ÿåœ¨æ­ç¤ºè§£å†³æ–¹æ¡ˆä¹‹å‰ï¼Œæˆ‘å¼ºçƒˆå»ºè®®å¤§å®¶å…ˆæš‚åœä¸€ä¸‹ï¼Œå°è¯•è‡ªå·±è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿™ç§ä¸»åŠ¨å‚ä¸å¯¹äºå­¦ä¹ å’Œä¿ç•™æˆ‘ä»¬æ‰€è®²çš„æ¦‚å¿µè‡³å…³é‡è¦ã€‚
Let's put our newfound knowledge into practice with a simple query. Imagine we're querying data from the 'sailors' table with two predicates: rating equal to three and age greater than 50. Here's the information we have from the system catalog: the number of tuples in the 'sailors' table is 1000, the number of distinct keys for 'rating' is 10 within the interval of one to 10, and the number of keys for 'sailor ID' is 1000. Now, the question is: how do we calculate the result size? Before I reveal the solutions, I strongly encourage you to pause here and attempt to solve it on your own first. This active engagement is crucial for learning and retaining the concepts we've covered.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$


<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420150324213.png" alt="image-20240420150324213" style="zoom:50%;" /> 

**1ï¸âƒ£**Sailors (S): 

NTuples(S) =1000, Nkeys(rating) = 10 interval [1-10],

age interval [0-100], Nkeys(sid)=1000

```sql
SELECT * FROM Sailors WHERE rating = 3 AND age > 50;
```

**2ï¸âƒ£**Calculate result size:

```
NTuples(S) = 1000
RF(rating) = 1/10 = 0.1
RF(age) = (100-50)/(100-0) = 0.5
ResultSize = NTuples(S)*RF(rating)*RF(age)
           = 1000*0.1*0.5= 50 tuples
```

```
å¥½äº†ï¼Œè®©æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹æŸ¥è¯¢ç»“æœå¤§å°çš„è®¡ç®—æ–¹æ³•ã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªè°“è¯çš„å•è¡¨é€‰æ‹©ï¼šè¯„åˆ†ç­‰äº 3 å’Œå¹´é¾„å¤§äº 50ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®— "è¯„åˆ† "çš„ç¼©å‡å› å­ã€‚ç”±äº "è¯„åˆ† "æœ‰ 10 ä¸ªä¸åŒçš„å€¼ï¼Œå› æ­¤ç¼©å‡å› å­æ˜¯ 10 å‡ 1ï¼Œç­‰äº 0.1 æˆ– 10%ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å…³æ³¨çš„æ˜¯ 10%çš„å¯èƒ½å€¼ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¡ç®— "å¹´é¾„ "çš„æŠ˜å‡ç³»æ•°ã€‚å¹´é¾„å¤§äº 50 å² "è¿™ä¸€æ¡ä»¶è¦†ç›–äº† 0 åˆ° 100 ä¹‹é—´çš„ä¸€åŠåŒºé—´ï¼Œå› æ­¤ç¼©å‡å› å­ä¸º 0.5 æˆ– 50%ã€‚ä¸ºäº†è®¡ç®—ç»“æœå¤§å°ï¼Œæˆ‘ä»¬å°† "æ°´æ‰‹ "è¡¨ä¸­çš„å›¾å…ƒæ•°ï¼ˆ1000 ä¸ªå›¾å…ƒï¼‰ä¹˜ä»¥æ¯ä¸ªè°“è¯çš„ç¼©å‡å› å­ï¼š 1000 * 0.1 * 0.5 = 50 ä¸ªå›¾å…ƒã€‚è¿™ä¸€é€»è¾‘é€‚ç”¨äºä»»ä½•ç±»ä¼¼æƒ…å†µã€‚æŒ‰ç…§è¿™äº›å…¬å¼ï¼Œå¹¶è€ƒè™‘åˆ°ä¸åŒé”®çš„æ•°é‡å’Œæ¶‰åŠçš„èŒƒå›´ï¼Œæˆ‘ä»¬å°±å¯ä»¥å‡†ç¡®åœ°ç¡®å®šä»»ä½•æŸ¥è¯¢çš„ç»“æœå¤§å°ï¼Œæ— è®ºå®ƒæ˜¯å¦æ¶‰åŠè¿æ¥ã€é€‰æ‹©æˆ–å…¶ä»–æ“ä½œã€‚
Alright, let's break down the calculation of the result size for our query. We have a single table selection with two predicates: rating equal to three and age greater than 50. First, we calculate the reduction factor over 'rating'. Since 'rating' has 10 distinct values, the reduction factor is 1 over 10, which equals 0.1 or 10%. This means we're interested in 10% of the possible values. Next, we calculate the reduction factor over 'age'. The condition 'age greater than 50' covers half of the interval between 0 and 100, so the reduction factor is 0.5 or 50%. To find the result size, we multiply the number of tuples in the 'sailors' table (1000 tuples) by the reduction factors for each predicate: 1000 * 0.1 * 0.5 = 50 tuples. This logic applies to any similar case. By following these formulas and considering the number of distinct keys and the ranges involved, we can accurately determine the result size for any query, whether it involves joins, selections, or other operations.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$



<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420151611706.png" alt="image-20240420151611706" style="zoom:50%;" /> 

**1ï¸âƒ£**What is query optimization/describe steps?

**2ï¸âƒ£**Equivalence classes

**3ï¸âƒ£**Result size estimation

**4ï¸âƒ£**Important for Assignment 3 as well

```
å› æ­¤ï¼Œåœ¨æœ¬è®²åº§ä¸­ï¼Œæœ€é‡è¦çš„æ˜¯æŒæ¡è¿™ä¸€è¿‡ç¨‹çš„æœ¬è´¨ã€‚ä½ éœ€è¦å½»åº•ç†è§£æ¯ä¸ªæ­¥éª¤ï¼Œäº†è§£æ¯ä¸ªé˜¶æ®µçš„å†…å®¹ï¼Œå°¤å…¶æ˜¯æˆ‘ä»¬å¦‚ä½•åˆ©ç”¨ç­‰ä»·å…³ç³»å¾—å‡ºç»“è®ºï¼Œä»¥åŠæˆ‘ä»¬åˆ©ç”¨ç­‰ä»·å…³ç³»çš„æ–¹æ³•ã€‚ç¡®å®šç­‰ä»·å…³ç³»--ä»€ä¹ˆä¸ä»€ä¹ˆç­‰ä»·--å¯ä»¥æˆä¸ºä¸€é“å¯é çš„è€ƒé¢˜ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å°†æ·±å…¥æ¢è®¨ç»“æœå¤§å°çš„è®¡ç®—ï¼Œè¿™æ˜¯åœ¨åç»­è¯¾ç¨‹ä¸­å æœ‰é‡è¦åœ°ä½çš„ä¸€ä¸ªå…³é”®ç¯èŠ‚ã€‚è¿™é¡¹æŠ€èƒ½è¿˜å°†åœ¨ä½œä¸šæ ‘ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œåœ¨ä½œä¸šæ ‘ä¸­ï¼Œæˆ‘ä»¬å°†æ‰®æ¼”æ•°æ®åº“ç®¡ç†å‘˜çš„è§’è‰²ï¼Œä»”ç»†è¯„ä¼°æˆ‘ä»¬çš„ç»¼åˆè®¡åˆ’ã€‚æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼Œæˆ‘æœŸå¾…ç€æˆ‘ä»¬çš„ä¸‹æ¬¡ä¼šé¢ã€‚
So, in this lecture, what's important to grasp is the essence of the process. You'll need to comprehend each step thoroughly, understanding what unfolds at each stage, particularly how we arrive at conclusions using equivalences, and the method we employ to leverage them. Identifying equivalencesâ€”what is equivalent to whatâ€”can make for a solid exam question. Naturally, we'll delve into calculating result sizes, a crucial aspect that will ğŸš—ry weight in subsequent sessions. This skill will also play a significant role in the assignment tree, where we take on the role of a database administrator, meticulously evaluating our comprehensive plans. Thank you for your attention, and I look forward to our next meeting.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240420151911591.png" alt="image-20240420151911591" style="zoom:50%;" /> 
$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
