$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404220947396.png" alt="image-20240404220947396" style="zoom: 50%;" /> 

```
æ¬¢è¿å›åˆ°æ•°æ®åº“ç³»ç»Ÿç³»åˆ—è®²åº§çš„ç¬¬åäºŒè®²ã€‚åœ¨ä»Šå¤©çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¢ç´¢æŸ¥è¯¢å¤„ç†æ¨¡å—ã€‚å›é¡¾ä¸€ä¸‹ï¼Œåœ¨ä¸Šä¸€è®²ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†æ•°æ®åº“ç³»ç»Ÿçš„æ‰§è¡Œå™¨ç»„ä»¶ï¼Œå®ƒè´Ÿè´£æ‰§è¡Œé¢„å®šä¹‰çš„æ“ä½œåºåˆ—ã€‚æˆ‘ä»¬è¿˜äº†è§£äº†è®¿é—®è·¯å¾„ï¼Œé‡ç‚¹æ˜¯é€‰æ‹©å’ŒæŠ•å½±çš„æ‰§è¡Œã€‚ä»Šå¤©çš„è®¨è®ºå°†è½¬å‘è¿æ¥ã€‚åºŸè¯ä¸å¤šè¯´ï¼Œè®©æˆ‘ä»¬è¿›å…¥ä¸»é¢˜ã€‚
Welcome back to the twelfth lecture in our database systems series. In todayâ€™s session, weâ€™ll continue exploring the query processing module. To recap, in our previous lecture, we delved into the executor component of database systems, which is responsible for executing a predefined sequence of operations. We also looked at access paths, focusing on the execution of selections and projections. Today's discussion will pivot to joins. Letâ€™s dive into this topic without further ado.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404221141035.png" alt="image-20240404221141035" style="zoom: 25%;" /> 

```
è®©æˆ‘ä»¬æ¥æ¢è®¨ä¸€ä¸‹ä½¿ç”¨å‡æƒ³é”®ï¼ˆæˆ‘ä»¬å°†å…¶ç§°ä¸º "ID"ï¼‰è¿æ¥ä¸¤ä¸ªè¡¨çš„ä»»åŠ¡ã€‚å‡è®¾æˆ‘ä»¬åœ¨ä¸€ä¸ªè¡¨ä¸­é‡åˆ°äº† 12 è¿™æ ·çš„ ID å€¼ï¼Œè€Œåœ¨å¦ä¸€ä¸ªè¡¨ä¸­é‡åˆ°äº†ç›¸åº”çš„åŒ¹é…å€¼ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯†åˆ«è¿™äº›åŒ¹é…å¯¹ã€‚ä¸€ç§ç›´æ¥çš„æ–¹æ³•æ˜¯æŒ‰é¡ºåºæ‰«æä¸¤å¼ è¡¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæ£€æŸ¥å·¦è¡¨ä¸­çš„ç¬¬ä¸€æ¡è®°å½•ï¼Œç„¶åå°†å…¶ä¸å³è¡¨ä¸­çš„æ‰€æœ‰è®°å½•è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºåŒ¹é…é¡¹ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•ï¼Œæˆ‘ä»¬å°±ç»§ç»­æ‰«æå·¦è¡¨ä¸­çš„ä¸‹ä¸€æ¡è®°å½•ï¼Œå¹¶é‡å¤è¿™ä¸€è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œåœ¨æ£€æŸ¥ ID å€¼ "2 "æ—¶ï¼Œæˆ‘ä»¬ä¼šå‘ç°ä¸€æ¡åŒ¹é…è®°å½•å¹¶ç”Ÿæˆç›¸åº”è®°å½•ã€‚è¿™ç§æ–¹æ³•é€‚ç”¨äºæ‰€æœ‰è®°å½•ï¼Œå¦‚ "73 "å’Œ "4"ï¼Œä»¥æ‰¾åˆ°æ‰€æœ‰æ½œåœ¨çš„åŒ¹é…è®°å½•ã€‚è™½ç„¶è¿™ç§æŠ€æœ¯å¾ˆæœ‰æ•ˆï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®ƒåœ¨å¤„ç†å¤§å‹æ•°æ®é›†æ—¶æ•ˆç‡è¾ƒä½ã€‚
Let's explore the task of joining two tables using an imaginary key, which we'll refer to as 'ID'. Suppose we encounter ID values like 12 in one table and corresponding matches in another. Our objective is to identify these matching pairs. One straightforward approach is to sequentially scan both tables. Specifically, we start by examining the first record in the left table and compare it against all records in the right table to find matches. If no match is found, we proceed to the next record in the left table and repeat the process. For instance, upon checking the ID value '2', we discover a match and generate the corresponding record. This method is applied to all records, such as '73' and '4', to find all potential matches. While this technique is effective, it's important to note its inefficiency for large datasets.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404221240442.png" alt="image-20240404221240442" style="zoom: 25%;" /> 

```
æé«˜æ•ˆç‡çš„å¦ä¸€ç§ç­–ç•¥æ˜¯å¯¹ä¸¤ä¸ªè¾“å…¥è¡¨è¿›è¡Œæ’åºã€‚é€šè¿‡ä»¥å‡åºæ’åˆ—å·¦è¡¨å’Œå³è¡¨çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç®€åŒ–æœç´¢è¿‡ç¨‹ã€‚åœ¨å¯¹ä¸¤ä¸ªè¡¨è¿›è¡Œæ’åºåï¼Œæˆ‘ä»¬å¯ä»¥åŒæ—¶å¯¹å®ƒä»¬è¿›è¡Œéå†ï¼Œæ— éœ€è¿›è¡Œç©·ä¸¾æ¯”è¾ƒå°±èƒ½è¿…é€Ÿè¯†åˆ«åŒ¹é…é¡¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå³è¡¨ä¸­çš„æœ€å°å€¼æ˜¯ "2"ï¼Œè€Œæˆ‘ä»¬åœ¨å·¦è¡¨ä¸­é‡åˆ°çš„æ˜¯ "1"ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç«‹å³å¾—å‡ºç»“è®ºï¼Œ"1 "ä¸åŒ¹é…ï¼Œæ— éœ€è¿›ä¸€æ­¥æ¯”è¾ƒã€‚è¿™ç§æ–¹æ³•å¤§å¤§å‡å°‘äº†è®¡ç®—é‡ã€‚åœ¨ä¸¤ä¸ªè¡¨ä¸­éƒ½åŒ¹é…åˆ° "2 "æ—¶ï¼Œæˆ‘ä»¬ä¼šç»§ç»­è¿›è¡Œæ¯”è¾ƒï¼Œç›´åˆ°æ¯”è¾ƒç»“æœè¶…å‡ºæ½œåœ¨åŒ¹é…èŒƒå›´ï¼Œè¡¨æ˜è¯¥æ•°æ®æ®µçš„æœç´¢å®Œæˆã€‚æ­¤å¤–ï¼Œé™¤äº†æ’åºä¹‹å¤–ï¼Œå“ˆå¸Œç®—æ³•ä¹Ÿèƒ½å‡å°‘ä¸å¿…è¦çš„è®¡ç®—ï¼Œåˆ©ç”¨å“ˆå¸Œè¡¨åŠ å¿«åŒ¹é…è¿‡ç¨‹ã€‚
An alternative strategy to improve efficiency involves sorting both input tables. By organizing the data in ascending order for both the left and right tables, we enable a more streamlined search process. With both tables sorted, we can simultaneously traverse them, swiftly identifying matches without exhaustive comparison. For example, if the smallest value in the right table is '2' and we encounter a '1' in the left table, we can immediately conclude there's no match for '1' and proceed without further comparisons. This approach significantly reduces the computational effort. Upon matching a '2' in both tables, we continue until the comparisons exceed the range of potential matches, indicating completion of the search for that segment. Moreover, beyond sorting, implementing hashing offers a similar reduction in unnecessary computations, leveraging a hash table to expedite the matching process.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404221325899.png" alt="image-20240404221325899" style="zoom: 25%;" /> 

```
ä¸ºäº†è¿›ä¸€æ­¥æé«˜æœç´¢æ•ˆç‡ï¼Œå¦ä¸€ç§å®ç”¨çš„æŠ€æœ¯æ˜¯ä½¿ç”¨æ¨¡å‡½æ•°è¿›è¡Œåˆ†ç»„ã€‚ä¾‹å¦‚ï¼Œåº”ç”¨å››åˆ™è¿ç®—å°†æ•°å­—åˆ†ä¸ºå››ç±»ï¼š0ã€1ã€2 å’Œ 3ï¼š 0ã€1ã€2 å’Œ 3ã€‚è¿™ç§åˆ†ç±»åœ¨æ¯”è¾ƒçš„ä¸¤è¾¹éƒ½æœ‰åæ˜ ã€‚å› æ­¤ï¼Œåƒ 4 è¿™æ ·çš„æ•°å­—ä¼šè¢«æ”¾å…¥ 0 å·æ¡¶ï¼Œ1 ä¼šè¢«æ”¾å…¥ 1 å·æ¡¶ï¼Œä»¥æ­¤ç±»æ¨ï¼Œè€Œ 7 åˆ™ä¼šå› å…¶æ¨¡ä¹˜ç»“æœè€Œè¢«æ”¾å…¥ 3 å·æ¡¶ã€‚è¿™ç§æ–¹æ³•åŒæ ·é€‚ç”¨äºå³ä¾§çš„æ•°æ®é›†ï¼Œå»ºç«‹äº†ä¸€ç»„ä» 0 åˆ° 3 çš„å¹³è¡Œæ•°æ®æ¡¶ã€‚ä¾‹å¦‚ï¼Œåœ¨å³ä¾§æ•°æ®é›†ä¸­ï¼Œ8ï¼ˆæ¨¡ 0ï¼‰è¢«åˆ†é…åˆ° 0 æ¡¶ï¼Œ7ï¼ˆæ¨¡ 3ï¼‰è¢«åˆ†é…åˆ° 3 æ¡¶ï¼Œ2ï¼ˆæ¨¡ 2ï¼‰è¢«åˆ†é…åˆ° 2 æ¡¶ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¡¶æ˜¯ç©ºçš„ã€‚è¿™ç§æ–¹æ³•åªå¯¹ç›¸åº”çš„æ•°æ®æ¡¶è¿›è¡Œæ½œåœ¨åŒ¹é…æ¯”è¾ƒï¼Œå¤§å¤§å‡å°‘äº†ä¸å¿…è¦çš„æ¯”è¾ƒã€‚ä¾‹å¦‚ï¼Œè™½ç„¶ 4 å’Œ 8ï¼ˆåœ¨ä¸åŒçš„æ•°æ®æ¡¶ä¸­ï¼‰ä¸åŒ¹é…ï¼Œä½†åœ¨å¦ä¸€ä¸ªæ•°æ®æ¡¶ä¸­å´èƒ½æ‰¾åˆ°åŒ¹é…ï¼Œè¿™å°±å±•ç¤ºäº†è¿™ç§æ–¹æ³•æ˜¯å¦‚ä½•ç®€åŒ–æœç´¢è¿‡ç¨‹çš„ã€‚è¿™ç§é«˜æ•ˆçš„æŠ€æœ¯ä¸ä»…é€‚ç”¨äºè¿™é¡¹ä»»åŠ¡ï¼Œåœ¨æ•°æ®åº“æ“ä½œä¸­ä¹Ÿå¾ˆå¸¸ç”¨ï¼Œæœ¬è®²åº§å°†å¯¹æ­¤è¿›è¡Œè®¨è®ºã€‚
To further enhance the search efficiency, another practical technique involves using a modulo function for bucketing. For instance, applying a modulo four operation categorizes numbers into four buckets: 0, 1, 2, and 3. This categorization is mirrored on both sides of the comparison. Consequently, a number like 4 is placed in bucket 0, 1 in bucket 1, and so on, with 7 ending up in bucket 3 due to its modulo result. This method is equally applied to the dataset on the right side, establishing a parallel set of buckets numbered 0 through 3. For example, in the right dataset, 8 (modulo 0) is allocated to bucket 0, 7 (modulo 3) to bucket 3, and 2 (modulo 2) to bucket 2, with one bucket remaining empty. By comparing only the corresponding buckets for potential matches, this approach significantly minimizes unnecessary comparisons. For instance, while 4 and 8 (in separate buckets) do not match, a match is found in another bucket, showcasing how this method streamlines the search process. Such efficient techniques are not only practical for this task but are also commonly utilized in database operations, as will be discussed in this lecture.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404221431567.png" alt="image-20240404221431567" style="zoom:50%;" /> 

```
å› æ­¤ï¼Œä»Šå¤©æˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§ç±»å‹çš„å…³èŠ‚ç‚¹ï¼Œå³åµŒå¥—å¾ªç¯ã€å…³èŠ‚ç‚¹ã€Salmer å…³èŠ‚ç‚¹å’Œå“ˆå¸Œå…³èŠ‚ç‚¹ã€‚è¿™äº›å†…å®¹å°†åœ¨æ•°æ®åº“ç®¡ç†ç³»ç»Ÿä¸€ä¹¦çš„ç¬¬ 14 ç« ä¸­ä»‹ç»ã€‚
So today we will cover three types of joints, namely nested loops, joint, salmer joint, and hash joints. And these are covered in chapter 14 of our database management systems book. 
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404221833073.png" alt="image-20240404221833073" style="zoom: 50%;" /> 

**1ï¸âƒ£**Are very common and can be veryexpensive (cross product in the worst case)

**2ï¸âƒ£**There are many implementation techniques for join operations

**3ï¸âƒ£**Join techniques we will cover:

1. Nested-loops join
2. Sort-merge join
3. Hash join

```
éœ€è¦æé†’çš„æ˜¯ï¼Œæ•°æ®åº“ä¹‹æ‰€ä»¥ä¸“æ³¨äºä¼˜åŒ–è¿æ¥æ“ä½œï¼Œæ˜¯å› ä¸ºè¿æ¥æ“ä½œæœ¬èº«æˆæœ¬å¾ˆé«˜ã€‚æ‰§è¡Œäº¤å‰ä¹˜ç§¯ï¼ˆå®è´¨ä¸Šæ˜¯å°†æ¯ä¸ªå…ƒç´ ä¸å…¶ä»–å…ƒç´ ç»“åˆåœ¨ä¸€èµ·ï¼‰çš„æ•ˆç‡éå¸¸ä½ï¼Œå°¤å…¶æ˜¯å¯¹äºå¤§è§„æ¨¡æ•°æ®åº“è€Œè¨€ã€‚ä¸ºäº†é™ä½è¿™ç§ä½æ•ˆç‡ï¼Œæ•°æ®åº“é‡‡ç”¨äº†å„ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæˆ‘ä»¬ä»Šå¤©å°±æ¥æ¢è®¨ä¸€ä¸‹ã€‚è¿™äº›æŠ€æœ¯åŒ…æ‹¬æ’åºã€æ•£åˆ—å’Œå¾ªç¯ç­‰ã€‚æ‰€è®¨è®ºçš„æ¯ä¸ªç¤ºä¾‹éƒ½æ—¨åœ¨ä¿ƒä½¿äººä»¬æ€è€ƒè¿™äº›ç­–ç•¥å¦‚ä½•èƒ½æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ï¼Œä»è€Œçªå‡ºä¼˜åŒ–åœ¨æ•°æ®åº“ç®¡ç†ä¸­çš„é‡è¦æ€§ã€‚
As a reminder, the reason why databases focus on optimizing join operations is due to their inherently high cost. Performing a cross product, which essentially combines each element with every other element, proves to be highly inefficient, particularly for large-scale databases. To mitigate this inefficiency, databases employ various optimization techniques, as we will explore today. These techniques include sorting, hashing, and looping, among others. Each example discussed is designed to prompt consideration of how these strategies can significantly reduce computational overhead, highlighting the importance of optimization in database management.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404222936219.png" alt="image-20240404222936219" style="zoom: 50%;" /> 

Example:

```sql
SELECT * FROM Reserves R1, Sailors S1 WHERE R1.sid=S1.sid
```

**1ï¸âƒ£**In algebra: $R\bowtie{S}$ They are very common and need to be ğŸš—efully optimized.

**2ï¸âƒ£**R X S is large; so, R X S followed by a selection is inefficient.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404223237248.png" alt="image-20240404223237248" style="zoom:50%;" /> 

**3ï¸âƒ£**Join is associative and commutative:

1. AxB== BxA
2. Ax(BxC)==(AxB)xC

**4ï¸âƒ£**Cost metric : Number of pages; Number of I/O

```
åœ¨æ·±å…¥ç ”ç©¶ SQL å’Œå…³ç³»ä»£æ•°é¢†åŸŸæ—¶ï¼Œè¡¨ç¤ºè¿æ¥æ“ä½œçš„æ–¹æ³•è‡³å…³é‡è¦ã€‚æœ‰å‡ ç§æ–¹æ³•å¯ä»¥è¡¨è¾¾è¿æ¥ï¼šä½¿ç”¨è‡ªç„¶è¿æ¥ã€å†…éƒ¨è¿æ¥ï¼Œæˆ–è€…åƒå±å¹•ä¸Šæ˜¾ç¤ºçš„é‚£æ ·ï¼Œåˆ—å‡ºè¦è¿æ¥çš„è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¹¶åœ¨ WHERE å­å¥ä¸­æŒ‡å®šè¿æ¥æ¡ä»¶ã€‚è™½ç„¶åè€…å¯èƒ½ç±»ä¼¼äºäº¤å‰ä¹˜ç§¯ï¼Œä½†æ•°æ®åº“åœ¨è§£æé˜¶æ®µä¼šå°†å…¶è§£é‡Šä¸ºè‡ªç„¶è¿æ¥ï¼Œå°¤å…¶æ˜¯å½“è¿æ¥çš„è¡¨ä¸­æœ‰å…±åŒå±æ€§æ—¶--åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­è¡¨ç¤ºä¸º sidã€‚
When delving into the realm of SQL and relational algebra, the way we notate a join operation is crucial. There are a few methods to express joins: using a natural join, an inner join, or as displayed on the screen, by listing the tables to be joined, separated by a comma, and specifying the join condition in the WHERE clause. Though the latter may resemble a cross product, databases interpret this during the parsing phase as a natural join, particularly when there's a common attribute in the joined tablesâ€”denoted as sid in our example.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404222936219.png" alt="image-20240404222936219" style="zoom: 50%;" /> 

Example:

```sql
SELECT * FROM Reserves R1, Sailors S1 WHERE R1.sid=S1.sid
```

**1ï¸âƒ£**In algebra: $R\bowtie{S}$ They are very common and need to be ğŸš—efully optimized.

**2ï¸âƒ£**R X S is large; so, R X S followed by a selection is inefficient.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404223237248.png" alt="image-20240404223237248" style="zoom:50%;" /> 

**3ï¸âƒ£**Join is associative and commutative:

1. AxB== BxA
2. Ax(BxC)==(AxB)xC

**4ï¸âƒ£**Cost metric : Number of pages; Number of I/O

```
æœ€å¸¸è§çš„è¿æ¥ç±»å‹æ˜¯è¡¨å…±äº«ä¸€ä¸ªå…±åŒå±æ€§ï¼Œå…³ç³»ä»£æ•°ç”¨ R å’Œ S ä¹‹é—´çš„äº¤é›†ç¬¦å·æ¥è¡¨ç¤ºã€‚æ½œåœ¨çš„ä½æ•ˆæºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³ R x S è¡¨ç¤ºçš„äº¤ä¹˜ä¼šäº§ç”Ÿå¤§é‡è¾“å‡ºï¼Œä»è€Œä½¿æ“ä½œæˆæœ¬é«˜æ˜‚ã€‚ç„¶è€Œï¼Œè‡ªç„¶è¿æ¥å®è´¨ä¸Šæ˜¯ä¸€ç§å¤åˆè¿ç®—ç¬¦ï¼Œç†è®ºä¸Šå¯ä»¥é€šè¿‡äº¤å‰ä¹˜ç§¯ã€é€‰æ‹©å’ŒæŠ•å½±çš„åºåˆ—æ¥å®ç°ï¼Œä»è€Œç®€åŒ–äº†è¿æ¥è¿‡ç¨‹ã€‚
The most prevalent type of join is the one where tables share a common attribute, which relational algebra denotes with an intersection symbol between R and S. Given its frequency, database systems are heavily optimized for this type of join. The potential inefficiency stems from the fact that the cross productâ€”indicated by R x Sâ€”tends to yield an extensive output, making it a costly operation. However, natural joins streamline the process by essentially acting as a composite operator, theoretically achievable through a sequence of a cross product, followed by selection and projection.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404222936219.png" alt="image-20240404222936219" style="zoom: 50%;" /> 

Example:

```sql
SELECT * FROM Reserves R1, Sailors S1 WHERE R1.sid=S1.sid
```

**1ï¸âƒ£**In algebra: $R\bowtie{S}$ They are very common and need to be ğŸš—efully optimized.

**2ï¸âƒ£**R X S is large; so, R X S followed by a selection is inefficient.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404223237248.png" alt="image-20240404223237248" style="zoom:50%;" /> 

**3ï¸âƒ£**Join is associative and commutative:

1. AxB== BxA
2. Ax(BxC)==(AxB)xC

**4ï¸âƒ£**Cost metric : Number of pages; Number of I/O

```
åœ¨è¿æ¥æ“ä½œä¸­ï¼Œ"å·¦ "å’Œ "å³ "è¾“å…¥å…·æœ‰ç‰¹å®šçš„å«ä¹‰ã€‚å·¦ "è¾“å…¥ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º Rï¼‰è¢«ç§°ä¸º "å¤– "è¡¨ï¼Œè€Œ "å³ "è¾“å…¥ï¼ˆSï¼‰è¢«ç§°ä¸ºè¿æ¥çš„ "å†… "è¡¨ã€‚é‡è¦çš„æ˜¯ï¼Œä¸è¦æŠŠè¿™ä¸ªæœ¯è¯­ä¸è¿æ¥çš„ç±»å‹ï¼ˆå¦‚å†…è¿æ¥æˆ–å·¦/å³å¤–è¿æ¥ï¼‰æ··ä¸ºä¸€è°ˆï¼›åœ¨è¿™é‡Œï¼Œ"å¤– "å’Œ "å†… "åªæ˜¯åŒºåˆ†è¡¨åœ¨è¿æ¥è¯­æ³•ä¸­çš„ä½ç½®ã€‚
In the context of join operations, the terms 'left' and 'right' inputs acquire specific meanings. The 'left' input, or R in our case, is referred to as the 'outer' table, and the 'right' input, S, is known as the 'inner' table of the join. It's important not to conflate this terminology with the types of joins, such as inner joins or left/right outer joins; here, 'outer' and 'inner' simply distinguish the position of tables in the join syntax.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404222936219.png" alt="image-20240404222936219" style="zoom: 50%;" /> 

Example:

```sql
SELECT * FROM Reserves R1, Sailors S1 WHERE R1.sid=S1.sid
```

**1ï¸âƒ£**In algebra: $R\bowtie{S}$ They are very common and need to be ğŸš—efully optimized.

**2ï¸âƒ£**R X S is large; so, R X S followed by a selection is inefficient.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404223237248.png" alt="image-20240404223237248" style="zoom:50%;" /> 

**3ï¸âƒ£**Join is associative and commutative:

1. AxB== BxA
2. Ax(BxC)==(AxB)xC

**4ï¸âƒ£**Cost metric : Number of pages; Number of I/O

```
è”æ¥æœ¬èº«å…·æœ‰å…³è”æ€§å’Œäº¤æ¢æ€§ï¼Œè¿™æ„å‘³ç€æ“ä½œä¸­è¡¨çš„é¡ºåºä¸ä¼šå½±å“ç»“æœï¼ŒA ä¸ B çš„è”æ¥ç»“æœä¸ B ä¸ A çš„è”æ¥ç»“æœç›¸åŒã€‚è¿™ç§å…³è”ç‰¹æ€§å…è®¸æ•°æ®åº“çµæ´»åœ°é‡æ–°å®‰æ’è¿æ¥æ“ä½œï¼Œä»¥æ„å»ºæœ€æœ‰æ•ˆçš„æ‰§è¡Œè®¡åˆ’ã€‚æœ€åï¼Œè¿™äº›æ“ä½œçš„æˆæœ¬æ€»æ˜¯ä»¥æ‰€æ¶‰åŠçš„é¡µé¢æ•°æˆ– I/O æ“ä½œæ•°æ¥é‡åŒ–ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬è¯„ä¼°è¿æ¥æ€§èƒ½çš„ä¸€è´¯æ ‡å‡†ã€‚
Joins are inherently associative and commutative, meaning the order of tables in the operation doesn't affect the resultâ€”A joined with B will yield the same result as B joined with A. Likewise, when dealing with multiple joins, the sequence of operations can be varied without altering the outcome. This associative property allows databases the flexibility to rearrange join operations to construct the most efficient execution plan. In the end, the cost of these operations is invariably quantified by the number of pages or I/O operations involved, which remains our consistent metric for assessing the performance of joins.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224211936.png" alt="image-20240404224211936" style="zoom:50%;" /> 

Sailors (sid: integer, sname: string, rating: integer, age: real)
Reserves (sid: integer, bid: integer, day: dates, rname: string)

**1ï¸âƒ£**Sailors (S):

1. 80 tuples per page, 500 pages
2. NPages(S) = 500, NTuplesPerPage(S) = 80
3. NTuples(S) = 500*80 = 40000

**4ï¸âƒ£**Reserves (R):

1. 100 tuples per page, 1000 pages
2. NPages(R) = 1000, NTuplesPerPage(R) =100
3. NTuples(R) = 100000

```
å› æ­¤ï¼Œæˆ‘å°†é‡‡ç”¨æˆ‘åœ¨è¿‡å»å‡ æ¬¡å…³äºæ°´å…µå’Œåå¤‡å½¹çš„è®²åº§ä¸­ä½¿ç”¨çš„ç›¸åŒæ–¹æ¡ˆï¼Œå³æ°´å…µæœ‰ 500 é¡µï¼Œåå¤‡å½¹æœ‰ 1000 é¡µã€‚
So I will use the same scheme I used in the past couple of lectures of sailors and reserves where we have 500 pages in sailors and 1000 pages in reserves. 
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404222936219.png" alt="image-20240404222936219" style="zoom: 50%;" /> 

Example:

```sql
SELECT * FROM Reserves R1, Sailors S1 WHERE R1.sid=S1.sid
```

**1ï¸âƒ£**In algebra: $R\bowtie{S}$ They are very common and need to be ğŸš—efully optimized.

**2ï¸âƒ£**R X S is large; so, R X S followed by a selection is inefficient.

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404223237248.png" alt="image-20240404223237248" style="zoom:50%;" /> 

**3ï¸âƒ£**Join is associative and commutative:

1. AxB== BxA
2. Ax(BxC)==(AxB)xC

**4ï¸âƒ£**Cost metric : Number of pages; Number of I/O

```
æé†’ä¸€ä¸‹ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨è‡ªç„¶è¿æ¥ã€ç­‰ä»·è¿æ¥æ—¶ï¼Œæˆ‘ä»¬ä¼šæŸ¥æ‰¾ç‰¹å®šçš„åˆ—æ¥æœç´¢åŒ¹é…è®°å½•ã€‚å› æ­¤ï¼Œæƒ³è±¡ä¸€ä¸‹åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘åœ¨ç¬¬ä¸€åˆ—ä¸Šè¿›è¡Œè¿æ¥ï¼Œç„¶åæœç´¢åŒ¹é…çš„è®°å½•ã€‚
And to remind you when we are joining those with natural join, equi join, we will look for a particular column where we are searching for the matches. So imagine in this case, uh I'm joining over the first column and searching for the matching records. 
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224613298.png" alt="image-20240404224613298" style="zoom:50%;" /> 

**1ï¸âƒ£**For each tuple in the outerrelation R, we scan the entire innerrelation S

Pseudo code:(ä¼ªä»£ç )

```pseudocode
foreachtuple r in Rdo
	foreachtuples in Sdo
		if ri== sjthen add <r, s> to result
```

![image-20240404224709718](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224709718.png)  

**2ï¸âƒ£**Cost:

```sql
Cost (SNJL) = NPages(Outer) + NTuples(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (SNLJ)= 1000+100*1000*500 = 50001000 (I/O)
```

```
ç®€å•çš„åµŒå¥—å¾ªç¯è¿æ¥æ˜¯ä¸€ç§åŸºæœ¬ä½†é‡è¦çš„æ•°æ®åº“æ“ä½œã€‚è¿™ä¸ªè¿‡ç¨‹éœ€è¦æ‰«æ "å¤–å±‚ "å…³ç³»ä¸­çš„æ¯ä¸ªå…ƒç»„ï¼Œç„¶åä¸ "å†…å±‚ "å…³ç³»ä¸­çš„æ¯ä¸ªå…ƒç»„è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºåŒ¹é…çš„å…ƒç»„ã€‚åœ¨ä¼ªä»£ç ä¸­ï¼Œè¿™è¡¨ç¤ºä¸ºä¸¤ä¸ªåµŒå¥—å¾ªç¯ï¼Œå…¶ä¸­å¤–å±‚å…³ç³» R ä¸­çš„æ¯ä¸ªå…ƒç»„ r éƒ½ä¸å†…å±‚å…³ç³» S ä¸­çš„æ¯ä¸ªå…ƒç»„ s è¿›è¡Œæ¯”è¾ƒã€‚
The simple nested loops join is an elementary but crucial database operation. The process entails scanning each tuple in the 'outer' relation, which is then compared against every tuple in the 'inner' relation to find matches. In pseudocode, this is represented as two nested loops where each tuple r in the outer relation R is compared with each tuple s in the inner relation S. If a match is found according to the join condition, the tuple pair <r, s> is added to the result set.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224613298.png" alt="image-20240404224613298" style="zoom:50%;" /> 

**1ï¸âƒ£**For each tuple in the outerrelation R, we scan the entire innerrelation S

Pseudo code:(ä¼ªä»£ç )

```pseudocode
foreachtuple r in Rdo
	foreachtuples in Sdo
		if ri== sjthen add <r, s> to result
```

![image-20240404224709718](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224709718.png)  

**2ï¸âƒ£**Cost:

```sql
Cost (SNJL) = NPages(Outer) + NTuples(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (SNLJ)= 1000+100*1000*500 = 50001000 (I/O)
```

```
ä¸ºäº†ç›´è§‚åœ°è¯´æ˜è¿™ä¸€ç‚¹ï¼Œè¯·çœ‹å·¦ä¾§è¾“å…¥ï¼ˆä»¥è“è‰²è¡¨ç¤ºï¼Œæ ‡è®°ä¸º Rï¼‰ï¼Œæ¯æ¡è®°å½•éƒ½è¦ä¸å³ä¾§è¾“å…¥ï¼ˆå³ "å†…éƒ¨ "è¾“å…¥ï¼‰ä¸­çš„æ‰€æœ‰è®°å½•è¿›è¡Œæ ¸å¯¹ã€‚è¿™ä¸€æ“ä½œä¼šé‡å¤è¿›è¡Œï¼Œä¾æ¬¡æ£€æŸ¥å·¦ä¾§è¾“å…¥ä¸­çš„æ¯ä¸ªå…ƒç»„ï¼Œå¹¶å¯¹æ¯ä¸ªå…ƒç»„çš„å³ä¾§è¾“å…¥è¿›è¡Œå…¨é¢æ‰«æã€‚
To visualize this, consider the left input, depicted in blue and labeled as R, where each record is checked against all the records in the right input, the 'inner' input. This operation is repeated, progressing sequentially through each tuple of the left input and conducting a full scan of the right input for each one.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224613298.png" alt="image-20240404224613298" style="zoom:50%;" /> 

**1ï¸âƒ£**For each tuple in the outerrelation R, we scan the entire innerrelation S

Pseudo code:(ä¼ªä»£ç )

```pseudocode
foreachtuple r in Rdo
	foreachtuples in Sdo
		if ri== sjthen add <r, s> to result
```

![image-20240404224709718](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404224709718.png)  

**2ï¸âƒ£**Cost:

```sql
Cost (SNJL) = NPages(Outer) + NTuples(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (SNLJ)= 1000+100*1000*500 = 50001000 (I/O)
```

```
è¿™ç§è¿æ¥çš„æˆæœ¬æŒ‡æ ‡ç”±ä»ç£ç›˜è¯»å–çš„é¡µæ•°å†³å®šã€‚å·¦ä¾§è¾“å…¥ï¼ˆå³å¤–éƒ¨å…³ç³»ï¼‰ä¼šè¢«ç²¾ç¡®éå†ä¸€æ¬¡ï¼Œç›¸å½“äºå…¶æ€»é¡µæ•°ã€‚è‡³äºå³è¾¹çš„è¾“å…¥ï¼Œå³å†…éƒ¨å…³ç³»ï¼Œåˆ™è¦å¯¹å¤–éƒ¨å…³ç³»çš„æ¯ä¸ªå…ƒç»„éå†ä¸€æ¬¡ã€‚åœ¨æ•°å­¦ä¸Šï¼Œè¿™è¡¨ç¤ºä¸ºå¤–éƒ¨å…³ç³»ä¸­çš„å…ƒç»„æ•°ä¹˜ä»¥å†…éƒ¨å…³ç³»ä¸­çš„é¡µæ•°ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œå¤–å±‚å…³ç³»ä¸­æœ‰ 1000 ä¸ªé¡µé¢ï¼Œå†…å±‚å…³ç³»ä¸­æœ‰ 500 ä¸ªé¡µé¢ï¼Œå¤–å±‚å…³ç³»ä¸­æœ‰ 100 ä¸ªå…ƒç»„ï¼Œè¾“å…¥è¿™äº›æ•°å­—åï¼Œè®¡ç®—ç»“æœæ˜¾ç¤º I/O æ“ä½œçš„æ€»æˆæœ¬ä¸º 5000 ä¸‡æ¬¡ï¼Œè¿™åæ˜ äº†è¿™ç§è¿æ¥æ–¹æ³•çš„æ½œåœ¨é«˜æˆæœ¬ã€‚
The cost metric for this type of join is determined by the number of page reads from disk. The left input, or the outer relation, is traversed exactly once, which equates to the total number of its pages. As for the right input, or the inner relation, it is traversed once for each tuple of the outer relation. Mathematically, this is expressed as the number of tuples in the outer relation multiplied by the number of pages in the inner relation. Plugging in the numbers from our example, with 1000 pages in the outer relation and 500 pages in the inner, and 100 tuples in the outer relation, results in a computation that indicates a total cost of 50 million I/O operations, reflecting the potentially high cost of this join method.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225314265.png" alt="image-20240404225314265" style="zoom:50%;" /> 

**1ï¸âƒ£**For each page of R

1. get each page of S
2. write out matching pairs of tuples <r, s>, where r is in R-page and S is in S-page

**2ï¸âƒ£**Pseudo code:

![image-20240404225505833](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225505833.png) 

```pseudocode
foreach page bRin R do
	foreach page bS in S do
		foreach tuple r in bR do
			foreach tuple s in bS do
				if ri== sj then add <r, s> to result
```

```sql
Cost (PNJL) = NPages(Outer) + NPages(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (PNLJ)= 1000+1000*500= 501000 (I/O)
```
```
ä¸ºäº†ä¼˜åŒ–è¿æ¥æ“ä½œï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨é¢å‘é¡µé¢çš„æ–¹æ³•ï¼Œè€Œä¸æ˜¯é€ä¸ªå…ƒç»„è¿­ä»£çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†è¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³å½“ä¸€æ¡è®°å½•è¢«æ£€ç´¢åˆ°å†…å­˜ä¸­æ—¶ï¼ŒåŒ…å«è¯¥è®°å½•çš„æ•´ä¸ªé¡µé¢éƒ½ä¼šè¢«è®¿é—®ã€‚å› æ­¤ï¼Œ"é¢å‘é¡µé¢çš„åµŒå¥—å¾ªç¯è¿æ¥ "åˆ©ç”¨äº†è¿™ä¸€ç‚¹ï¼Œå°†å·¦ä¾§è¾“å…¥å–å›çš„é¡µé¢ä¸­çš„æ‰€æœ‰è®°å½•ä¸å³ä¾§è¾“å…¥ç›¸åº”é¡µé¢ä¸­çš„æ‰€æœ‰è®°å½•è¿›è¡Œæ£€æŸ¥ã€‚è¿™ç§é€é¡µæ¯”è¾ƒçš„è¿‡ç¨‹ä¸€ç›´æŒç»­åˆ°æ£€æŸ¥å®Œå·¦ä¾§è¾“å…¥çš„æ‰€æœ‰é¡µé¢ä¸ºæ­¢ã€‚
In an effort to optimize the join operation, we can adopt a page-oriented approach rather than tuple-by-tuple iteration. This method leverages the fact that when a single record is retrieved into memory, the entire page containing that record is accessed. Therefore, the Page-Oriented Nested Loops Join capitalizes on this by checking all records within the fetched page of the left input against all records in the corresponding page of the right input. This page-by-page comparison proceeds until all pages from the left input have been examined.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225314265.png" alt="image-20240404225314265" style="zoom:50%;" /> 

**1ï¸âƒ£**For each page of R

1. get each page of S
2. write out matching pairs of tuples <r, s>, where r is in R-page and S is in S-page

**2ï¸âƒ£**Pseudo code:

![image-20240404225505833](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225505833.png) 

```pseudocode
foreach page bRin R do
	foreach page bS in S do
		foreach tuple r in bR do
			foreach tuple s in bS do
				if ri== sj then add <r, s> to result
```

```sql
Cost (PNJL) = NPages(Outer) + NPages(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (PNLJ)= 1000+1000*500= 501000 (I/O)
```
```
ä¸‹é¢çš„ä¼ªä»£ç æ¼”ç¤ºäº†è¿™ä¸€è¿‡ç¨‹ï¼šå¯¹äºå·¦è¾“å…¥ R ä¸­çš„æ¯ä¸€é¡µï¼Œå³è¾“å…¥ S ä¸­çš„æ¯ä¸€é¡µéƒ½ä¼šè¢«å¸¦å…¥å†…å­˜ã€‚åœ¨è¿™äº›é¡µé¢ä¸­ï¼Œæˆ‘ä»¬ä¼šéå†æ¯ä¸ªå…ƒç»„ï¼Œå°† R ä¸­çš„å…ƒç»„ä¸ S ä¸­çš„å…ƒç»„è¿›è¡Œæ¯”è¾ƒã€‚
The pseudocode demonstrates this process: for each page in the left input R, every page in the right input S is brought into memory. Within these pages, we then iterate through each tuple, comparing tuples from R to those in S. When a match is found, the tuple pair is added to the result set.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225314265.png" alt="image-20240404225314265" style="zoom:50%;" /> 

**1ï¸âƒ£**For each page of R

1. get each page of S
2. write out matching pairs of tuples <r, s>, where r is in R-page and S is in S-page

**2ï¸âƒ£**Pseudo code:

![image-20240404225505833](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404225505833.png) 

```pseudocode
foreach page bRin R do
	foreach page bS in S do
		foreach tuple r in bR do
			foreach tuple s in bS do
				if ri== sj then add <r, s> to result
```

```sql
Cost (PNJL) = NPages(Outer) + NPages(Outer) * NPages(Inner)
```

**3ï¸âƒ£**Our example:

```sql
Cost (PNLJ)= 1000+1000*500= 501000 (I/O)
```
```
åœ¨è¯„ä¼°è¿™ç§æ–¹æ³•çš„æˆæœ¬æ—¶ï¼Œä»¥é¡µé¢ä¸ºå¯¼å‘çš„åµŒå¥—å¾ªç¯è¿æ¥æ˜¾ç„¶æœ‰å¾ˆå¤§çš„æ”¹è¿›ã€‚å·¦ä¾§è¾“å…¥ R ä»ä¼šè¢«éå†ä¸€æ¬¡ï¼Œç›¸å½“äºå…¶é¡µé¢æ•°ã€‚ä½†æ˜¯ï¼Œå³ä¾§è¾“å…¥ S çš„éå†æ¬¡æ•°ä¸å·¦ä¾§è¾“å…¥çš„é¡µæ•°ç›¸åŒï¼Œè€Œä¸æ˜¯å…¶å›¾å…ƒæ•°ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼ŒR ä¸­æœ‰ 1000 ä¸ªé¡µé¢ï¼ŒS ä¸­æœ‰ 500 ä¸ªé¡µé¢ï¼Œå› æ­¤ I/O æ“ä½œçš„æˆæœ¬ä¸º 501,000 æ¬¡ï¼Œæ¯”ç®€å•åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬å¤§å¹…é™ä½ã€‚è¿™ç§æ•ˆç‡çš„æé«˜å¾—ç›Šäºåœ¨è¿›å…¥ä¸‹ä¸€ä¸ªé¡µé¢ä¹‹å‰ï¼Œå¯¹æ‰€è®¿é—®é¡µé¢ä¸­çš„æ‰€æœ‰è®°å½•è¿›è¡Œäº†ç­–ç•¥æ€§æ£€æŸ¥ï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘äº†æ‰€éœ€çš„é¡µé¢è®¿é—®æ€»æ•°ã€‚
When evaluating the cost of this approach, it becomes clear that the Page-Oriented Nested Loops Join offers a significant improvement. The left input,  R , is still traversed once, equating to the number of its pages. However, the right input,  S , is traversed as many times as there are pages in the left input, rather than its tuples. Applying this to our example, with 1000 pages in  R  and 500 in  S , results in a cost of 501,000 I/O operations, a drastic reduction from the cost of a simple nested loops join. This efficiency gain is due to the strategic check of all records within an accessed page before proceeding to the next, hence minimizing the total number of page accesses required.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230005157.png" alt="image-20240404230005157" style="zoom:33%;" /> 

```
è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹åˆ°ç›®å‰ä¸ºæ­¢çš„è®¨è®ºã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè¾“å…¥ï¼šä¸€ä¸ªåœ¨è¿™é‡Œï¼Œç”¨ä¸€ç§é¢œè‰²æ ‡è®°ï¼›å¦ä¸€ä¸ªåœ¨è¿™é‡Œï¼Œç”¨å¦ä¸€ç§é¢œè‰²æ ‡è®°ã€‚æˆ‘ä»¬çš„å†…å­˜æ¯”ä¸¤ä¸ªè¾“å…¥éƒ½è¦å°ï¼Œæ‰€æœ‰çš„å¤„ç†éƒ½åœ¨å†…å­˜ä¸­è¿›è¡Œã€‚ä¸ºäº†æ‰§è¡Œè¿æ¥ï¼Œæˆ‘ä»¬ä»å·¦ä¾§è¾“å…¥ç«¯å’Œå³ä¾§è¾“å…¥ç«¯å„å¼•å…¥ä¸€é¡µï¼Œç¡®ä¿æœ‰ä¸€é¡µç•™ç»™ç»“æœã€‚åœ¨è¿™ä¸ªç©ºé—´ä¸­ï¼Œæˆ‘ä»¬æ£€æŸ¥ä¸¤ä¸ªè¾“å…¥çš„æ‰€æœ‰è®°å½•ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ç»“æœé¡µä¸­ã€‚è¿™æè¿°äº†é¢å‘é¡µé¢çš„åµŒå¥—å¾ªç¯æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¯æ¬¡å¤„ç†æ¥è‡ªä¸¤ä¸ªè¾“å…¥çš„ä¸€é¡µæ•°æ®ã€‚
Let's summarize our discussion so far. Imagine we have two inputs: one here, marked in one color, and another here, marked in a different color. Our memory, which is smaller than both inputs, is where all processing occurs. To perform a join, we bring in one page from the left input and one page from the right input, ensuring we have a page reserved for results. In this space, we examine all records from both inputs, storing the outcomes in the results page. This describes the page-oriented nested loops approach, which processes data one page at a time from both inputs.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230124884.png" alt=" " style="zoom:33%;" /> 

```
åœ¨ç°å®ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æ‹¥æœ‰æ›´å¤šçš„å¯ç”¨å†…å­˜ï¼Œè€Œä¸æ˜¯ä»…å¤Ÿå­˜å‚¨å·¦ä¾§è¾“å…¥å’Œå³ä¾§è¾“å…¥çš„å•ä¸ªé¡µé¢ã€‚æˆ‘ä»¬è¦è®¨è®ºçš„ä¸‹ä¸€ç§è¿æ¥æ–¹å¼å°±åˆ©ç”¨äº†è¿™ä¸€äº‹å®ï¼Œåˆ©ç”¨æ•´ä¸ªå¯ç”¨å†…å­˜ç©ºé—´æ¥æé«˜æ•ˆç‡ã€‚æˆ‘ä»¬ä»å°†ä¸ºç»“æœå’Œå³è¾“å…¥å„ä¿ç•™ä¸€é¡µï¼Œä½†å°†å¯¹æ–¹æ³•è¿›è¡Œä¼˜åŒ–ï¼Œä»¥å……åˆ†åˆ©ç”¨é¢å¤–çš„å†…å­˜ç©ºé—´ã€‚
In reality, we typically have more memory available than just enough to store a single page from the left input and one from the right. The next type of join we will discuss takes advantage of this fact, utilizing the entire available memory space for improved efficiency. We will still reserve one page for the result and one page for the right input, but the approach will be optimized to make full use of the additional memory space.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230424907.png" alt="image-20240404230424907" style="zoom: 33%;" /> 

```
å¯¹äºå·¦ä¾§è¾“å…¥ï¼Œæˆ‘ä»¬ä¼šåœ¨ç©ºé—´å…è®¸çš„æƒ…å†µä¸‹åœ¨å†…å­˜ä¸­åˆ†é…å°½å¯èƒ½å¤šçš„é¡µé¢ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬å·²ç»å­˜å‚¨äº†å‰å››é¡µï¼Œä¸ºäº†è®©åœºæ™¯æ›´æœ‰è¶£ï¼Œæˆ‘ä»¬å‡è®¾è¿˜æœ‰æ›´å¤šå¯ç”¨é¡µé¢ã€‚å°†è¿™å››é¡µåŠ è½½åˆ°å†…å­˜åï¼Œæˆ‘ä»¬å°†é€é¡µå¤„ç†å·¦ä¾§è¾“å…¥ã€‚å¯¹äºæ”¾å…¥å†…å­˜çš„æ¯ä¸€é¡µï¼Œæˆ‘ä»¬éƒ½è¦å°†å…¶ä¸å·²å­˜å‚¨åœ¨å†…å­˜ä¸­çš„æ‰€æœ‰é¡µé¢è¿›è¡Œæ¯”è¾ƒã€‚å®Œæˆè¿™äº›æ¯”è¾ƒåï¼Œæˆ‘ä»¬å°†ç»§ç»­æ’å…¥ä¸‹ä¸€é¡µï¼Œå¹¶å†æ¬¡ä¸å†…å­˜ä¸­çš„æ‰€æœ‰é¡µé¢è¿›è¡Œæ¯”è¾ƒï¼Œç„¶åå†ç»§ç»­å¤„ç†ã€‚
For the left input, we allocate as many pages in memory as space permits. Imagine we've stored the first four pages, and to make the scenario more intriguing, let's say there are more pages available. Once these four pages are loaded into memory, we process the left input page by page. For each page placed in memory, we compare it against all pages already stored there. After completing these comparisons, we move on to insert the next page, again comparing it against all pages in memory before proceeding further.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230744120.png" alt="image-20240404230744120" style="zoom: 33%;" /> 

```
åœ¨å®Œæˆå¯¹æ•´ä¸ªå³ä¾§è¾“å…¥çš„ä¸€æ¬¡ä¼ é€’åï¼Œæˆ‘ä»¬å¯ä»¥ä¸¢å¼ƒå†…å­˜ä¸­çš„ç°æœ‰é¡µé¢ã€‚è¿™äº›é¡µé¢å¯ä»¥è¿”å›åˆ°å®ƒä»¬çš„æºå¤´ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è·å–ä¸‹ä¸€ä¸ªå¤§çš„é¡µé¢å—ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨å†…å­˜ä¸­è¿›è¡Œå¤„ç†ã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬æ ¹æ®å·¦ä¾§è¾“å…¥ä¾æ¬¡æ£€æŸ¥æ¯ä¸ªæ–°é¡µé¢ï¼Œä»ç¬¬ä¸€é¡µå¼€å§‹ï¼Œç„¶åå†æ£€æŸ¥åç»­é¡µé¢ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å¤§å¤§å‡å°‘å¯¹å³ä¾§è¾“å…¥æ‰€éœ€çš„æ£€æŸ¥æ¬¡æ•°ã€‚åœ¨æˆ‘çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦å¯¹å³ä¾§è¾“å…¥è¿›è¡Œä¸¤æ¬¡æ£€æŸ¥ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä¸€æ¬¡æ€§åœ¨å†…å­˜ä¸­å­˜å‚¨ä¸€å¤§å—å†…å®¹ï¼Œä»è€Œæ›´é«˜æ•ˆåœ°å®Œæˆæ£€æŸ¥ã€‚
After completing a single pass over the entire right input, we can disğŸš—d the existing pages from memory. These can be returned to their source, allowing us to fetch the next large block of pages and store them in memory for processing. This process involves sequentially checking each new page against the left input, starting from the first page and moving on to subsequent pages. By doing this, we significantly reduce the number of passes required over the right input. In my example, we only need two passes over the right input because we can store a large chunk of it in memory at once, thus completing the pass more efficiently.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230824781.png" alt="image-20240404230824781" style="zoom:33%;" /> 

```
åœ¨å†…å­˜ä¸­å­˜å‚¨ä¸‹ä¸€ä¸ªå¤§å—åï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬æ€»å…±æœ‰ 8 ä¸ªé¡µé¢ï¼Œæˆ‘ä»¬å°±ç»“æŸäº†å¤„ç†è¿‡ç¨‹ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬åªéœ€å¯¹æ­£ç¡®çš„è¾“å…¥è¿›è¡Œä¸¤æ¬¡ä¼ é€’å°±å®Œæˆäº†å¤„ç†ã€‚è¿™ç§æ•ˆç‡æ˜¯æˆ‘ä»¬ä¸‹ä¸€ä¸ªè¿æ¥æ–¹æ³•çš„åŸºçŸ³ï¼Œå®ƒåˆ©ç”¨è¿™ç§æ–¹æ³•ä¼˜åŒ–äº†æ•°æ®å¤„ç†ã€‚
After storing the next large chunk in memory and considering that we have a total of eight pages, we conclude the process. Thus, we complete our processing with just two passes over the right input. This efficiency is the cornerstone of our next join method, which leverages this approach to optimize data processing.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230919992.png" alt="image-20240404230919992" style="zoom:50%;" /> 

**1ï¸âƒ£**Page-oriented NL doesn'texploit extra memory buffers

**2ï¸âƒ£**Alternative approach:

- Use one page as an input buffer for scanning the inner S, one page as the output buffer, and use all remaining pages to hold â€˜blockâ€™of outer R

**3ï¸âƒ£**For each matching tuple r in R-block, s in S-page, add <r, s> to result. Then read next R-block, scan S, etc

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231011499.png" alt="image-20240404231011499" style="zoom:67%;" /> 

```
æˆ‘ä»¬æ¢ç´¢çš„ä¸‹ä¸€ä¸ªæŠ€æœ¯æ˜¯å—åµŒå¥—å¾ªç¯è¿æ¥ï¼Œæ—¨åœ¨æœ€å¤§é™åº¦åœ°åˆ©ç”¨å¯ç”¨å†…å­˜ã€‚è¿™ç§æ–¹æ³•æ˜¯å°½å¯èƒ½å¤šåœ°å­˜å‚¨å·¦ä¾§è¾“å…¥çš„é¡µé¢ï¼ŒåŒæ—¶ä¸ºå³ä¾§è¾“å…¥çš„ä¸€ä¸ªé¡µé¢å’Œè¾“å‡ºçš„å¦ä¸€ä¸ªé¡µé¢é¢„ç•™å†…å­˜ã€‚å‡è®¾æˆ‘ä»¬çš„æ•°æ®åº“å…³ç³»æ˜¯å­˜å‚¨åœ¨ç£ç›˜ä¸Šçš„ R å’Œ Sï¼Œå¯ç”¨å†…å­˜ä¸º B é¡µï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¸ºè¾“å…¥ R åˆ†é… B å‡ 2 é¡µã€‚è¿™ç§å¾ªç¯ç¡®ä¿äº†å†…å­˜çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œæ€»æœ‰ä¸€ä¸ªæ’æ§½ä¸“é—¨ç”¨äºç´¯ç§¯è¿æ¥ç»“æœã€‚å¦‚æœè¾“å‡ºç»“æœè¶…å‡ºäº†åˆ†é…çš„é¡µé¢ï¼Œåˆ™ä¼šæ— ç¼å†™å…¥ç£ç›˜ï¼Œä»è€Œç¡®ä¿æŒç»­å¤„ç†è€Œä¸ä¼šå‡ºç°å†…å­˜æº¢å‡ºã€‚
The next technique we explore is the Block Nested Loops Join, designed to maximize the use of available memory. This method involves storing as many pages from the left input as possible while reserving memory for one page from the right input and another for the output. Assuming our database relations are R and S stored on disk, and the available memory is B pages, we allocate B minus two pages for the input R. We process the input S one page at a timeâ€”loading a page, using it for joins, then removing it to make room for the next. This cycle ensures efficient use of memory, with one slot always dedicated to accumulating the join results. Should the output exceed the allocated page, it is seamlessly written to disk, ensuring continuous processing without memory overflow.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231122285.png" alt="image-20240404231122285" style="zoom: 50%;" /> 

```sql
Cost (BNJL) = NPages(Outer) + NBlocks(Outer) * NPages(Inner)
```

![image-20240404231157593](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231157593.png) 

**1ï¸âƒ£**NBlocks(Outer) = $[\cfrac{NPages(Outer)}{B-2}]$

**2ï¸âƒ£**Our example:

Letâ€™s say we have 102 pages of space in memory, and consider Reserves (R) as the outer and Sailors (S) as the inner table.

```sql
NBlocks(R) = 1000/(102-2) = 10
Cost(BNLJ) = 1000+ 10* 500= 6000 I/O
```

```
å—åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬å…¬å¼è€ƒè™‘äº†å·¦è¾“å…¥çš„æ¯ä¸ªå—éƒ½éœ€è¦éå†æ•´ä¸ªå³è¾“å…¥çš„å¿…è¦æ€§ã€‚å› æ­¤ï¼Œè®¡ç®—å…¬å¼ä¸ºå·¦è¾“å…¥çš„é¡µæ•°åŠ ä¸Šå·¦è¾“å…¥çš„å—æ•°ä¸å³è¾“å…¥çš„é¡µæ•°çš„ä¹˜ç§¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸¤ä¸ªåŒºå—ç”¨äºéå†å…³ç³» Sï¼Œé‚£ä¹ˆæˆ‘ä»¬è®¡ç®—çš„åŒºå—æ•°å°±æ˜¯å·¦ä¾§å…³ç³»çš„æ€»é¡µæ•°é™¤ä»¥ B å†å‡å» 2ã€‚è¿™ä¸€æ¨å¯¼è€ƒè™‘äº†ä¸ºå³ä¾§è¾“å…¥å’Œè¾“å‡ºå„ä¿ç•™ä¸€ä¸ªé¡µé¢çš„æƒ…å†µï¼Œè§£é‡Šäº†å¦‚ä½•é€šè¿‡ B å‡ 2 æ¥æœ‰æ•ˆåœ°ç¡®å®šåŒºå—æ•°ã€‚
The cost formula for the Block Nested Loops Join accounts for the necessity to traverse the entire right input for each block of the left input. Thus, the formula is the number of pages in the left input plus the product of the number of blocks in the left input and the number of pages in the right input. For example, if we have two blocks for traversing relation S, we calculate the number of blocks as the total number of pages in the left relation divided by B minus two. This deduction accounts for the pages reserved for one input from the right and one for the output, explaining the division by B minus two to determine the block count efficiently.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404230919992.png" alt="image-20240404230919992" style="zoom:50%;" /> 

**1ï¸âƒ£**Page-oriented NL doesn'texploit extra memory buffers

**2ï¸âƒ£**Alternative approach:

- Use one page as an input buffer for scanning the inner S, one page as the output buffer, and use all remaining pages to hold â€˜blockâ€™of outer R

**3ï¸âƒ£**For each matching tuple r in R-block, s in S-page, add <r, s> to result. Then read next R-block, scan S, etc

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231011499.png" alt="image-20240404231011499" style="zoom:67%;" />  

```
å¦‚æœæˆ‘ä»¬è€ƒè™‘åˆ°å…³ç³» R ç”± 10 é¡µç»„æˆï¼Œè€Œæˆ‘ä»¬çš„å†…å­˜å®¹é‡åœ¨è€ƒè™‘äº†å³è¾“å…¥å’Œå³è¾“å‡ºå„ä¸€é¡µï¼ˆB å‡ 2ï¼‰åï¼Œå…è®¸ä¸€æ¬¡å­˜å‚¨ 5 é¡µå…³ç³» Rï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ€ç»ˆä¼šæœ‰ä¸¤ä¸ªåŒºå—ï¼ˆ10 é™¤ä»¥ 5ï¼‰ã€‚è¿™å°±å¯¼è‡´æˆ‘ä»¬åŸºæœ¬ä¸Šéœ€è¦å¯¹å³ä¾§è¾“å…¥è¿›è¡Œä¸¤æ¬¡ä¼ é€’ï¼Œå¯¹åº”äºå…³ç³» R çš„ä¸¤ä¸ªå¤„ç†å—ã€‚
If we consider a scenario where relation R consists of 10 pages and our memory capacity, after accounting for one page each for the right input and output (B minus 2), allows for storing 5 pages of relation R at a time, we end up with two blocks (10 divided by 5). This results in essentially requiring two passes over the right input, corresponding to the two blocks of relation R being processed.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231122285.png" alt="image-20240404231122285" style="zoom: 50%;" /> 

```sql
Cost (BNJL) = NPages(Outer) + NBlocks(Outer) * NPages(Inner)
```

![image-20240404231157593](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231157593.png) 

**1ï¸âƒ£**NBlocks(Outer) = $[\cfrac{NPages(Outer)}{B-2}]$

**2ï¸âƒ£**Our example:

Letâ€™s say we have 102 pages of space in memory, and consider Reserves (R) as the outer and Sailors (S) as the inner table.

```sql
NBlocks(R) = 1000/(102-2) = 10
Cost(BNLJ) = 1000+ 10* 500= 6000 I/O
```

```
åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨æœ‰ 102 é¡µå¯ç”¨å†…å­˜çš„æƒ…å†µä¸‹æ£€æŸ¥ "å—åµŒå¥—å¾ªç¯è¿æ¥"ã€‚æˆ‘ä»¬å°†å…¶åº”ç”¨åˆ°ä¹‹å‰æ¶‰åŠ "å‚¨å¤‡"ï¼ˆRï¼‰å’Œ "æ°´æ‰‹"ï¼ˆSï¼‰å…³ç³»çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ã€‚ä¸ºäº†å¯åŠ¨è®¡ç®—ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šå…³ç³» R æ‰€éœ€çš„å—æ•°ï¼Œè®¡ç®—å…¬å¼ä¸ºæ€»é¡µæ•°ï¼ˆ1000ï¼‰é™¤ä»¥å¯ç”¨å†…å­˜é¡µæ•°å‡ 2ï¼Œå¾—å‡º 10 ä¸ªå—ã€‚
In this example, we examine the Block Nested Loops Join given a scenario where we have 102 pages of memory available, a number selected for simplicity. We apply this to our previous case study involving the 'Reserves' (R) and 'Sailors' (S) relations. To initiate the computation, we first determine the number of blocks required for relation R, which can be calculated as the total number of pages (1000) divided by the number of available memory pages minus two, resulting in 10 blocks.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231122285.png" alt="image-20240404231122285" style="zoom: 50%;" /> 

```sql
Cost (BNJL) = NPages(Outer) + NBlocks(Outer) * NPages(Inner)
```

![image-20240404231157593](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231157593.png) 

**1ï¸âƒ£**NBlocks(Outer) = $[\cfrac{NPages(Outer)}{B-2}]$

**2ï¸âƒ£**Our example:

Letâ€™s say we have 102 pages of space in memory, and consider Reserves (R) as the outer and Sailors (S) as the inner table.

```sql
NBlocks(R) = 1000/(102-2) = 10
Cost(BNLJ) = 1000+ 10* 500= 6000 I/O
```

```
åœ¨ç¡®å®šå…³ç³» R æœ‰ 10 ä¸ªæ•°æ®å—åï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªæ•°æ®å—ä¸æ•´ä¸ªå…³ç³» S è¿›è¡Œä¸€æ¬¡è¿­ä»£ã€‚è¿™ä¸€æ“ä½œä¼šäº§ç”Ÿä¸€ä¸ªè¿æ¥æˆæœ¬å…¬å¼ï¼šå·¦ä¾§è¾“å…¥çš„å¤§å°ï¼ˆ1000 é¡µï¼‰åŠ ä¸ŠåŒºå—æ•°ï¼ˆ10ï¼‰å’Œå³ä¾§è¾“å…¥çš„å¤§å°ï¼ˆ500 é¡µï¼‰çš„ä¹˜ç§¯ã€‚å› æ­¤ï¼ŒI/O æ“ä½œæ€»æˆæœ¬ä¸º 6000 æ¬¡é¡µé¢è®¿é—®ã€‚è¿™ä¸€æ•°å­—å¤§å¤§ä½äºæˆ‘ä»¬æœ€åˆç¤ºä¾‹ä¸­ä»¤äººæœ›è€Œå´æ­¥çš„ 5000 ä¸‡æ¬¡ I/O æ“ä½œçš„æˆæœ¬ã€‚è¿™ç§ä¼˜åŒ–æœ‰æ•ˆåœ°è¯æ˜äº†é€šè¿‡å‡å°‘å¯¹æ•°æ®çš„è®¿é—®æ¬¡æ•°å¯ä»¥è·å¾—æ˜¾è‘—çš„æ€§èƒ½æå‡--è¿™æ˜¯æ•°æ®åº“æ“ä½œä¸­è‡³å…³é‡è¦çš„ä¼˜åŒ–ï¼Œå¯ä»¥å°†æŸ¥è¯¢å“åº”æ—¶é—´ä»æ•°å¤©ç¼©çŸ­åˆ°æ•°ç§’ï¼Œè€Œè¿™æ­£æ˜¯æ•°æ®åº“æ€§èƒ½è°ƒæ•´çš„æœ€ç»ˆç›®æ ‡ã€‚
Upon establishing that there are 10 blocks for relation R, we proceed by iterating over each block against the entire relation S once. This operation yields a formula for the join cost: the size of the left input (1000 pages) added to the product of the number of blocks (10) and the size of the right input (500 pages). The total I/O operation cost is, therefore, 6,000 page accesses. This figure is drastically lower than the prohibitive cost of 50 million I/O operations from our original example. Such optimization effectively demonstrates the significant performance gains that can be achieved by reducing the number of passes over the dataâ€”a crucial optimization in database operations that can turn query response times from days into seconds, which is the ultimate goal in database performance tuning.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231631994.png" alt="image-20240404231631994" style="zoom:50%;" /> 

```
åœ¨æ¢è®¨äº†å¯¹ä¸¤ä¸ªè¾“å…¥å…³ç³»è¿›è¡Œå¾ªç¯çš„æ¦‚å¿µåï¼Œæˆ‘ä»¬ç°åœ¨æ¥çœ‹çœ‹å‰é¢ç®€è¦æåˆ°çš„ç¬¬äºŒç§æ–¹æ³•ï¼šå¯¹ä¸¤ä¸ªè¾“å…¥å…³ç³»ä¸­çš„è®°å½•è¿›è¡Œæ’åºã€‚è¿™ç§ç­–ç•¥ä½¿æˆ‘ä»¬åªéœ€éå†ä¸¤ä¸ªå…³ç³»ä¸€æ¬¡ï¼Œé€šè¿‡æŒ‰é¢„å®šé¡ºåºæ’åˆ—è®°å½•æ¥ç®€åŒ–æµç¨‹ï¼Œä»è€Œæé«˜æ¯”è¾ƒå’ŒåŒ¹é…çš„æ•ˆç‡ã€‚
Having explored the concept of looping through both inputs, we now turn to a second approach briefly mentioned earlier: sorting records in both inputs. This strategy enables us to traverse both relations just once, streamlining the process by aligning the records in a predetermined order to facilitate more efficient comparison and matching.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231751282.png" alt="image-20240404231751282" style="zoom:50%;" /> 

**1ï¸âƒ£****Sort** R and S on the join column, then scan them to do a **merge**(on join column), and output result tuples

![image-20240404231818521](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231818521.png) 

**2ï¸âƒ£**Sorted R is scanned once;

**3ï¸âƒ£**Each S group of the same key values is scanned once per matching R tuple (typically means Sorted S is scanned once too).

**4ï¸âƒ£**Useful when:

1. one or both inputs are already sorted on join attribute(s)
2. output is required to be sorted on join attributes(s)

```
æ’åº-åˆå¹¶è¿æ¥ç®—æ³•çš„è¿è¡ŒåŸç†ç®€å•è€Œæœ‰æ•ˆã€‚é¦–å…ˆï¼Œå®ƒæ ¹æ®è¿æ¥é”®å¯¹ R å’Œ S è¿™ä¸¤ä¸ªè¾“å…¥è¿›è¡Œæ’åºã€‚ç„¶åï¼Œå®ƒåŒæ—¶éå†ä¸¤ä¸ªå·²æ’åºçš„è¾“å…¥ï¼Œå¯»æ‰¾åŒ¹é…çš„é”®ã€‚æ‰¾åˆ°åŒ¹é…åï¼Œç›¸åº”çš„å›¾å…ƒå°±ä¼šè¢«è¿æ¥èµ·æ¥ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šä¾æ¬¡è¿›è¡Œï¼Œç›´åˆ°ä¸¤ä¸ªè¾“å…¥ä¸­çš„æ‰€æœ‰å…ƒç´ éƒ½å®Œå…¨æ¯”è¾ƒè¿‡ä¸€æ¬¡ä¸ºæ­¢ã€‚è¿™ç§æ–¹æ³•çš„é«˜æ•ˆä¹‹å¤„åœ¨äºï¼Œä¸€æ—¦ä¸¤ä¸ªè¾“å…¥éƒ½æ’åºå®Œæ¯•ï¼Œå°±å¯ä»¥å¯¹å…¶è¿›è¡Œå•ç¨‹æ“ä½œï¼Œæ— éœ€åµŒå¥—å¾ªç¯ï¼Œå› æ­¤æ˜¯ä¸€ç§éå¸¸ç²¾ç®€çš„æ–¹æ³•ã€‚
The sort-merge join algorithm operates on a simple yet effective principle. Firstly, it sorts both inputs, R and S, based on the join key. Then, it concurrently traverses both sorted inputs, looking for matching keys. When a match is found, the corresponding tuples are joined. This process continues sequentially until all elements of both inputs have been compared exactly once. The efficiency of this method lies in its single-pass operation over both inputs once they are sortedâ€”there's no need for nested looping, making it a very streamlined approach.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231751282.png" alt="image-20240404231751282" style="zoom:50%;" /> 

**1ï¸âƒ£****Sort** R and S on the join column, then scan them to do a **merge**(on join column), and output result tuples

![image-20240404231818521](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404231818521.png) 

**2ï¸âƒ£**Sorted R is scanned once;

**3ï¸âƒ£**Each S group of the same key values is scanned once per matching R tuple (typically means Sorted S is scanned once too).

**4ï¸âƒ£**Useful when:

1. one or both inputs are already sorted on join attribute(s)
2. output is required to be sorted on join attributes(s)

```
ä¸è¿‡ï¼Œåˆå§‹æ’åºæ­¥éª¤å¯èƒ½ä¼šè€—è´¹å¤§é‡èµ„æºã€‚æˆ‘ä»¬å°†è¯¦ç»†æ¢è®¨ç›¸å…³çš„æˆæœ¬ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç°å®ä¸–ç•Œä¸­çš„æ•°æ®åº“ç³»ç»Ÿåªæœ‰åœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ‰ä¼šé€‰æ‹©æ’åºåˆå¹¶è¿æ¥ã€‚ä¾‹å¦‚ï¼Œå½“å…¶ä¸­ä¸€ä¸ªè¾“å…¥å·²ç»æ’åºï¼Œæˆ–è€…è¿æ¥åˆ—ä¸Šæœ‰ç´¢å¼•æ—¶ï¼Œè¿™ç§æ–¹æ³•å°±ä¼šå—åˆ°é’çã€‚ç‰¹åˆ«æ˜¯ B+ æ ‘ç´¢å¼•ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æŒ‰æ’åºé¡ºåºè¯»å–æ•°æ®ã€‚æ­¤å¤–ï¼Œå¦‚æœå…ˆå‰æ“ä½œçš„è¾“å‡ºå·²æ’åºï¼Œæ’åº-åˆå¹¶è¿æ¥ä¹Ÿæ˜¯ä¸€ç§å¯è¡Œçš„é€‰æ‹©ã€‚æœ€ç»ˆï¼Œæ•°æ®åº“ä¼šå¯¹è¿™äº›å› ç´ è¿›è¡Œè¯„ä¼°ï¼Œä»¥å†³å®šæ’åºåˆå¹¶è¿æ¥æ˜¯å¦æ˜¯æœ€ä½³ç­–ç•¥ã€‚
However, the initial sorting step can be resource-intensive. The associated costs will be explored in detail, but it's important to note that real-world database systems might only opt for a sort-merge join under certain conditions. For example, this approach is favored when one of the inputs is already sorted, or there's an index on the join column. A B+ tree index, specifically, can facilitate reading data in a sorted sequence. Additionally, if the output from a prior operation is sorted, a sort-merge join becomes a viable option. Ultimately, databases will evaluate these factors to decide if a sort-merge join is the optimal strategy.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404234728062.png" alt="image-20240404234728062" style="zoom:50%;" /> 

```sql
Cost (SMJ) = Sort(Outer) + Sort(Inner) + NPages(Outer) + NPages(Inner)
-- Sort inputs Merge inputs
Sort(R) = External Sort Cost = 2*NumPasses*NPages(R)
```

- Our example: Letâ€™s say that both Reserves and Sailors can be sorted in 2 passes, then:

```sql
Cost(SMJ) = Sort R + Sort S + NPages(R) + NPages(S)
			 = 2*2*NPages(R)+ 2*2*NPages(S)
			 + NPages(R) + NPages(S)
			 = 5*1000 + 5* 500 = 7500 I/O
```

```
æ‰§è¡Œæ’åºåˆå¹¶è¿æ¥çš„å…¨éƒ¨æˆæœ¬å–å†³äºå¤–éƒ¨è¾“å…¥å’Œå†…éƒ¨è¾“å…¥çš„æ’åºæ€»å’Œï¼Œä»¥åŠå¤„ç†æ’åºåçš„åŒ¹é…è¾“å…¥æ‰€éœ€çš„é¡µé¢è¯»å–æ¬¡æ•°ã€‚å¦‚å‰æ‰€è¿°ï¼Œè¿™ç§æ’åºè´¹ç”¨ä¸å¤–éƒ¨æ’åºè´¹ç”¨ç›¸åŒã€‚æ•°æ®åº“ä¸€ç›´ä½¿ç”¨å¤–éƒ¨æ’åºç®—æ³•è¿›è¡Œæ’åºã€‚è®¡ç®—å…¬å¼æ¦‚æ‹¬åœ°è¯´ï¼Œå°±æ˜¯é€šè¿‡æ¬¡æ•°ä¸å…³ç³»é¡µæ•°ä¹˜ç§¯çš„ä¸¤å€ã€‚2 çš„ç³»æ•°è€ƒè™‘äº†æ’åºè¿‡ç¨‹ä¸­çš„è¯»å†™æ“ä½œã€‚
The full cost of executing a sort-merge join is determined by the sum of sorting both the outer and inner inputs and then the number of page reads required to process the sorted inputs for matches. This sorting expense is identical to the external sort cost, as previously discussed. Databases consistently utilize the external sort algorithm for sorting purposes. The formula for calculating this, to recap, is twice the product of the number of passes and the number of pages of the relation. The factor of two accounts for both reading and writing operations during the sorting process.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404234728062.png" alt="image-20240404234728062" style="zoom:50%;" /> 

```sql
Cost (SMJ) = Sort(Outer) + Sort(Inner) + NPages(Outer) + NPages(Inner)
-- Sort inputs Merge inputs
Sort(R) = External Sort Cost = 2*NumPasses*NPages(R)
```

- Our example: Letâ€™s say that both Reserves and Sailors can be sorted in 2 passes, then:

```sql
Cost(SMJ) = Sort R + Sort S + NPages(R) + NPages(S)
			 = 2*2*NPages(R)+ 2*2*NPages(S)
			 + NPages(R) + NPages(S)
			 = 5*1000 + 5* 500 = 7500 I/O
```

```
è®©æˆ‘ä»¬é‡æ¸©ä¸€ä¸‹æœ€åˆæ¶‰åŠ "é¢„å¤‡å½¹ "å’Œ "æ°´æ‰‹ "æ•°æ®é›†çš„ä¾‹å­ã€‚å‡è®¾è¿™ä¸¤ä¸ªæ•°æ®é›†åªéœ€é€šè¿‡ä¸¤æ¬¡å°±èƒ½é«˜æ•ˆæ’åºï¼Œè¿™å°±ç®€åŒ–äº†æˆ‘ä»¬çš„è®¡ç®—ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ’åºæ¬¡æ•°çš„ç¡®å®šæ˜¯åŸºäºæ›´å¤æ‚çš„æ•°å­¦è®¡ç®—ï¼Œä½†ä¸€æ—¦ç¡®å®šï¼Œè¿™äº›æ•°å­—å°±å¯ä»¥ç›´æ¥æ’å…¥å…¬å¼ä¸­ã€‚æ¯ä¸ªæ•°æ®é›†çš„æ’åºæˆæœ¬è®¡ç®—ä¸ºé€šè¿‡æ¬¡æ•°çš„ 2 å€ä¹˜ä»¥ç›¸åº”æ•°æ®é›†çš„é¡µæ•°ã€‚æ’åºå®Œæˆåï¼Œæˆ‘ä»¬ä¼šå°†ä¸¤ä¸ªæ•°æ®é›†çš„é¡µæ•°ç›¸åŠ ï¼Œä»¥è®¡ç®—åˆå¹¶é˜¶æ®µå’Œç”Ÿæˆç»“æœé›†çš„è´¹ç”¨ã€‚
Let's revisit our initial example involving the 'Reserves' and 'Sailors' datasets. Suppose both datasets can be efficiently sorted in just two passes, which simplifies our computation. It's important to recognize that determining the number of passes is based on more complex mathematics, but once established, these figures are plugged directly into the formula. The sorting cost for each dataset is calculated as two times the number of passes times the number of pages in the respective dataset. After sorting, we add the number of pages from both datasets to account for the merge phase and the production of the result set.
```

$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404234728062.png" alt="image-20240404234728062" style="zoom:50%;" /> 

```sql
Cost (SMJ) = Sort(Outer) + Sort(Inner) + NPages(Outer) + NPages(Inner)
-- Sort inputs Merge inputs
Sort(R) = External Sort Cost = 2*NumPasses*NPages(R)
```

- Our example: Letâ€™s say that both Reserves and Sailors can be sorted in 2 passes, then:

```sql
Cost(SMJ) = Sort R + Sort S + NPages(R) + NPages(S)
			 = 2*2*NPages(R)+ 2*2*NPages(S)
			 + NPages(R) + NPages(S)
			 = 5*1000 + 5* 500 = 7500 I/O
```

```
è¿™æ ·ç´¯è®¡è®¡ç®—çš„ç»“æœæ˜¯ï¼Œè¾“å…¥å…±ç»è¿‡äº”æ¬¡ï¼Œä»è€Œå¾—å‡ºæœ¬ä¾‹çš„è¾“å…¥/è¾“å‡ºæˆæœ¬ä¸º 7,500 ç¾å…ƒã€‚éœ€è¦ç‰¹åˆ«æé†’çš„æ˜¯ï¼Œæ ¹æ®æˆ‘ä»¬çš„ä¾‹å­å¾—å‡ºçš„ 5 å€ä¹˜æ•°ä¸åº”è¢«è§†ä¸ºæ ‡å‡†ç³»æ•°ã€‚å®é™…çš„è®¡ç®—å…¬å¼å› æ‰€éœ€é€šè¿‡æ¬¡æ•°è€Œå¼‚ï¼Œæ ¹æ®ç›¸å…³æ•°æ®é›†ï¼Œå¯èƒ½æ˜¯ä¸€æ¬¡ã€ä¸‰æ¬¡ã€å››æ¬¡æˆ–ä»»ä½•å…¶ä»–æ¬¡æ•°ã€‚å› æ­¤ï¼Œäº†è§£åŸºæœ¬å…¬å¼åŠå…¶åº”ç”¨è€Œä¸æ˜¯è®°ä½ä»»ä½•å…·ä½“çš„æ•°å­—ç¤ºä¾‹è‡³å…³é‡è¦ã€‚
This cumulative calculation results in a total of five passes over the inputs, leading to the specific example's I/O cost of 7,500. As a critical reminder, the multiplier of five, derived from our example, should not be taken as a standard coefficient. The actual formula varies depending on the number of passes required, which could be one, three, four, or any other number based on the datasets in question. Therefore, it's essential to understand the underlying formula and its application rather than memorizing any specific numerical examples.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235151177.png" alt="image-20240404235151177" style="zoom:50%;" /> 

```
æœ€åï¼Œæˆ‘ä»¬æ¢è®¨äº†æ•£åˆ—è¿æ¥çš„æ¦‚å¿µï¼Œå®ƒå°†æ•°æ®ä»åˆ†ç±»è½¬ä¸ºæ•£åˆ—ã€‚é€šè¿‡å¯¹ä¸¤ä¸ªè¾“å…¥åº”ç”¨ç›¸åŒçš„å“ˆå¸Œå‡½æ•°ï¼Œæˆ‘ä»¬å°†æ•°æ®å½’ç±»åˆ°ç›¸åº”çš„æ¡¶ä¸­ã€‚è¿™ç¡®ä¿äº†å¦‚æœå­˜åœ¨åŒ¹é…ï¼Œåˆ™ä¼šåœ¨åŒä¸€æ•°æ®æ¡¶ä¸­æ‰¾åˆ°ï¼Œä»è€Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç»•è¿‡å¤§é‡ä¸å¿…è¦çš„é¡µé¢æ£€æŸ¥ã€‚è¿™ç§æ–¹æ³•åªå…³æ³¨æ½œåœ¨çš„åŒ¹é…ï¼Œç®€åŒ–äº†è¿æ¥è¿‡ç¨‹ï¼Œä»è€Œå¤§å¤§æé«˜äº†æ•ˆç‡ã€‚
Finally, we explore the concept of Hash Joins, which pivot from sorting to hashing data. By applying the same hash function to both inputs, we categorize data into corresponding buckets. This ensures that if a match exists, it will be found within the same bucket, allowing us to bypass a significant number of unnecessary page checks. This method significantly enhances efficiency by focusing only on potential matches, streamlining the join process.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235318787.png" alt="image-20240404235318787" style="zoom:50%;" /> 

**1ï¸âƒ£**Partition both relations using hash function h: R tuples in partition l will onlymatch S tuples in partition I

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235347620.png" alt="image-20240404235347620" style="zoom:50%;" /> 

```
å“ˆå¸Œè¿æ¥æŠ€æœ¯é¦–å…ˆåº”ç”¨å“ˆå¸Œå‡½æ•°ï¼ˆè®°ä¸º hï¼‰å°†è¾“å…¥å…³ç³» R å’Œ S åˆ†å‰²æˆç£ç›˜ä¸Šçš„ç›¸åº”éƒ¨åˆ†ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œç»™å®šåˆ†åŒº I ä¸­å…³ç³» R çš„æ¯ä¸ªå…ƒç»„å°†å®Œå…¨åŒ¹é…å…³ç³» S çš„ç›¸åº”åˆ†åŒº I ä¸­çš„å…ƒç»„ã€‚è¿™ä¸€æ­¥éª¤ç¡®ä¿åªéœ€è¦æ¯”è¾ƒç›¸å…³åˆ†åŒºï¼Œä»è€Œå¤§å¤§å‡å°‘äº†æ½œåœ¨åŒ¹é…çš„æœç´¢ç©ºé—´ã€‚
The hash-join technique begins by applying a hash function, denoted as h, to partition both input relations R and S into corresponding segments on the disk. In this process, each tuple from relation R within a given partition I will exclusively match tuples in the corresponding partition I of relation S. This step ensures that only relevant partitions need to be compared, significantly reducing the search space for potential matches.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235318787.png" alt="image-20240404235318787" style="zoom:50%;" /> 

**2ï¸âƒ£**Read in a partition of R, hash it using h2 (<> h!). Scan matching partition of S, probe hash table for matches

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235406468.png" alt="image-20240404235406468" style="zoom:50%;" /> 

```
åˆ†åŒºåï¼Œæˆ‘ä»¬æ¯æ¬¡åªå…³æ³¨å…³ç³» R ä¸­çš„ä¸€ä¸ªåˆ†åŒºã€‚æˆ‘ä»¬åº”ç”¨ç¬¬äºŒä¸ªå“ˆå¸Œå‡½æ•° h2ï¼ˆå¯èƒ½ä¸ h ç›¸åŒï¼Œä¹Ÿå¯èƒ½ä¸åŒï¼‰æ¥ç»„ç»‡åˆ†åŒºå†…çš„æ•°æ®ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ‰«æå…³ç³» S ä¸­çš„åŒ¹é…åˆ†åŒºã€‚åœ¨æ‰«æè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸º R åˆ†åŒºåˆ›å»ºçš„å“ˆå¸Œè¡¨æ¥æ¢æµ‹å’Œè¯†åˆ« S ä¸­çš„ä»»ä½•åŒ¹é…å›¾å…ƒã€‚ä»¥è¿™ç§æ–¹å¼è¿­ä»£æ¯ä¸ªåˆ†åŒºå¯¹--å°† R ä¸­çš„ç¬¬ä¸€ä¸ªåˆ†åŒºä¸ S ä¸­çš„ç¬¬ä¸€ä¸ªåˆ†åŒºåŒ¹é…ï¼Œç„¶åç§»åŠ¨åˆ°ç¬¬äºŒä¸ªåˆ†åŒºï¼Œä»¥æ­¤ç±»æ¨ï¼Œæˆ‘ä»¬å°±æœ‰æ•ˆåœ°æ‰§è¡Œäº†è¿æ¥æ“ä½œã€‚
After partitioning, we focus on one partition at a time from relation R. We apply a second hash function, h2, which may be the same as or different from h, to organize the data within the partition. Simultaneously, we scan the matching partition from relation S. As we proceed, we use the hash table created for the partition of R to probe and identify any matching tuples in S. This probing is performed in the main memory, using designated input and output buffers for the operation. By iterating through each partition pair in this mannerâ€”matching the first partition from R with the first from S, then moving to the second, and so onâ€”we effectively perform the join operation.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235826054.png" alt="image-20240404235826054" style="zoom:50%;" /> 

**1ï¸âƒ£**In partitioning phase, we read+writeboth relations

**2ï¸âƒ£**In matching phase, we read both relations

```sql
Cost (HJ) = 2 * NPages(Outer) + 2* NPages(Inner) -- Create partitions
				+ NPages(Outer) + NPages(Inner)      -- Match partitions
```

- Our example:

```sql
Cost(HJ) = 2*NPages(R) + 2*NPages(S) + NPages(R) + NPages(S)
			= 3 * 1000+ 3* 500= 4500 I/Os
```

```
åœ¨å“ˆå¸Œè¿æ¥è¿‡ç¨‹çš„åˆå§‹é˜¶æ®µï¼Œå³åˆ†åŒºé˜¶æ®µï¼Œä¸¤ä¸ªå…³ç³»éƒ½ä»ç£ç›˜è¯»å–ï¼Œå¹¶åœ¨ç»è¿‡å“ˆå¸Œå‡½æ•°å¤„ç†åä»¥åˆ†åŒºçš„å½¢å¼å†™å›ã€‚è¿™ç§è¯»å†™æ“ä½œä¼šäº§ç”Ÿæˆæœ¬ï¼Œè®¡ç®—å…¬å¼ä¸ºå¤–éƒ¨å…³ç³»å’Œå†…éƒ¨å…³ç³»çš„é¡µæ•°çš„ä¸¤å€--è¿™ä»£è¡¨äº†åˆ›å»ºåˆ†åŒºæ‰€æ¶‰åŠçš„è¾“å…¥å’Œè¾“å‡ºæ“ä½œã€‚
In the initial phase of the hash-join process, the partitioning phase, both relations are read from disk and written back as partitions after being processed by the hash function. This read-write operation incurs a cost, which is calculated as two times the number of pages for both the outer and inner relationsâ€”this represents the input and output actions involved in creating the partitions.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235826054.png" alt="image-20240404235826054" style="zoom:50%;" /> 

**1ï¸âƒ£**In partitioning phase, we read+writeboth relations

**2ï¸âƒ£**In matching phase, we read both relations

```sql
Cost (HJ) = 2 * NPages(Outer) + 2* NPages(Inner) -- Create partitions
				+ NPages(Outer) + NPages(Inner)      -- Match partitions
```

- Our example:

```sql
Cost(HJ) = 2*NPages(R) + 2*NPages(S) + NPages(R) + NPages(S)
			= 3 * 1000+ 3* 500= 4500 I/Os
```

```
éšåçš„åŒ¹é…é˜¶æ®µéœ€è¦è¯»å–ç›¸åº”å…³ç³»çš„åˆ†åŒºï¼Œä»¥è¯†åˆ«å’ŒåŒ¹é…å…ƒç»„ã€‚è¿™ä¸€é˜¶æ®µçš„ç›¸å…³æˆæœ¬æ˜¯å¯¹æ¯ä¸ªåˆ†åŒºçš„ä¸€æ¬¡è¯»å–ï¼Œå³å¤–éƒ¨å…³ç³»å’Œå†…éƒ¨å…³ç³»çš„é¡µæ•°ä¹‹å’Œã€‚æ€»çš„æ¥è¯´ï¼Œè¿™ä¸€é˜¶æ®µçš„æˆæœ¬æ˜¯å¤–éƒ¨å…³ç³»çš„é¡µæ•°åŠ ä¸Šå†…éƒ¨å…³ç³»çš„é¡µæ•°ã€‚ç»¼åˆè¿™äº›æˆæœ¬ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œå“ˆå¸Œè¿æ¥éœ€è¦å¯¹ä¸¤ä¸ªè¾“å…¥è¿›è¡Œä¸‰æ¬¡éå†ï¼Œè¿™ä¸ªå…¬å¼éå¸¸ç®€å•ï¼Œå¯ä»¥åœ¨å®é™…ä½¿ç”¨ä¸­è®°ä½ã€‚
The subsequent matching phase entails reading the partitions of the corresponding relations to identify and match tuples. The cost associated with this phase is a single read pass over each partition, which is the sum of the number of pages of the outer and inner relations. In totality, this phaseâ€™s cost is the number of pages of the outer relation plus the number of pages of the inner relation. Combining these costs, we conclude that the hash-join necessitates three passes over both inputs, a formula that is simple enough to be memorized for practical use.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240404235826054.png" alt="image-20240404235826054" style="zoom:50%;" /> 

**1ï¸âƒ£**In partitioning phase, we read+writeboth relations

**2ï¸âƒ£**In matching phase, we read both relations

```sql
Cost (HJ) = 2 * NPages(Outer) + 2* NPages(Inner) -- Create partitions
				+ NPages(Outer) + NPages(Inner)      -- Match partitions
```

- Our example:

```sql
Cost(HJ) = 2*NPages(R) + 2*NPages(S) + NPages(R) + NPages(S)
			= 3 * 1000+ 3* 500= 4500 I/Os
```

```
åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­--"å‚¨å¤‡ "å…³ç³»çš„å¤§å°ä¸º 1000 é¡µï¼Œ"æ°´æ‰‹ "å…³ç³»çš„å¤§å°ä¸º 500 é¡µ--å“ˆå¸Œè¿æ¥æ“ä½œçš„æ€»æˆæœ¬ä¸º 4,500 æ¬¡ I/O æ“ä½œã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªæ•°å­—å¤§å¤§ä½äºç®€å•åµŒå¥—å¾ªç¯è¿æ¥æ‰€äº§ç”Ÿçš„æˆæœ¬ã€‚è™½ç„¶è¿™ä¸ªå…¬å¼æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å·¥å…·ï¼Œä½†å…³é”®æ˜¯è¦é¿å…æ­»è®°ç¡¬èƒŒï¼Œå°†å…¶ä½œä¸ºæ™®éæœ€ä¾¿å®œçš„é€‰æ‹©ã€‚æ•£åˆ—è¿æ¥çš„æ•ˆç‡ä¼šå› å¤šç§å› ç´ è€Œå˜åŒ–ï¼Œä¾‹å¦‚æ‰€éœ€çš„ä¼ é€’æ¬¡æ•°å’Œå¯ç”¨å†…å­˜é‡ã€‚å› æ­¤ï¼Œåœ¨ç‰¹å®šæƒ…å†µä¸‹ï¼Œå¿…é¡»é€ä¸€è¯„ä¼°å„ç§æ›¿ä»£æ–¹æ¡ˆï¼Œä»¥ç¡®å®šæœ€å…·æˆæœ¬æ•ˆç›Šçš„è¿æ¥æ–¹æ³•ã€‚
In the context of our illustrative exampleâ€”with the 'Reserves' relation sized at 1000 pages and the 'Sailors' relation at 500 pagesâ€”the total cost for the hash-join operation is 4,500 I/O operations. Notably, this figure is significantly lower than the cost incurred by a simple nested loop join. While this formula is a useful tool, it's crucial to avoid rigidly memorizing it as the universally cheapest option. The hash-join's efficiency can vary based on several factors, such as the number of passes required and the amount of available memory. Consequently, itâ€™s imperative to assess the alternatives case-by-case to determine the most cost-effective join method for a given situation.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405000940204.png" alt="image-20240405000940204" style="zoom:50%;" /> 

https://www.youtube.com/watch?v=o1dMJ6-CKzU

From 0:58

```
å› æ­¤ï¼Œå¦‚æœä½ ä»ç„¶å¯¹è¿™äº›ç®—æ³•æ„Ÿåˆ°å›°æƒ‘ï¼Œæˆ‘å»ºè®®ä½ è§‚çœ‹è¿™ä¸ªç®€çŸ­çš„è§†é¢‘ï¼Œå®ƒåŸºæœ¬ä¸Šæè¿°äº†è¿™ä¸‰ç§å…³èŠ‚çš„ç®—æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
So if you're still confused by any of these algorithms, I do encourage you to watch this short video that essentially depicts how these algorithms work uh for all three types of joints. 
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
![image-20240405001338970](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405001338970.png) 

```
è®©æˆ‘ä»¬ç®€è¦è®¨è®ºä¸€ä¸‹æ•°æ®åº“å¼•æ“ã€‚ä»æœ¬è´¨ä¸Šè®²ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå­˜å‚¨åœ¨ç£ç›˜ä¸Šçš„å¤§å‹æ•°æ®åº“ï¼Œæ‰€æœ‰æ•°æ®éƒ½å­˜æ”¾åœ¨é‚£é‡Œã€‚åœ¨å†…å­˜ä¸­è¿è¡Œçš„æ•°æ®åº“ç®¡ç†è½¯ä»¶åŒ…æ‹¬ä¸€ä¸ªç§°ä¸ºæ•°æ®ç¼“å†²åŒºçš„éƒ¨åˆ†ã€‚è¿™æ˜¯ä¸€ä¸ªå†…å­˜ç¼“å†²åŒºï¼Œæ•°æ®ä»ç£ç›˜æš‚æ—¶å¼•å…¥åˆ°è¿™é‡Œè¿›è¡Œå¤„ç†ã€‚åœ¨è¿™é‡Œè¿›è¡Œè®¡ç®—å’Œæ•°æ®å¤„ç†ï¼Œç„¶åå°†ç»“æœè¿”å›ç»™ç”¨æˆ·ã€‚è™½ç„¶æˆ‘ä»¬ç°åœ¨ä¸ä¼šæ·±å…¥ç ”ç©¶ä»£ç†æˆ–æ—¥å¿—ç¼“å†²åŒºï¼Œä½†äº†è§£åŸºæœ¬æµç¨‹å¾ˆé‡è¦ï¼šå½“ç”¨æˆ·ä»è¡¨ä¸­è¯·æ±‚æ•°æ®æ—¶ï¼Œç³»ç»Ÿä¼šä»ç£ç›˜è¯»å–æ•°æ®ï¼Œåœ¨å†…å­˜ä¸­è¿›è¡Œå¤„ç†ï¼Œç„¶åæ˜¾ç¤ºç»™ç”¨æˆ·ã€‚å¦‚æœæ˜¯æ•°æ®æ›´æ–°ï¼Œåˆ™é¦–å…ˆåœ¨å†…å­˜ä¸­è¿›è¡Œæ›´æ”¹ã€‚å…³äºäº‹åŠ¡çš„æ¦‚å¿µä»¥åŠæ•°æ®çŠ¶æ€å¦‚ä½•åœ¨æäº¤åæ°¸ä¹…ä¿å­˜åœ¨æ•°æ®åº“ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨åé¢è¿›è¡Œæ¢è®¨ã€‚æœ¬æ¦‚è¿°ä»…ä¾›å‚è€ƒã€‚
Let's briefly discuss the database engine. Essentially, we have a large database stored on disk, where all data resides. The database management software, which operates in memory, includes a segment known as the data buffer. This is the memory buffer where data is temporarily brought from disk for processing. Here, calculations and data manipulations occur before the results are presented back to the user. While we won't delve into agents or the log buffer now, it's important to understand the basic flow: when a user requests data from a table, the system reads the data from disk, processes it in memory, and then displays it to the user. In the case of data updates, changes are first made in memory. The concepts of transactions and how data states are permanently stored in the database upon committing will be explored later. This overview serves merely for illustration purposes.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
![image-20240405001433135](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405001433135.png) 

```
è¦äº†è§£è¿æ¥çš„æ“ä½œæ–¹æ³•ï¼Œè®©æˆ‘ä»¬ä»åµŒå¥—å¾ªç¯è¿æ¥å¼€å§‹ã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè¾“å…¥ï¼šå·¦è¾¹çš„è¾“å…¥ç”¨è“è‰²è¡¨ç¤ºï¼Œå³è¾¹çš„è¾“å…¥ç”¨ç»¿è‰²è¡¨ç¤ºã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬ä»å·¦è¾“å…¥ç«¯è¯»å–ä¸€æ¡è®°å½•ï¼ˆä¸ºç®€åŒ–èµ·è§ï¼Œé€šå¸¸æ˜¯ä¸€é¡µï¼‰ï¼Œç„¶åä»å³è¾“å…¥ç«¯æ‰«ææ‰€æœ‰è®°å½•ä»¥æŸ¥æ‰¾åŒ¹é…ã€‚ä¸ºä¾¿äºè¯´æ˜ï¼Œæˆ‘ä»¬è€ƒè™‘çš„æ˜¯å•æ¡è®°å½•è€Œä¸æ˜¯é¡µé¢ï¼Œä»¥ä¾¿æ¸…æ¥šåœ°è¡¨è¾¾æ¦‚å¿µã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä»å·¦è¾¹è¾“å…¥ç¬¬ä¸€æ¡è®°å½•ï¼ˆæ ‡ä¸º "1"ï¼‰ï¼Œç„¶åå°†å…¶ä¸å³è¾¹è¾“å…¥çš„æ‰€æœ‰è®°å½•è¿›è¡Œæ¯”è¾ƒï¼Œæœç´¢åŒ¹é…çš„è®°å½•ã€‚æˆ‘ä»¬ä¾æ¬¡å°†ç¬¬äºŒæ¡è®°å½• "2"ï¼Œç„¶åæ˜¯ "3"ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æˆ‘ä»¬å°†å·¦ä¾§è¾“å…¥çš„æ¯æ¡è®°å½•éƒ½ä¸å³ä¾§è¾“å…¥çš„æ‰€æœ‰è®°å½•è¿›è¡Œæ¯”å¯¹ã€‚å½“æˆ‘ä»¬æ£€æŸ¥åˆ°å·¦è¾¹æœ€åä¸€æ¡è®°å½• "6 "æ—¶ï¼Œæˆ‘ä»¬çš„è¿‡ç¨‹å°±ç»“æŸäº†ã€‚è¿™ç§é«˜å±‚æ¬¡çš„æè¿°æœ‰åŠ©äºè¯´æ˜åµŒå¥—å¾ªç¯è¿æ¥çš„åŸºæœ¬å·¥ä½œåŸç†ã€‚
To understand how joins operate, let's start with the Nested Loops Join. In this approach, we have two inputs: the left input is depicted in blue, and the right input in green. The process involves reading one record (for simplification, though typically it's one page) from the left input and then scanning all records from the right input to find matches. For illustrative purposes, we're considering individual records instead of pages to clearly convey the concept. So, we take the first record, labeled '1', from the left and compare it against all records on the right, searching for matches. We continue this process sequentially with the second record, '2', then '3', and so on, until we have checked each record from the left input against the entire right input. Once we reach the last record on the left, marked '6', our process concludes. This high-level description helps illustrate the fundamental workings of a Nested Loops Join.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
![image-20240405001525520](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405001525520.png) 

```
ç´¢å¼•åµŒå¥—å¾ªç¯æ“ä½œæ˜¯æˆ‘ä»¬å°šæœªæ·±å…¥ç ”ç©¶çš„ä¸»é¢˜ï¼Œä¹Ÿä¸ä¼šåœ¨æœ¬ä¸»é¢˜ä¸­æ¶‰åŠï¼Œå®ƒå›´ç»•ç€åˆ©ç”¨ç´¢å¼•ï¼ˆæ•°æ®åœ¨å…¶ä¸­æ’åºï¼‰æ¥é«˜æ•ˆå¯¼èˆªåˆ°æŒ‡ç¤ºå®é™…æ•°æ®æ‰€åœ¨ä½ç½®çš„æŒ‡é’ˆã€‚è¿™ç§æ–¹æ³•é€šè¿‡åˆ©ç”¨ç´¢å¼•çš„æœ‰åºç»“æ„æ¥ç®€åŒ–æ•°æ®åº“ä¸­çš„æœç´¢è¿‡ç¨‹ï¼Œä½†å®ƒä¸åœ¨æˆ‘ä»¬å½“å‰çš„ç ”ç©¶èŒƒå›´å†…ï¼Œå› æ­¤åœ¨ç°é˜¶æ®µæ— éœ€æ‹…å¿ƒå¯¹å®ƒçš„ç†è§£ã€‚
The Index Nested Loops operation, a topic we haven't delved into and won't be covering in this subject, revolves around utilizing an indexâ€”where data is sortedâ€”to efficiently navigate to the pointers that indicate where the actual data resides. This method streamlines the search process within databases by leveraging the organized structure of indexes, but it's not within our current scope of study, so there's no need for concern about understanding it at this stage.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
![image-20240405001600314](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405001600314.png) 

```
æ’åº-åˆå¹¶è¿æ¥é¦–å…ˆè¦å¯¹ä¸¤ä¸ªè¾“å…¥è¿›è¡Œæ’åºï¼Œç¡®ä¿å®ƒä»¬å®Œå…¨æœ‰åºã€‚æ’åºå®Œæˆåï¼Œæˆ‘ä»¬åŒæ—¶éå†ä¸¤ä¸ªè¾“å…¥ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¯”è¾ƒä¸€ä¸ªè¾“å…¥é¡¹ä¸­çš„ "1 "å’Œå¦ä¸€ä¸ªè¾“å…¥é¡¹ä¸­çš„ "1 "æ—¶ï¼Œä¸€æ—¦é‡åˆ° "2"ï¼Œæˆ‘ä»¬å°±çŸ¥é“ "1 "çš„æ¯”è¾ƒå·²ç»å®Œæˆï¼Œç„¶åç»§ç»­æ¯”è¾ƒ "2"ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šé«˜æ•ˆåœ°ç»§ç»­ä¸‹å»ï¼›å½“åˆ°è¾¾ "3 "æ—¶ï¼Œæˆ‘ä»¬æ— éœ€å†æ£€æŸ¥ "2"ã€‚è¿™ä¸ªæ–¹æ³•å±•ç¤ºäº†å¦‚ä½•åªéœ€å¯¹ä¸¤ä¸ªè¾“å…¥è¿›è¡Œä¸€æ¬¡ä¼ é€’å°±è¶³ä»¥å®Œæˆæ“ä½œï¼Œçªå‡ºäº†æ’åº-åˆå¹¶è¿æ¥åœ¨ç®€åŒ–æ¯”è¾ƒè¿‡ç¨‹ä¸­çš„æ•ˆç‡ã€‚
The Sort-Merge join begins by sorting both inputs, ensuring they are fully organized. Once sorted, we traverse both inputs simultaneously. For example, when comparing '1' from one input with '1' from the other, and as soon as we encounter '2', we know that the comparison for '1' is complete and move on to '2'. This process continues efficiently; upon reaching '3', we proceed without needing further checks for '2'. This method demonstrates how a single pass over both inputs suffices to complete the operation, highlighting the efficiency of the Sort-Merge join in streamlining the comparison process.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
![image-20240405001638302](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405001638302.png) 

```
æ•£åˆ—è¿æ¥æœ€åˆæ˜¯ä½¿ç”¨ç›¸åŒçš„æ•£åˆ—å…¬å¼å°†ä¸¤ä¸ªè¾“å…¥æ•°æ®æ•£åˆ—åˆ°æ•°æ®æ¡¶ä¸­ï¼Œè¿™æ˜¯ç¡®ä¿ç›¸åº”æ•°æ®è¿›å…¥ç›¸åŒæ•°æ®æ¡¶çš„å…³é”®æ­¥éª¤ã€‚æ•£åˆ—åï¼Œè¯¥è¿‡ç¨‹åŒ…æ‹¬æ£€æŸ¥è¿™äº›ç›¸åº”æ•°æ®æ¡¶ä¸­çš„åŒ¹é…é¡¹ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬æ•£åˆ—å€¼ "2 "å¹¶å°†å…¶æŒ‡å‘ç¬¬ä¸€ä¸ªæ•°æ®æ¡¶æ—¶ï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥è¯¥ç‰¹å®šæ•°æ®æ¡¶ä¸­çš„æ‰€æœ‰å€¼ã€‚æ£€æŸ¥å®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥ç¡®å®šåœ¨å…¶ä»–ä»»ä½•æ•°æ®æ¡¶ä¸­éƒ½æ‰¾ä¸åˆ°ä¸ "2 "åŒ¹é…çš„å€¼ã€‚è¿™ç§æ–¹æ³•å‡¸æ˜¾äº†æ•£åˆ—è¿æ¥çš„æ•ˆç‡ï¼Œå®ƒæ ¹æ®åº”ç”¨çš„æ•£åˆ—å…¬å¼å°†æ•°æ®åˆ†ç¦»æˆæ˜“äºç®¡ç†çš„éƒ¨åˆ†ï¼Œä»è€Œç®€åŒ–äº†åŒ¹é…æœç´¢ã€‚
The Hash Join involves initially hashing both inputs into buckets using the same hash formula, a critical step to ensure corresponding data lands in the same buckets. After hashing, the process involves checking for matches within these corresponding buckets. For instance, when we hash the value '2' and it directs us to the first bucket, we only need to examine all values within this specific bucket. Once this check is complete, we can be certain that no matches for '2' will be found in any other bucket. This method highlights the efficiency of the Hash Join, which simplifies the search for matches by segregating data into manageable segments based on the hash formula applied.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405002001457.png" alt="image-20240405002001457" style="zoom:50%;" /> 

```
å¥½çš„ æ‰€ä»¥ï¼Œæœ€åä¸€ç‚¹è¦æ³¨æ„çš„æ˜¯ï¼Œå½“æ¶‰åŠåˆ° "è¿æ¥ "æ—¶ï¼Œå…¶å®å°±æ˜¯ "å…³èŠ‚è¿æ¥æ¡ä»¶"ã€‚
OK. So uh the last note when it comes to join is really uh on joint joint conditions. 
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405002246792.png" alt="image-20240405002246792" style="zoom:50%;" /> 

**1ï¸âƒ£**Equalities over several attributes (e.g., R.sid=S.sidAND R.rname=S.sname):

- For Sort-Merge and Hash Join, sort/partition on combination of the two join columns

**2ï¸âƒ£**Inequality conditions (e.g., R.rname< S.sname):

1. Hash Join, Sort Merge Join not applicable
2. Block NL quite likely to be the best join method here

```
åœ¨æœ¬è®²åº§å¯¹ç­‰è¿æ¥çš„æ¢ç´¢ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•æ‰§è¡Œä»¥å±æ€§é—´ç›¸ç­‰ä¸ºæ¡ä»¶çš„è¿æ¥ï¼Œä¾‹å¦‚ R.sid = S.sid AND R.rname = S.rnameã€‚å¯¹äºè¿™äº›æƒ…å†µï¼Œæˆ‘ä»¬æœ‰å‡ ç§æ–¹æ³•å¯ä¾›é€‰æ‹©ï¼šåµŒå¥—å¾ªç¯ã€æ’åºåˆå¹¶æˆ–æ•£åˆ—è¿æ¥ï¼Œæ¯ç§æ–¹æ³•éƒ½æœ‰è‡ªå·±ç‹¬ç‰¹çš„åŸºäºå…±åŒå±æ€§ç»„åˆè¡Œçš„æ–¹æ³•ã€‚å¯¹äºæ’åºåˆå¹¶å’Œæ•£åˆ—è¿æ¥ï¼Œå…¶å®ç°ä¾èµ–äºæ ¹æ®ä¸¤ä¸ªè¿æ¥åˆ—çš„ç»„åˆå¯¹è¡¨è¿›è¡Œæ’åºæˆ–åˆ†åŒºï¼Œè€Œè¿™ä¸¤ä¸ªè¿æ¥åˆ—æ˜¯å®Œå…¨åŒ¹é…çš„ã€‚
In our exploration of equi-joins during this lecture, we've learned how to execute joins where the condition is based on equality between attributes, such as R.sid = S.sid AND R.rname = S.rname. For these scenarios, we have several options at our disposal: nested loops, sort-merge, or hash joins, each with its unique approach to combining rows based on a common attribute. In the case of sort-merge and hash joins, the implementation relies on sorting or partitioning the tables on the combination of the two join columns, which are matched exactly.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405002246792.png" alt="image-20240405002246792" style="zoom:50%;" /> 

**1ï¸âƒ£**Equalities over several attributes (e.g., R.sid=S.sidAND R.rname=S.sname):

- For Sort-Merge and Hash Join, sort/partition on combination of the two join columns

**2ï¸âƒ£**Inequality conditions (e.g., R.rname< S.sname):

1. Hash Join, Sort Merge Join not applicable
2. Block NL quite likely to be the best join method here

```
ä½†æ˜¯ï¼Œå½“é‡åˆ°æ¶‰åŠä¸ç­‰å¼çš„å…¶ä»–ç±»å‹è¿æ¥æ¡ä»¶ï¼ˆå¦‚ R.rname < S.snameï¼‰æ—¶ï¼Œä¸Šè¿°è¿æ¥æ–¹æ³•å°±ä¸é€‚ç”¨äº†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®åº“é€šå¸¸ä¼šæ¢å¤ä½¿ç”¨åµŒå¥—å¾ªç¯è¿æ¥ï¼Œè€Œå—åµŒå¥—å¾ªç¯ (BNL) è¿æ¥å¯èƒ½æ˜¯æœ€å…·æˆæœ¬æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆã€‚ä¹‹æ‰€ä»¥é€‰æ‹©è¿™ç§æ–¹æ³•ï¼Œæ˜¯å› ä¸ºæ•£åˆ—è¿æ¥æœ¬èº«ä¸é€‚åˆéç›¸ç­‰æ¡ä»¶--å®ƒä»¬æ— æ³•å¤„ç†èŒƒå›´æ¯”è¾ƒã€‚åŒæ ·ï¼Œæ’åºåˆå¹¶è¿æ¥ä¹Ÿä¸æ”¯æŒä¸ç­‰å¼æ¡ä»¶ï¼Œå°½ç®¡æ½œåœ¨çš„æœŸæœ›ä¸æ­¤ç›¸åã€‚è™½ç„¶åœ¨æ’åºåˆå¹¶æ¡†æ¶å†…è®¾è®¡ä¸€ç§å…è®¸ä¸ç­‰å¼çš„ç®—æ³•æ˜¯å¯ä»¥æƒ³è±¡çš„ï¼Œä½†æ ‡å‡†æ•°æ®åº“ç³»ç»Ÿå¹¶æ²¡æœ‰é‡‡ç”¨è¿™ç§æ–¹æ³•ã€‚å› æ­¤ï¼Œåœ¨è¿æ¥æ¡ä»¶ä¸æ˜¯åŸºäºç›¸ç­‰æ¡ä»¶çš„ç›¸å¯¹ç½•è§çš„æƒ…å†µä¸‹ï¼Œæ•°æ®åº“é»˜è®¤é‡‡ç”¨é˜»å¡åµŒå¥—å¾ªç¯è¿æ¥ã€‚
However, when faced with other types of join conditions that involve inequalities, such as R.rname < S.sname, the aforementioned join methods are not applicable. Databases typically revert to using nested loop joins for these cases, with block nested loops (BNL) joins being a likely candidate for the most cost-effective solution. The reason for this preference is that hash joins are inherently unsuitable for non-equality conditionsâ€”they cannot process range comparisons. Similarly, despite potential expectations to the contrary, sort-merge joins do not support inequality conditions either. While it is conceivable to design an algorithm that allows for inequalities within a sort-merge framework, standard database systems have not adopted such an approach. Therefore, in the relatively uncommon scenarios where the join condition is not based on equality, databases default to block nested loops joins.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405002510259.png" alt="image-20240405002510259" style="zoom:50%;" /> 

**1ï¸âƒ£**A virtue of relational DBMSs:

1. Queries are composed of a few basic operators
2. Implementation of operators can be ğŸš—efully tuned
3. Important to do this

**2ï¸âƒ£**Many alternative implementations for each operator

- No universally superior technique for most operators

**3ï¸âƒ£**Must consider alternatives for each operation in a query and choose best one based on system statisticsâ€¦

- Part of the broader task of optimizing a query composed of several operations

```
æ€»ä¹‹ï¼Œæœ¬è®²åº§æ·±å…¥æ¢è®¨äº†æ•°æ®åº“ç³»ç»Ÿä¸­å„ç§æ“ä½œçš„å®ç°ï¼Œå°†å…³ç³»ä»£æ•°çš„ç†è®ºæ¦‚å¿µè½¬åŒ–ä¸ºå®é™…åº”ç”¨ï¼Œå¦‚é€‰æ‹©ã€æŠ•å½±å’Œè¿æ¥ã€‚æˆ‘ä»¬æ¢è®¨äº†å®ç°è¿™äº›æ“ä½œçš„ä¸åŒæ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•ä¼°ç®—å®ƒä»¬åœ¨æ•°æ®åº“ç³»ç»Ÿä¸­çš„æˆæœ¬ã€‚è¿™å°±ä»‹ç»äº†ä¼˜åŒ–å™¨çš„ä½œç”¨ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€è¯¾è®¨è®ºçš„å¹•å "å¤§è„‘"ã€‚ä¼˜åŒ–å™¨ä¼šè¯„ä¼°æ‰§è¡ŒæŸ¥è¯¢çš„æ‰€æœ‰å¯èƒ½æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶é€‰æ‹©æœ€å…·æˆæœ¬æ•ˆç›Šçš„æ–¹æ³•ï¼Œä»¥ç¡®ä¿å¿«é€Ÿå“åº”æ—¶é—´ã€‚è¿™ä¸€é”™ç»¼å¤æ‚çš„è¿‡ç¨‹å¼ºè°ƒäº†ä¼˜åŒ–å™¨åœ¨æ•°æ®åº“ç®¡ç†ä¸­çš„å…³é”®ä½œç”¨ï¼Œå…¶ç›®çš„æ˜¯æé«˜æ•ˆç‡å’Œæ€§èƒ½ã€‚
In summary, this lecture has delved into the implementation of various operations within a database system, translating the theoretical concepts of relational algebra into practical applications such as selection, projection, and joins. We've explored different methods of implementing these operations and how to estimate their costs within a database system. This introduces the role of the optimizer, the "brain" behind the scenes, which we will discuss in our next session. The optimizer evaluates all possible alternatives to execute a query and chooses the most cost-effective approach, ensuring fast response times. This intricate process underscores the optimizer's crucial role in database management, aiming to enhance efficiency and performance.
```


$$
\textcolor{red}{\Huge{-------}\colorbox{yellow}{åˆ†å‰²çº¿}\Huge{-------}}
$$
<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240405002727089.png" alt="image-20240405002727089" style="zoom:50%;" /> 

**1ï¸âƒ£**Understand alternatives for join operator implementations

- Be able to calculate the cost of alternatives

**2ï¸âƒ£**Important for Assignment 3 as well

```
é‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯å¿…ä¸å¯å°‘çš„å‘¢ï¼Ÿä½ éœ€è¦æŒæ¡å¦‚ä½•åº”ç”¨è¿™äº›å…¬å¼ï¼Œä½ å°†æœ‰ä¸€ä»½å…¬å¼å°æŠ„ä¾›ä½ ä½¿ç”¨ã€‚æˆ‘ä¼šä¸ºä½ ä»¬æä¾›æ‰€æœ‰çš„å…¬å¼ï¼Œä½†å…³é”®æ˜¯ä½ ä»¬è¦äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨æ¯ä¸€ä¸ªå…¬å¼ã€‚è¿™å°†æ˜¯ä½ çš„ä½œä¸šåœ°å½¢ï¼Œä½ å°†åœ¨è¿™é‡Œæ‰®æ¼”ä¼˜åŒ–å¸ˆæˆ–æ•°æ®åº“ç®¡ç†å‘˜çš„è§’è‰²ã€‚æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼Œæˆ‘æœŸå¾…ç€ä¸‹ä¸€å ‚è¯¾çš„åˆ°æ¥ã€‚
So, what is essential? You'll need to grasp how to apply these formulas, and you'll have a formula cheat sheet at your disposal. I'll provide you with all the formulas, but it's crucial for you to understand how to utilize each one effectively. This will be your assignment terrain, where you'll step into the role of the optimizer or the database administrator. Thank you for your attention, and I look forward to our next session.
```

